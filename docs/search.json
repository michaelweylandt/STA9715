[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "STA 9715 - Additional Resources and Course Policies",
    "section": "",
    "text": "Readings and practice problems will be assigned from the following freely-available textbooks:\n\nIntroduction to Probability by Blitzstein and Hwang (BH)\nMathematics for Machine Learning by Diesenroth, Faisal, and Ong (DFO)\nIntroduction to Probability by Grinstead and Snell (GS)\n\nFor students wishing to dig deeper or to consult alternative resources, the following books are also recommended:\n\nStatistical Inference by Casella and Berger (Chapters 1-5)\nProbability with Applications in Engineering, Science, and Technology by Carlton and Devore (Chapters 1-4)\nFundamentals of Probability: A First Course by DasGupta (DG)1\n\n\n\nSTA9715 will use Piazza as the course discussion board. Students are encouraged to direct all questions about course topics or logistics to Piazza; use of a public anonymous discussion board allows students to benefit from the insights of their classmates and allows instructors to answer questions publicly to the benefit of all students.\nStudents are encouraged to use Piazza’s private question feature if they need to contact the instructor directly. Please only use private questions for personal inquiries: questions about the technical substance of the course can and should be asked (pseudonymously) in the public section of Piazza.\nPiazza login information will be distributed through CUNY Brightspace.\n\n\n\nStudents are encouraged to make use of any and all external resources, including generative AI tools, for at home study and for practice problems. Students are strongly encouraged to collaborate on weekly practice problems. You are ultimately responsible for the correctness of any submitted materials - “the AI told me so” is not a valid defense.\nNote that official solutions for many practice problems can be found online on the BH homepage.\nThe instructor will provide a formula sheet for use during in-class quizzes, tests, and final exam. No alternative resources may be used during these activities."
  },
  {
    "objectID": "resources.html#course-resources",
    "href": "resources.html#course-resources",
    "title": "STA 9715 - Additional Resources and Course Policies",
    "section": "",
    "text": "Readings and practice problems will be assigned from the following freely-available textbooks:\n\nIntroduction to Probability by Blitzstein and Hwang (BH)\nMathematics for Machine Learning by Diesenroth, Faisal, and Ong (DFO)\nIntroduction to Probability by Grinstead and Snell (GS)\n\nFor students wishing to dig deeper or to consult alternative resources, the following books are also recommended:\n\nStatistical Inference by Casella and Berger (Chapters 1-5)\nProbability with Applications in Engineering, Science, and Technology by Carlton and Devore (Chapters 1-4)\nFundamentals of Probability: A First Course by DasGupta (DG)1\n\n\n\nSTA9715 will use Piazza as the course discussion board. Students are encouraged to direct all questions about course topics or logistics to Piazza; use of a public anonymous discussion board allows students to benefit from the insights of their classmates and allows instructors to answer questions publicly to the benefit of all students.\nStudents are encouraged to use Piazza’s private question feature if they need to contact the instructor directly. Please only use private questions for personal inquiries: questions about the technical substance of the course can and should be asked (pseudonymously) in the public section of Piazza.\nPiazza login information will be distributed through CUNY Brightspace.\n\n\n\nStudents are encouraged to make use of any and all external resources, including generative AI tools, for at home study and for practice problems. Students are strongly encouraged to collaborate on weekly practice problems. You are ultimately responsible for the correctness of any submitted materials - “the AI told me so” is not a valid defense.\nNote that official solutions for many practice problems can be found online on the BH homepage.\nThe instructor will provide a formula sheet for use during in-class quizzes, tests, and final exam. No alternative resources may be used during these activities."
  },
  {
    "objectID": "resources.html#academic-integrity-policy",
    "href": "resources.html#academic-integrity-policy",
    "title": "STA 9715 - Additional Resources and Course Policies",
    "section": "Academic Integrity Policy",
    "text": "Academic Integrity Policy\nI fully support CUNY’s Policy on Academic Integrity, which states, in part:\n\nAcademic dishonesty is prohibited in The City University of New York. Penalties for academic dishonesty include academic sanctions, such as failing or otherwise reduced grades, and/or disciplinary sanctions, including suspension or expulsion.\n\n\nAcademic integrity is at the core of a college or university education. Faculty assign essays, exams, quizzes, projects, and so on both to extend the learning done in the classroom and as a means of assessing that learning. When students violate the academic integrity policy (i.e., “cheat”), they are committing an act of theft that can cause real harm to themselves and others including, but not limited to, their classmates, their faculty, and the caregivers who may be funding their education. Academic dishonesty confers an unfair advantage over others, which undermines educational equity and fairness. Students who cheat place their college’s accreditation and their own future prospects in jeopardy.\n\nIn this course, expectations for academic integrity are straightforward: no use of unauthorized materials on weekly quizzes, mid-semester tests, or the course final exam. Unless explicitly stated otherwise by the instructor in writing, the only authorized materials are the instructor-provided formula sheets.\nAcademic sanctions in this class will range from an F on the Assignment to an F in this Course. A report of suspected academic dishonesty will be sent to the Office of the Dean of Students.\nStudents are encouraged to contact the instructor with any questions or concerns related to matters of academic integrity."
  },
  {
    "objectID": "resources.html#course-accomodations",
    "href": "resources.html#course-accomodations",
    "title": "STA 9715 - Additional Resources and Course Policies",
    "section": "Course Accomodations",
    "text": "Course Accomodations\n\nDisability Services\nIt is CUNY policy to provide Accommodations and Academic Adjustments to students with disabilities.\nAny student who has a disability who may need accommodations in this class should register as early as possible with Student Disability Services (SDS). Your registration with Student Disability Services is confidential, and is not recorded on your Baruch Academic Record. SDS can be reached by email at disability.services@baruch.cuny.edu, by phone at 646-312-4590, or in person at NVC 2-272.\nPlease note that the instructor cannot provide accommodations unless requested by SDS.\n\n\nReligious Accomodations\nIt is CUNY policy to provide accommodations for students’ sincerely held religious beliefs. If a religious accommodation is requested, please contact the instructor at least two weeks in advance.\n\n\nUnexcused Abscence Policy\nAttendance is not required, but lecture recordings will not be provided. Students are responsible for the content of all sessions missed."
  },
  {
    "objectID": "resources.html#personal-resources2",
    "href": "resources.html#personal-resources2",
    "title": "STA 9715 - Additional Resources and Course Policies",
    "section": "Personal Resources2",
    "text": "Personal Resources2\nTake care of yourself. Do your best to maintain a healthy lifestyle this semester by eating well, exercising, avoiding drugs and alcohol, getting enough sleep and taking some time to relax. This will help you achieve your goals and cope with stress.\nAll of us benefit from support during times of struggle. You are not alone. Asking for support sooner rather than later is often helpful.\n\nMental Health Resources\nIf you or anyone you know experiences significant academic stress, difficult life events, or feelings like anxiety or depression, I strongly encourage you to seek support.\nThe Baruch Counselling Center is here to help. You can visit them in person at 137 E 25th St, 9th floor or call them at 646-312-2155 during normal business hours; you can make an appointment online here. For more immediate support, please call NYC WELL (1-888-NYC-WELL or 1-888-692-9355).3\nAsking for help is often difficult: consider reaching out to a friend, family, or a member of the faculty you trust for help getting connected to support that can help.\nIf you are worried about a friend or classmate, consider reaching out to the Baruch Campus Intervention Team.\n\n\nPhysical Health\nHealthy CUNY promotes well-being and a culture of health in order to foster the academic and life success of all CUNY students. They can connect you with a variety of campus- and community-based healthcare providers.\nBaruch Health Services provides students with a full range of clinical health services. Call 646-312-2040 or email StudentHealthCareCenter@baruch.cuny.edu to make an appointment.\n\n\nFood Security\nAll CUNY students have access to CUNY Food Pantries located throughout the five boroughs, thanks to the CUNY CARES program. CUNY CARES is also able to help qualifying students with SNAP (“Food Stamps”) enrollment.\nOn campus, you can also access the Bearcat Food Pantry.\n\n\nFinancial Security\nBaruch students experiencing heightened financial stress have access to Student Emergency Grants administered through the Office of the Dean of Students.\nNote that funds are also available for students experiencing immigration-related financial stress.\n\n\nImmigration Status\nCUNY Citizenship Now! provides confidential, high-quality immigration law services to all CUNY students.\nNote that Citizenship Now!’s primary Manhattan office is located in the Heights, not on the Baruch campus and that an appointment is strongly recommended. Call 646-664-9350 during business hours for more information."
  },
  {
    "objectID": "resources.html#footnotes",
    "href": "resources.html#footnotes",
    "title": "STA 9715 - Additional Resources and Course Policies",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFree to CUNY Students. Please contract instructor if having access issues↩︎\nLanguage adapted from Professor Ryan Tibshirani (UC Berkeley).↩︎\nDescriptions of Baruch and CUNY resources adapted from program websites.↩︎"
  },
  {
    "objectID": "notes/continuous_rvs.html",
    "href": "notes/continuous_rvs.html",
    "title": "Continuous Random Variables",
    "section": "",
    "text": "\\[\\newcommand{\\P}{\\mathbb{P}} \\newcommand{\\E}{\\mathbb{E}} \\newcommand{\\V}{\\mathbb{V}}\\]\nIn this set of notes, we introduce the fundamentals of continuous random variables and their distributions. At a high level, continuous RVs are much like their discrete counterparts - we can compute expectations and variances, compute probabilities of events, see how they behave under transformations. They differ in one key way however: they do not have a probability mass function. Continuous RVs are instead characterized by a probability density function. If you take an “expectations first” view of probability theory, this is not a ground-shaking change; if you instead take a “distributions first” view, the changes are a bit more obvious. Regardless, we begin by recalling our discussion of “events” in probability."
  },
  {
    "objectID": "notes/continuous_rvs.html#events-and-sigma-algebras",
    "href": "notes/continuous_rvs.html#events-and-sigma-algebras",
    "title": "Continuous Random Variables",
    "section": "Events and Sigma Algebras",
    "text": "Events and Sigma Algebras\nRecall that in our earlies discussion of probability, we studiously avoided asking the probability of an outcome; we instead insisted on only assigning probabilities to events. At the time, I argued that events are easier to generalize: it is easier to have one uniform set of rules for events than to have two interlocking sets of rules for outcomes and events separately.1 This is certainly true, but it’s now time to see the other advantage of event-thinking.\nFormally, a probability space consists of three things:\n\n\\(\\Omega\\), a set of possible outcomes\n\\(\\mathcal{E}\\), a set of allowed events\n\\(\\P: \\mathcal{E} \\to [0, 1]\\), a measure function that assigns a numerical value to every event \\(E \\in \\mathcal{E}\\)\n\nThe set of events \\(\\mathcal{E}\\) is required to have certain properties:\n\nIf \\(E \\in \\mathcal{E}\\), the complement is as well: \\(E^c \\in \\mathcal{E}\\).\n\\(\\emptyset, \\Omega \\in \\mathcal{E}\\)\nIf \\(E_1, E_2, \\dots\\) are (a countable list of) elements of \\(\\mathcal{E}\\), so is their union: \\(\\bigcup_{i=1}^{\\infty} E_i \\in \\mathcal{E}\\)\n\nMany - if not all - of the apparent paradoxes of probability theory are resolved by the set \\(\\mathcal{E}\\). \\(\\mathcal{E}\\) essentially defines the set of allowed questions we can ask of our probability measure. If a set is “too weird”, we simply exclude it from \\(\\mathcal{E}\\) and the problems go away. (Life is much easier in math-land.)\nRecalling that \\(\\mathcal{E}\\) defines the “allowed questions”, let’s review our three rules:\n\nIf we are allowed to ask the probability of \\(E\\), we must also be allowed to ask the probability of not \\(E\\) (\\(E^c\\)).\nWe have to be able to ask whether anything happens (\\(\\Omega \\in \\mathcal{E}\\)) or whether nothing happens (\\(\\emptyset \\in \\mathcal{E}\\)). (Recall that we take \\(\\P(\\emptyset) = 0\\) and \\(\\P(\\Omega) = 1\\).)\nIf we are allowed to ask whether \\(E_1, E_2, \\dots\\) happen separately, we are also allowed to ask whether any of them, i.e., their union, happens.\n\nThe fundamental curiosity of continuous random variables is that we take out the singleton events \\(\\{X = x\\}\\) from the set \\(\\mathcal{E}\\). That is, questions like “what is the probability that \\(X\\) equals 3” are no longer valid in the land of continuous random variables."
  },
  {
    "objectID": "notes/continuous_rvs.html#continuous-random-variables",
    "href": "notes/continuous_rvs.html#continuous-random-variables",
    "title": "Continuous Random Variables",
    "section": "Continuous Random Variables",
    "text": "Continuous Random Variables\n\nExact Equality is Ill-Posed\nSuppose we seek to develop a probabilistic model for a ‘natural’ quantity, e.g., my height. You might seek to calculate the probability that I am 5’10”. But upon a bit of reflection, that’s actually not a well-posed question. It depends how accurately you are measuring:\n\nIf you are giving an estimated height to a public safety officer, 5’10” might be a very exact measurement.\nIf you are taking my height for my annual physical, 5’10” might seem to be ‘correct.’\nIf you pull out a tape measure, I may be closer to 5’10.625”. And\nIf you use lab grade equipment to measure me down to the final atom, there’s not even a real answer - my hair is constantly moving back and forth.2\n\nWith this perspective, let’s reconsider the question “What is the probability that Michael is exactly 5’10”?“. Depending on your philosophical inclinations, the answer is either 0 or the question is ill-defined. It is customary to introduce continuous random variables from the former view (”probability 0”); I prefer the latter (“invalid question”). Regardless, we need a better building block for probabilities of ‘natural’ events.\n\n\nCumulative Distribution Functions\nIn our discussion of discrete random variables, we emphasized the role of the probability mass function. But there was another, equivalent, function that characterizes a distribution: the cumulative distribution function (CDF).\n\\[ F_X(x) = \\P(X \\leq x) \\]\nFor discrete distributions, we simply defined \\(F_X(\\cdot)\\) in terms of the PMF. But we can also take the CDF as our starting point. If we start from a CDF, the PMF of a discrete random variable is given by\n\\[ P(X = x) = F_X(x) - F_X(x-1) \\quad \\text{ for discrete } X \\]\nWhat does a CDF look like for a continuous random variable? In essence, nothing changes! We can still ask the question \\(\\P(X \\leq x)\\) - formally, the set \\((-\\infty, x] \\in \\mathcal{E}\\) - regardless of the continuity or discreteness of \\(X\\). Given some reference height, we simply ask whether I am taller than it or not. We might mutter about needing more precise measuring tools to be sure - such is the concern of experimentalists - but at least the question is well-posed.\n\n\nContinuous Random Variables\nWe are now ready to define continuous random variables. A random variable \\(X\\) is continuous if its CDF \\(F_X(\\cdot)\\) satisfies the following:\n\n\\(\\lim_{x \\to -\\infty} F_X(x) = 0\\)\n\\(\\lim_{x \\to +\\infty} F_X(x) = 1\\)\n\\(F_X(\\cdot)\\) is non-decreasing. (\\(x \\leq y \\implies F_X(x)\\leq F_X(y)\\))\n\\(F_X(\\cdot)\\) is continuous and almost everywhere differentiable.\n\nThese rules may be more continuous than what we have seen so far, but they are mostly restatements of our basic probability properties.\n\n\\(F(-\\infty) = 0\\). What is the chance that \\(X\\) is less than \\(-\\infty\\)? Zero of course!\n\\(F(+\\infty) = 1\\). What is the chance that \\(X\\) is less than \\(+\\infty\\)? 100%.3\n\\(F_X(\\cdot)\\) is non-decreasing. Of course! Since \\(\\{X \\leq x\\} \\subseteq \\{X \\leq y\\}\\), we have to have \\(\\P\\{X \\leq x\\} \\leq \\P\\{X \\leq y\\} \\implies F_X(x)  \\leq F_X(y)\\).\n\nThe final assumption - about continuity and differentiability - is a bit more technical, but it lets us avoid weird pathologies. In brief, we’re just enforcing the rule that there are no “jumps” in \\(F_X(\\cdot)\\). Such “jumps” are indicative of discrete, not continuous, behavior.4\nWe now have a cleaner - and perhaps simpler - categorization of random variables. All random variables are defined by their CDF. If the CDF of a random variable \\(X\\) is a “step-function”, \\(X\\) is a discrete random variable; if the CDF of a random variable \\(X\\) is a continuous function, \\(X\\) is a continuous random variable.\n\n\nProbability Densities\nNow suppose we are interested in some continuous random variable \\(X\\). Because \\(X\\) is continuous, \\(F_X(\\cdot)\\) is continuous and has a derivative (almost everywhere). This derivative turns out to be useful enough to get its own name:\n\\[\\frac{\\text{d}F_X}{\\text{d}x}(x) = F_X'(x) \\text { is the \\emph{probability density function} of $X$}\\]\nThe probability density function (PDF) is the closest analogue a continuous RV has to a PMF.\nBefore we dive into the use of PDFs, let’s see what properties we can derive.\n\nFirst, we note that, because \\(F_X(\\cdot)\\) is non-decreasing, its derivative \\(f_X(\\cdot)\\) is non-negative. So both PDFs and PMFs are non-negative.\nNext, we apply the fundamental theorem of calculus to \\(F_X(\\cdot)\\) and \\(f_X(\\cdot)\\).\n\\[ F_X(a) = \\int_{-\\infty}^a F'_X(x)\\,\\text{d}x = \\int_{-\\infty}^a f_X(x)\\,\\text{d}x = \\P(X \\leq a)\\]\nThat is, we can compute the CDF by integrating the PDF.\nBy subtraction, we can also use the PDF to compute probabilities of intervals.\n\n\\[\\begin{align*}\n\\P(a \\leq X \\leq b) &= \\P(X \\leq b) - \\P(X \\leq a) \\\\\n                    &= \\int_{-\\infty}^b f_X(x)\\,\\text{d}x - \\int_{-\\infty}^a f_X(x)\\,\\text{d}x \\\\\n                    &= \\int_{a}^b f_X(x)\\,\\text{d}x\n\\end{align*}\\]\nOf course, if we take \\(a = b\\) and attempt to compute \\(\\P(a \\leq X \\leq a) = \\P(X = a)\\), we get \\(\\int_a^a f_X(x)\\,\\text{d}x\\). By convention, this is taken to be 0, consistent with our argument that “exact equality” must have probability 0 if we insist on putting a probability on it.5\n\n\nExpectations and Moments\nIf you stare at the discussion above for a bit, you might notice an interesting way to rewrite our key integrals:\n\\[\\P(a \\leq X \\leq b) = \\int_a^b f_X(x)\\, \\text{d}x  = \\int_{-\\infty}^{\\infty} 1_{x \\in [a, b]}(x)\\, f_X(x)\\,\\text{d}x\\] That is, rather than using bounds on our integral, we can use an indicator function. Because the indicator function is 0 outside of the range of interest, this implicitly focuses the integral only on the interval \\([a, b]\\) without requiring us to keep track of bounds. We also recall that the probability of any event can be written as the expectation of the relevant indicator function:\n\\[ \\E[1_{X \\in [a, b]}] = \\int_{-\\infty}^{\\infty} 1_{x \\in [a, b]}(x)\\,f_X(x)\\,\\text{d}x\\]\nFrom this, it’s not too big a leap to argue that expectations in general can be written as:\n\\[ \\E[h(X)] = \\int_{-\\infty}^{\\infty} h(x) f(x)\\,\\text{d}x \\]\nIndeed, we take the case of \\(h(x) = x\\) to define the “plain” expectation:\n\\[ \\E[X] = \\int_{-\\infty}^{\\infty} x\\, f(x)\\,\\text{d}x \\]\nStepping back, we see that - as far as expectations are concerned - the only shift from discrete to continuous is to replace the sum with an integral. If we recall the standard motivation of the integral as a “infinite sum of infinitely small things”, this doesn’t feel too implausible.\n\n\n\n\n\n\nTip\n\n\n\nFor practice, convince yourself that all our formulas for expectations and variances hold in the continuous case as well.\n\n\n\n\nConditional Distributions of Continuous Random Variables\nThe “conditioning” rules for continuous random variables parallel their discrete counterparts:\n\\[ f_{Y | X}(y, x) = \\frac{f_{Y, X}(y, x)}{f_X(x)} \\]\nBecause of this, the rules of conditional expectations and variances translate to the continuous case with only the standard “sum to integral” substitution.\n\n\nMixture Distributions and Classification\nA particularly important family of discrete-continuous distributions is the set of mixtures. Given a Bernoulli RV \\(Z\\) and two continuous RVs \\(X_1, X_2\\), the derived RV\n\\[ X = Z X_1 + (1-Z) X_2 \\]\ncan be seen to be continuous as well, despite its ‘discrete input’ Z. (Why?)\nSuch distributions arise commonly in the modeling of classification problems.\nWe can derive the CDF of \\(X\\) quite easily:\n\\[\\begin{align*}\nF_X(x) &= \\P(X \\leq x) \\\\\n       &= \\P(Z X_1 + (1-Z) X_2 \\leq x) \\\\\n       &= \\P(Z X_1 + (1-Z) X_2 \\leq x | Z = 0)\\P(Z = 0) + \\P(Z X_1 + (1-Z) X_2 \\leq x | Z = 1)\\P(Z = 1)\\\\\n       &= \\P(X_2 \\leq x)\\P(Z = 0) + \\P(X_1\\leq x)\\P(Z = 1)\\\\\n       &= F_{X_2}(x)(1-p) + F_{X_1}(x)p\n\\end{align*}\\]\nIt’s not hard to show that this defines a valid CDF. Differentiating with respect to \\(x\\), we can also see that the PDF is given by:\n\\[ f_X(x) = f_{X_1}(x) * p + f_{X_2}(x) * (1-p) \\]\nFrequently, we will observe \\(X\\) and want to know whether \\(Z = 0\\) or \\(Z = 1\\)? If the supports of \\(X_1, X_2\\) are overlapping, we cannot be certain, but we can use Bayes’ rule:\n\\[\\begin{align*}\n\\P(Z = 0 | X = x) &= \\frac{\\P(X = x | Z = 0)\\P(Z = 0)}{\\P(X = x)}\n\\end{align*}\\]\nHere, we can mix PMFs and PDFs at will within our Bayes’ rule calculation.6 This gives us:\n\\[\\begin{align*}\n\\P(Z = 0 | X = x) &= \\frac{\\P(X = x | Z = 0)\\P(Z = 0)}{\\P(X = x)} \\\\\n                  &= \\frac{f_X(X = x | Z = 0)\\P(Z = 0)}{f_X(X = x)} \\\\\n                  &= \\frac{f_{X_1}(x) * p}{f_{X_1}(x) * p + f_{X_2}(x) * (1-p)}\n\\end{align*}\\]\nThis type of rule gives rise to a generative classifier in Machine Learning. I have also recently used this type of logic to give probabilities of certain climate drivers giving observed data."
  },
  {
    "objectID": "notes/continuous_rvs.html#important-continuous-distributions",
    "href": "notes/continuous_rvs.html#important-continuous-distributions",
    "title": "Continuous Random Variables",
    "section": "Important Continuous Distributions",
    "text": "Important Continuous Distributions\nUnlike discrete random variables - which can mainly be built out of increasingly arcane combinations of Bernoulli random variables -\n\nContinuous Uniform Distribution"
  },
  {
    "objectID": "notes/continuous_rvs.html#footnotes",
    "href": "notes/continuous_rvs.html#footnotes",
    "title": "Continuous Random Variables",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWe let ourselves be a bit sloppier and talk about outcomes for random variables, \\(\\P(X = x)\\). If we had been properly rigorous throughout, we should have spoken only of the “atomic” event \\(\\P(\\{X = x\\})\\), but it’s customary to equate a single outcome with the event containing only that outcome.↩︎\nYou might recognize this discussion as having a “how many angels can dance on the head of a pin?” flavor. You would not be wrong to note such a similarity.↩︎\nIn this course, we take random variables to be real-valued and disallow \\(\\pm\\infty\\) as valid values. It’s not too much harder to allow extended real-valued variables, but it’s generally not worth the effort.↩︎\nIt is of course possible to have mixed discrete-continuous random variables. These are most commonly needed in survival analysis. Consider, e.g., how long a patient survives in a medical trial of 5 years. All amounts between 0 and 5 are valid (continuous) but there’s also a “chunk” of probability at “5 or more”. Here the underlying measurement (future lifetime) is arguably continuous, but our observations thereof have a mixed discrete-continuous flavor. In this course, we’ll mainly stay away from this sort of mixed discrete-continuous structure.↩︎\nThis is perhaps as good a place to note that we essentially always choose \\(\\mathcal{E}\\) to contain all intervals of the form \\((-\\infty, x]\\) so that \\(F_X(\\cdot)\\) can always be computed. The smallest \\(\\mathcal{E}\\) that allows this is the so-called “Borel \\(\\sigma\\)-algebra on \\(\\mathbb{R}\\) and it is the nigh-universal default in the study of random variables. Now that you have read this footnote, you can immediately forget it, because you will never encounter a fundamentally different choice of \\(\\mathcal{E}\\) in this course.↩︎\nIt’s actually a bit hard to show that this works formally, but we don’t worry about such things in this course.↩︎"
  },
  {
    "objectID": "notes/discrete_distributions.html",
    "href": "notes/discrete_distributions.html",
    "title": "Key Discrete Distributions",
    "section": "",
    "text": "\\[\\newcommand{\\P}{\\mathbb{P}} \\newcommand{\\E}{\\mathbb{E}} \\newcommand{\\V}{\\mathbb{V}}\\]\nIn this set of notes, we introduce the key discrete distributions:\nOur focus in this set of notes is defining the formal properties of each distribution. Our discussion in class will focus more on the “when and why?” questions dictating when we should use a particular distribution."
  },
  {
    "objectID": "notes/discrete_distributions.html#review-random-variables-mean-and-variance",
    "href": "notes/discrete_distributions.html#review-random-variables-mean-and-variance",
    "title": "Key Discrete Distributions",
    "section": "Review: Random Variables, Mean, and Variance",
    "text": "Review: Random Variables, Mean, and Variance\nRecall that a random variable, \\(X\\), is functionally specified by two components:\n\nThe support of \\(X\\) is the set of values \\(X\\) can take, encoded as real numbers. In the discrete random variable context, the support of \\(X\\) is typically integral: \\(\\textsf{supp}(X) \\subseteq \\mathbb{Z}\\)\nThe probability mass function (PMF) of \\(X\\) which is a mapping from \\(\\textsf{supp}(X)\\) to \\([0, 1]\\) satisfying: \\[ \\sum_{x \\in \\textsf{supp}(X)} \\P(X = x) = 1\\]\n\nAlongside these two defining quantities, we often report the mean (or expected value) and variance of a random variable:\n\\[\\begin{align*}\n\\E[X] &= \\sum_{x \\in \\textsf{supp}(X)} x\\, \\P(X = x) \\\\\n\\V[X] &= \\E[(X - \\E[X])^2] \\\\\n      &= \\sum_{x \\in \\textsf{supp}(X)} (x - \\E[X])^, \\P(X = x) \\\\\n      &= \\left(\\sum_{x \\in \\textsf{supp}(X)} x^2\\, \\P(X = x)\\right) - \\E[X]^2 \\\\\n      &= \\E[X^2] - \\E[X]^2\n\\end{align*}\\]\nRecall that the variance \\(\\V[X]\\) is always non-negative and is strictly positive if \\(|\\textsf{supp}(X)| \\geq 2\\) - that is, if \\(X\\) is “truly” random in the sense of possibly taking more than one value.1"
  },
  {
    "objectID": "notes/discrete_distributions.html#bernoulli",
    "href": "notes/discrete_distributions.html#bernoulli",
    "title": "Key Discrete Distributions",
    "section": "Bernoulli",
    "text": "Bernoulli\nOur simplest distribution is the Bernoulli distribution, named after the great Swiss mathematician Jacob Bernoulli. The Bernoulli distribution models a single “coin flip”-type event: that is, an event with two possible outcomes conventionally called “success” and “failure”. To make this a random variable, we associate “success” with the value \\(1\\) and “failure” with the value \\(0\\).\nNote that, even though we called these two outcomes “success” and “failure”, we can use a Bernoulli distribution for anything with two outcomes: left vs. right, up vs. down, right vs. wrong, or happened vs didn’t happen. These last two pairings are incredibly important. Whenever we make a binary prediction, it is either correct or incorrect - a Bernoulli outcome. Because of this, Bernoulli random variables are commonly used to study the predictive accuracy of classification systems, an incredibly important topic in Machine Learning. Bernoulli distributions are also “the most extreme” version of bounded random variables (putting all of the probability on two endpoints) so we can often bound the performance of any predictive model for bounded outcomes using Bernoulli variables.\nA Bernoulli distributed \\(X\\) is then defined by the PMF:\n\\[ P(X = 1) = p \\text{ and } P(X = 0) = 1 - P(X \\neq 0) = 1 - P(X = 1) = 1 - p = q \\]\n\n\n\n\n\n\nTip\n\n\n\nMake sure you can explicitly justify each step connecting \\(P(X = 0)\\) to \\(1 - p\\).\n\n\nIf we are clever - and recall that \\(p^0 = 1\\) for any \\(p \\neq 0\\)-we can write the Bernoulli PMF as\n\\[ \\P(X = x) = p^x(1-p)^{1-x} = p^xq^{1-x} \\text{ for } x \\in \\{0, 1\\}\\]\nNote that, even though we sometimes write the Bernoulli with two parameters, \\(p,q\\), it is really a one-parameter distribution since \\(q = 1 - p\\) by construction.\nThe mean and variance are quite easy to calculate:\n\\[\\begin{align*}\n\\E[X] &= \\sum_{x \\in \\textsf{supp}(X)} x * \\P(X = x) \\\\\n      &= 0 * \\P(X = 0) + 1 * \\P(X = 1) \\\\\n      &= 0 * (1 - p) + 1 * p \\\\\n      &= p\n\\end{align*}\\]\n\n\n\n\n\n\nTip\n\n\n\nWhy are we not surprised to see “expectation = probability” here? Think about the connection between Bernoulli random variables and indicator functions.\n\n\nWhile we can compute the variance directly, it’s a bit easier to work from \\(\\V[X] = \\E[X^2] - \\E[X]^2\\) if we note that \\(X^2 = X\\) for a Bernoulli random variable.\n\\[\\begin{align*}\n\\V[X] &= \\E[X^2] - \\E[X]^2 \\\\\n      &= \\E[X] - \\E[X^2] \\\\\n      &= p - p^2 \\\\\n      &= p(1 - p) \\\\\n      &= pq\n\\end{align*}\\]\nFrom this expression, it’s not hard to see that the variance of a Bernoulli random variable is never more than \\(0.25\\) and that the maximum is obtained when \\(p = q = 0.5\\): that is, the “50/50” coin-flip is the “most random” coin."
  },
  {
    "objectID": "notes/discrete_distributions.html#rademacher",
    "href": "notes/discrete_distributions.html#rademacher",
    "title": "Key Discrete Distributions",
    "section": "Rademacher",
    "text": "Rademacher\nA Rademacher variable is a close cousin of the Bernoulli often used to model incremental processes that, at each step, either become “a bit better” or “a bit worse”. Specifically, while a Bernoulli is a 0/1 random variable, Rademachers take values \\(\\pm 1\\).\n\\[P(X = x) = \\begin{cases} 1 & \\text{ with probability } p \\\\ 0 & \\text{ with probability } q = 1 - p \\end{cases}\\]\nWhile Bernoulli variables come with all sorts of weights, Rademachers are normally symmetric, taking \\(\\pm 1\\) with equal 50% probability.\nTo get the mean and variance of a Rademacher, let’s use the linearity of expectation. Let \\(R \\sim \\text{Rademacher}(p)\\); then \\(R = 2B - 1\\) where \\(B \\sim \\text{Bernoulli}(p)\\). Hence,\n\\[\\begin{align*}\n\\E[R] &= \\E[2B - 1] \\\\\n      &= 2\\E[B] - 1 \\\\\n      &= 2p - 1\n\\end{align*}\\]\nSimilarly,\n\\[\\begin{align*}\n\\V[R] &= \\V[2B - 1] \\\\\n      &= 2^2 \\V[B] \\\\\n      &= 4 * p * (1-p) \\\\\n      &= 4pq\n\\end{align*}\\]\nAs before, this is “most random” when \\(p = q = 0.5\\). In this case, however we get a variance of 1 for \\(R\\) instead of \\(0.25\\) for \\(B\\). Tricks like this make Rademachers very useful in theoretical analyses."
  },
  {
    "objectID": "notes/discrete_distributions.html#binomial",
    "href": "notes/discrete_distributions.html#binomial",
    "title": "Key Discrete Distributions",
    "section": "Binomial",
    "text": "Binomial\nThe Binomial distribution arises as the sum of a known, fixed number of \\(n\\) identically and independently distributed (IID) Bernoulli random variables. This concept of IID is incredibly important and we will see it many times throughout this course.\nBecause a binomial is a sum if IID elements, its mean and variance are relatively simple to compute. Let \\(X \\sim \\text{Binomial}(n, p)\\) - that is, let \\(X\\) be the sum of \\(n\\) \\(\\text{Bernoulli}(p)\\) random variables, \\(X_1, X_2, \\dots, X_n\\). Then\n\\[\\begin{align*}\n\\E[X] &= \\E\\left[\\sum_{i=1}^n X_i\\right] \\\\\n      &= \\sum_{i=1}^n \\E[X_i] \\text{ by linearity of expectation} \\\\\n      &= \\sum_{i=1}^n p \\\\\n      &= np\n\\end{align*}\\]\nSimilarly,\n\\[\\begin{align*}\n\\V[X] &= \\V\\left[\\sum_{i=1}^n X_i\\right] \\\\\n      &= \\sum_{i=1}^n \\V[X_i] \\text{ (Variances add for independent RVs)}\\\\\n      &= \\sum_{i=1}^n p(1-p) \\\\\n      &= n p(1-p)\n\\end{align*}\\]\nWhile the mean and variance are quite easy, it’s a bit trickier to derive the PMF from first principles. This is an important element of “probability thinking” - it is often easier to compute aspects of distributions indirectly instead of computing the distribution in toto and then deriving its properties. In particular, when you can break a problem into a set of IID elements - as we have done here - tools like linearity, expectation, and variance make life quite easy.\nSuppose we want to compute \\(\\P(X = x)\\). We know that we must have \\(x\\) successes and \\(n - x\\) failures for a sum of \\(x\\). The probability of the event\n\\[\\P\\left[(X_1, X_2, \\dots, X_n) = (\\underbrace{1, 1, \\dots, 1}_{\\text{$x$ times}}, \\underbrace{0, 0, \\dots, 0}_{\\text{$n-x$ times}})\\right]\\]\ncan be computed by independence of the individual Bernoullis:\n\\[\\begin{align*}\n\\P\\left[(X_1, X_2, \\dots, X_n) = (\\underbrace{1, 1, \\dots, 1}_{\\text{$x$ times}}, \\underbrace{0, 0, \\dots, 0}_{\\text{$n-x$ times}})\\right] &= \\prod_{i=1}^n P(X_i = x_i) \\\\\n&= \\prod_{i=1}^x \\P(X_i = 1) * \\prod_{i=x+1}^{n} \\P(X_i = 0) \\\\\n&=  \\prod_{i=1}^x p * \\prod_{i=x+1}^{n} (1-p) \\\\\n&= p^x (1-p)^{n-x}\n\\end{align*}\\]\nBut \\(\\P(X = x)\\) is not just this particular ordering of \\((X_1, \\dots, X_n)\\). For purposes of the Binomial random variable, we don’t really care what order these happened, so we have \\(\\binom{n}{x}\\) possible orderings (of \\(n\\) flips, choosing \\(x\\) of them to be 1). Because the set of possible orderings is a disjoint partition, we can get the aggregate probability \\(\\P(X = x)\\) by multipling \\(\\binom{n}{x}\\) by the probability of each outcome, which we already showed was \\(p^x(1-p)^{n-x}\\). Taken together, this gives us:\n\\[\\P(X = x) = \\binom{n}{x}p^x(1-p)^x \\text{ for } x \\in \\{0, \\dots, n\\}\\]\nWe pause here to note that the name binomial distribution comes from the similarity between this PMF and the standard binomial expansion:\n\\[(a + b)^n = \\sum_{x=0}^n \\binom{n}{x} a^xb^{n-x} \\]\nWe get the binomial distribution by setting \\(a = p, b = 1 - p\\). This lets us easily confirm that the sum of the binomial PMF is indeed 1, as we require: \\[\\begin{align*}\n\\sum_{x = 0}^n \\P(X = x) &= \\sum_{x=0}^n \\binom{n}{x}p^x(1-p)^x \\\\\n&= (p + (1-p))^n \\\\\n&= 1^n \\\\\n&= 1\n\\end{align*}\\]"
  },
  {
    "objectID": "notes/discrete_distributions.html#poisson",
    "href": "notes/discrete_distributions.html#poisson",
    "title": "Key Discrete Distributions",
    "section": "Poisson",
    "text": "Poisson\nThe Binomial distribution occurs with a fixed number of events \\(n\\) and known probability \\(p\\). An important ‘limiting’ case is where the number of events is very large and the probability is very small; in this case, the important number is the expected number of successes \\(\\mu = n * p\\). We model this case as a Poisson random variable. Specifically, a Poisson model is a model for count values that are, on average, reasonably small (around \\(\\mu\\)) but potentially unbounded.\nThe Poisson PMF with mean \\(\\mu\\) is given by \\[\\P(X = k) \\frac{\\mu^k e^{-\\mu}}{k!} \\text{ for } k \\in \\{0, 1, 2 \\dots, \\} \\]\nAs we have discussed before, factorials grow even more rapidly than exponentials, so this tends towards zero as \\(k\\) gets large: that is, very large counts become exceedingly unlikely. You can derive the Poisson PMF from the binomial PMF by setting \\(p = \\mu / n\\) and taking the \\(n \\to \\infty\\) limit, but the arithmetic is a bit cumbersome and so we do not pursue it here.\nWhile we have already called \\(\\mu\\), the Poisson mean, we can show this explicitly:\n\\[\\begin{align*}\n\\E[X] &= \\sum_{x=0}^{\\infty} x \\P(X = x) \\\\\n      &= \\sum_{x=0}^{\\infty} x * \\frac{\\mu^x e^{-\\mu}}{x!} \\\\\n      &= \\sum_{x=1}^{\\infty} x * \\frac{\\mu^x e^{-\\mu}}{x!} \\\\\n      &= e^{-\\mu} \\sum_{x=1}^{\\infty} x * \\frac{\\mu^x}{x!} \\\\\n      &= e^{-\\mu} \\mu \\sum_{x=1}^{\\infty} \\frac{\\mu^{x-1}}{(x-1)!} \\\\\n      &= e^{-\\mu} \\mu \\sum_{y=0}^{\\infty} \\frac{\\mu^{y}}{y!} \\\\\n      &= e^{-\\mu} \\mu e^{\\mu} \\\\\n      &= \\mu\n\\end{align*}\n\\]\nNext, we turn to the variance. As similar argument shows \\(\\E[X^2] = \\mu^2 + \\mu\\), so we get \\(\\V[X] = \\E[X^2] - \\E[X]^2 = \\mu^2 + \\mu - \\mu^2 = \\mu\\).\nThis is a remarkable property: for a Poisson random variable, a single parameter controls both the mean and the variance. Further more, as the expected number of counts becomes larger, so does the variance.\nIf we think back to the binomial connection, we can see how this arises: the binomial variance is given by \\(n p q = np(1-p) = np - np^2\\). We create a Poisson limit by setting \\(p = \\mu / n\\) and letting \\(n \\to \\infty\\). Here, this yields:\n\\[np - np^2 = n * \\left(\\frac{\\mu}{n}\\right) - n* \\left(\\frac{\\mu}{n}\\right)^2 = \\mu - \\mu^2 / n\\].\nAs \\(n \\to \\infty\\), we simply get the variance \\(\\mu\\) which matches direct calculation. At a high level, for the Poisson mean to get larger, we need \\(p\\) to get larger, which in turn raises the variance (since we are far below the ‘turning point’ of binomial variance at \\(p = 0.5\\))."
  },
  {
    "objectID": "notes/discrete_distributions.html#geometric",
    "href": "notes/discrete_distributions.html#geometric",
    "title": "Key Discrete Distributions",
    "section": "Geometric",
    "text": "Geometric\nSo far, we have considered distributions that count the number of times “success” happens out of a fixed number of trials. We now turn to distributions with a fixed number of successes, but a random number of total trials. In these models, the random variable of interest is the total number of trials.2\nOur basic model is the geometric distribution. The total number of coin flips until we get our first heads (inclusive. If we denote this variable as \\(X\\), we can easily see that the PMF is given by:\n\\[\\P(X = x) = p(1-p)^{x-1} \\text{ for } x \\in \\{1, 2, \\dots\\}\\]\nThis PMF arises because we don’t need to account for order: we know the last flip is a success with probability \\(p\\) and the previous \\(x-1\\) flips are each failures, occurring with probability \\(q = 1-p\\). By independence, these probabilities can be combined with simple multiplication, giving the resulting PMF.\nMean and variance can be computed in many ways. Here, we’ll show a general approach that uses differentiation and geometric series creatively to compute several useful quantities in the same manner.\nRecall that a geometric series satisfies:\n\\[\\sum_{i=0}^{\\infty} ar^i = \\frac{a}{1-r}\\]\nWe can differentiate both sides of this with respect to \\(r\\) to find:\n\\[\\begin{align*}\n\\sum_{i=0}^{\\infty} ar^i &= \\frac{a}{1-r} \\\\\n\\frac{\\text{d}}{\\text{d}r}\\sum_{i=0}^{\\infty} ar^i &= \\frac{\\text{d}}{\\text{d}r}\\frac{a}{1-r} \\\\\n\\sum_{i=0}^{\\infty} air^{i-1} &= \\frac{a}{(1-r)^2} * (-1) * (-1)\\\\\n\\sum_{i=0}^{\\infty} air^{i-1} &= \\frac{a}{(1-r)^2}\n\\end{align*}\\]\nwhere the right hand side picks up two \\(-1\\) terms: one from the exponent on the denominator and one from the minus sign inside the denominator (chain rule).\nWe can repeat this trick again:\n\\[\\begin{align*}\n\\sum_{i=0}^{\\infty} air^{i-1} &= \\frac{a}{(1-r)^2} \\\\\n\\frac{\\text{d}}{\\text{d}r}\\sum_{i=0}^{\\infty} air^{i-1} &= \\frac{\\text{d}}{\\text{d}r}\\frac{a}{(1-r)^2} \\\\\n\\sum_{i=0}^{\\infty} ai(i-1)r^{i-2} &= \\frac{2a}{(1-r)^3}\n\\end{align*}\\]\nWith these three formulae in hand, we are ready to show the basic properties of a geometric random variable:\n\\[\\begin{align*}\n\\sum_{x=1}^{\\infty} \\P(X = x) &= \\sum_{x=1}^{\\infty} p(1-p)^{x-1} \\\\\n                              &= \\sum_{y=0}^{\\infty} p(1-p)^y \\\\\n                              &= \\frac{p}{1-(1-p)} \\\\\n                              &= 1\n\\end{align*}\\]\nwhere we used only the “basic” geometric series formula here.\nNext, for expectation:\n\\[\\begin{align*}\n\\E[X] &= \\sum_{x=1}^{\\infty} x \\P(X = x) \\\\\n      &= \\sum_{x=1}^{\\infty} x p(1-p)^{x-1} \\\\\n      &= \\frac{p}{(1-(1-p))^2} \\\\\n      &= \\frac{p}{p^2} \\\\\n      &= \\frac{1}{p}\n\\end{align*}\\]\nwhere we used our first differentiated formula. This fits our intuition: if something happens \\(p\\) times, we need \\(1/p\\) tries for it to happen on average.\nSimilarly, the second differentiated formula can be used to compute \\(\\E[X(X-1)] = \\E[X^2] - \\E[X]\\) and from there, \\(\\V[X]\\) = $. Again, comparing against intuition, variance is highest for small \\(p\\) - if something is very rare, it’s very hard to say how long until it happens.\nThe geometric distribution has a remarkable property called memorylessness: \\(P(X &gt; m + n | X &gt; n) = P(X &gt; m)\\). This says that, if you have already tried \\(n\\) times, the probability of taking \\(m + n\\) tries is the same as \\(m\\) tries if starting afresh. The coin flip process is “memoryless” in that it doesn’t remember or depend upon what came before. Because of the memorylessness property, we can never say a success is “due up” in a geometric process. This is at stark odds with our intuition about gambling - if something hasn’t happened for a while, it’s bound to happen. If the events are truly IID, this simply isn’t the case.\nMemorylessness is a bit magic: the geometric distribution (and its close kin) is actually the only discrete distribution with this property. The other famous distribution with this property is the (continuous) exponential distribution, which has the same negative exponential structure. For this reason, the geometric distribution is sometimes called the discrete exponential distribution, though that name has mainly fallen out of paper.\nTo show memorylessness, we can use some of our basic principles of conditional PMFs. Before doing so, let’s define some useful alternative formulations of the PMF.\n\nThe CDF - cumulative distribution function - is \\[F(x) = \\P(X \\leq x) = \\sum_{i=1}^{x} \\P(X = x)\\]\nThe CCDF - complementary CDF - is \\[\\overline{F}(x) = \\P(X &gt; x) = \\sum_{x+1}^{\\infty} \\P(X = x)\\]\n\nClearly, \\(F(x) + \\overline{F}(x) = 1\\) for all \\(x\\). With these in hand, it’s easy to state the manipulation formulas for “self-conditioned” random variables.\n\n\\(\\P(X = x | X \\leq x) = \\P(X = x) / F(x)\\)\n\\(\\P(X = x | X &gt; x) = \\P(X = x) / \\overline{F}(x)\\)\n\nWe will use the latter form for showing memorylessness of the geometric.\nFirst, note that\n\\[\\begin{align*}\nF(x) &= \\sum_{i=1}^x p(1-p)^{i-1}  \\\\\n     &= p \\sum_{j=0}^{x-1} (1-p)^j \\\\\n     &= p * \\frac{1-(1-p)^{x}}{1-(1-p)} \\\\\n     &= p * \\frac{1 - (1-p)^x}{p}\\\\\n     &= 1 - (1-p)^x\n\\end{align*}\\]\nusing the formula for a finite geometric series. From this, we have \\(\\overline{F}(x) = (1-p)^x\\). At this point, you should be realizing that things are likely to work out very nicely when dividing \\(\\P(X = x)\\) and \\(\\overline{F}(x)\\).\nHence, \\[\\begin{align*}\n\\P(X = x + y | X &gt; y) &= \\frac{\\P(X = x + y) }{\\overline{F}(y)} \\\\\n                      &= \\frac{p(1-p)^{x+y-1}}{(1-p)^x} \\\\\n                      &= p(1-p)^{y-1} \\\\\n                      &= P(Y = y)\n\\end{align*}\\] where \\(Y\\) is a “new” (restarted) random variable."
  },
  {
    "objectID": "notes/discrete_distributions.html#negative-binomial",
    "href": "notes/discrete_distributions.html#negative-binomial",
    "title": "Key Discrete Distributions",
    "section": "Negative Binomial",
    "text": "Negative Binomial\nTODO"
  },
  {
    "objectID": "notes/discrete_distributions.html#hypergeometric",
    "href": "notes/discrete_distributions.html#hypergeometric",
    "title": "Key Discrete Distributions",
    "section": "Hypergeometric",
    "text": "Hypergeometric\nTODO"
  },
  {
    "objectID": "notes/discrete_distributions.html#footnotes",
    "href": "notes/discrete_distributions.html#footnotes",
    "title": "Key Discrete Distributions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRecall that we sometimes consider constants, \\(a\\), as “degenerate” random variables satisfying \\(P(X = a) = 1\\) to make the statements of our theorems easier.↩︎\nUnfortunately, there are two conflicting conventions used for some of these distributions: some count the total number of trials (success + failure) while others count only the number of failures. This is not a hard change - it’s just a simple \\(+s\\) for \\(s\\) successes - but it makes comparing formulae from different references a bit inconvenient.↩︎"
  },
  {
    "objectID": "notes/tails.html",
    "href": "notes/tails.html",
    "title": "On Tails of Distributions and Implications for Statistical Inference",
    "section": "",
    "text": "\\[\\newcommand{\\P}{\\mathbb{P}} \\newcommand{\\E}{\\mathbb{E}} \\newcommand{\\V}{\\mathbb{V}}\\]\nIn this set of notes, we introduce the concepts of the “tails” of a distribution and discuss implications for statistical inference.\nThe discussion of distribution tails is typically dominated by talk of “fat” or “heavy” tails. Heavy-tailed models are particularly popular in post-2008 finance, for reasons we will discuss below, as they naturally allow “crash” behvaior. Before we turn to heavy-tails, however, we need to discuss “standard” tails and their implications for statistical inference.\nMuch of statistical theory is built on a foundation of “tail bounds”. Tail bounds give an upper bound on the probability of some random variable being greater than some quantity: a prototypical tail bound is something like “the probability of procedure \\(\\mathscr{P}\\) having error more than \\(\\delta\\) is less than \\(\\epsilon\\)”, where \\(\\delta\\) and \\(\\epsilon\\) are both some small numbers. For instance, a predictive model may guarantee that the probability of being off by more than 2 standard deviations is less than 5% or, equivalently, that 95% of observations will fall within \\(2\\sigma\\) of the predicted value. Tail bounds can also be used to build confidence intervals: a tail bound of the form “the probability that the CI doesn’t contain the true value is less than 5% under the null” is essentially the definition of a confidence interval. Here, the error is binary (0 vs 1) but the basic machinery still holds.\nIn all these cases, we are constructing some random variable - the procedure error - and hoping to guarantee that it’s not too large. Typically, the procedure error is a (not-too-complex) function of several independent sources of ‘noise’ or error. The output of the procedure is then itself random1, as is its error. Rather counterintuitively, even if the error is a function of many random components, the aggregate effect of that error is usually quite predictable. This is a phenomenon we’ll see in many forms throughout this course, so let’s begin to explore it properly."
  },
  {
    "objectID": "notes/tails.html#heavy-tails",
    "href": "notes/tails.html#heavy-tails",
    "title": "On Tails of Distributions and Implications for Statistical Inference",
    "section": "Heavy Tails",
    "text": "Heavy Tails\nSo far, life is good. We have nice bounds that decay rapidly and hold with only minimal assumptions on \\(X\\). Sample means and sample probabilities do exactly what we want them to and, without too much work, we expect we could apply our techniques to other quantities of interest like medians and quartiles. What could go wrong?\nThe law of large numbers tells us that, with enough data, the randomness “washes out” from a large sample. But what happens if the randomness is so wild that it can’t be washed out? The LLN fails to hold and we are in a dark and scary place. This is the domain of heavy-tailed monsters.\nThe most famous heavy-tailed distribution is the Cauchy distribution, named after the French mathematician Augustin-Louis Cauchy and pronounced either Co-shee or Cow-shee depending on the quality of your French accent. It has a rather benign PDF and CDF:\n\\[\\begin{align*}\nf_X(x) &= \\frac{1}{\\pi(1 + x^2)} \\\\\nF_X(x) &= \\frac{1}{\\pi}\\arctan(x) + \\frac{1}{2}\n\\end{align*}\\]\nGraphically, it looks quite similar to its normal distribution kin.\n\nx &lt;- seq(-5, 5, length.out=501)\nplot(x, dnorm(x), \n     type=\"l\", col=\"red4\", lwd=2, \n     xlab=\"x\", ylab=expression(f[X](x)), \n     main=\"Comparison of Normal (Red) and Cauchy (Green) PDFs\")\nlines(x, dcauchy(x), type=\"l\", col=\"green4\", lwd=2)\n\n\n\n\n\n\n\n\n\nx &lt;- seq(-5, 5, length.out=501)\nplot(x, pnorm(x), \n     type=\"l\", col=\"red4\", lwd=2, \n     xlab=\"x\", ylab=expression(f[X](x)), \n     main=\"Comparison of Normal (Red) and Cauchy (Green) CDFs\")\nlines(x, pcauchy(x), type=\"l\", col=\"green4\", lwd=2)\n\n\n\n\n\n\n\n\nEyeballing these graphs, we can see that the normal distribution has “more” mass near (\\(x\\) near 0) and the Cauchy has more mass in the tails (\\(x\\) far from 0), but the differences don’t appear that large.\nBut looks can deceive! The Cauchy distribution is quite a wild thing: it in fact fails to have an expected value. Mathematically, the integral\n\\[\\E_{X \\sim \\text{Cauchy}}[X] = \\int_{-\\infty}^{\\infty} \\frac{x}{\\pi(1+x^2)}\\,\\text{d}x\\]\nis ill-posed. To see this formally, note that the integrand is approximately \\(1/x\\) so the indefinite integral is \\(\\ln(x)\\) which goes to \\(\\infty\\).\nBut what does this actually mean? We first note that, if \\(\\E[X]\\) does not exist, neither does \\(\\V[X]\\).9 From our discussion above, this means we have no law of large numbers. It’s easiest to see the impact of this visually.\nLet’s start by simulating large numbers of normal random variables and plotting their cumulative means:\n\nn &lt;- 500\nr &lt;- 500\nXX &lt;- matrix(rnorm(n * r), nrow=r)\nXX &lt;- apply(XX, 2, dplyr::cummean)\nplot(1:n, XX[,1], type=\"n\", \n     xlab=\"n\", ylab=expression(bar(X[n])), \n     ylim = range(XX),\n     main=\"Law of Large Numbers - Normal Deviates\"\n)\nfor(i in 1:r){\n    lines(1:n, XX[,i], col=scales::alpha(\"blue2\",0.15))\n}\n\nlines(1:n, +1/sqrt(1:n), col=\"red4\", lty=2)\nlines(1:n, -1/sqrt(1:n), col=\"red4\", lty=2)\n\n\n\n\n\n\n\n\nHere, each line is a different ‘universe’ in which we observe \\(\\overline{X}_n\\) for different values of \\(n\\). For small values of \\(n\\) (left hand side of the figure), there is a large variance, but as \\(n \\to \\infty\\) and we move right, the variance washes out quickly. In fact, it washes out at a rate of \\(1/\\sqrt{n}\\) consistent with our theory for \\(\\sigma_{\\overline{X}_n} = \\sqrt{\\V[\\overline{X}_n]}\\).\nContrast this with the Cauchy distribution:\n\nn &lt;- 500\nr &lt;- 500\nXX &lt;- matrix(rcauchy(n * r), nrow=r)\nXX &lt;- apply(XX, 2, dplyr::cummean)\nplot(1:n, XX[,1], type=\"n\", \n     xlab=\"n\", ylab=expression(bar(X[n])), \n     ylim = range(XX),\n     main=\"Law of Large Numbers - Cauchy Deviates\"\n)\nfor(i in 1:r){\n    lines(1:n, XX[,i], col=scales::alpha(\"blue2\",0.15))\n}\n\nlines(1:n, +1/sqrt(1:n), col=\"red4\", lty=2)\nlines(1:n, -1/sqrt(1:n), col=\"red4\", lty=2)\n\n\n\n\n\n\n\n\nThere are occasional crazy large spikes which “blow up” the sample mean. These spikes are possible under any distribution with \\(\\mathbb{R}\\)-support, but they are common enough for the Cauchy that we ‘break’ the sample mean.\nThis is the essence of heavy tails. Heavy-tailed distributions are, in their purest form, distributions that are “so wild” they break the fundamental building blocks of statistics. Of course, not everything is doomed in the world of heavy tails - we can replace the sample mean with something like the sample median, which is more robust to these crazy spikes - but we have to tread much more carefully.\n\nWhence Heavy Tails?\nSo where do heavy tails come from? We discuss one example below, stock market returns, where heavy tails are a fundamental feature of the underlying data generating process. In the land of theory, however, it’s a bit harder to see what might give rise to heavy tails. But whenever we want to ‘break’ something in math, we have one ever useful standby - division by zero.\nSuppose we have two IID standard normal random variables \\(X, Y\\). What is the behavior of their ratio \\(Z = X / Y\\)? It turns out that \\(Z\\) has a Cauchy distribution! On some level, this makes sense: if \\(Y\\) is standard normal, it is “usually near 0” in some probabilistic sense, so we are “usually nearly dividing by 0”. While exact division by zero isn’t something we need to worry about for continuous \\(Y\\), we are close to division by 0 whenever \\(Y\\) is small. Diving deeper, we know that dividing by small numbers gives large numbers, so the probability \\(\\P(|Y| &lt; \\epsilon)\\) for some small \\(\\epsilon\\) essentially gives us the probability of very large terms showing up, \\(\\P(1/|Y| &gt; 1/\\epsilon)\\).\nConcisely, the Cauchy is “usually infinity” in the same way that the normal distribution is “usually zero”. Never exactly, but often enough for that to define its behavior.\nStepping back, this gives us point of caution in our actual statistical work. Be very cautious dividing by random variables, particularly if they have significant mass near zero. Even if you are lucky enough to never exactly divide by zero, you are probabilisticly close enough that things go horribly wrong. We will next discuss one circumstance in which this happens with some regularity.\n\n\nHeavy Tails in Finance\nSuppose that the price of a stock is given by \\(S_t\\) - here \\(S_t\\) is a random function, giving the price of the stock at any time \\(t\\). It is common to report the returns of investments in this stock over some time interval:\n\\[R_{t_1 \\to t_2} = \\frac{S_{t_2}}{S_{t_1}} - 1\\]\nIn more mathematical contexts, we instead use continuous or log returns to measure performance:\n\\[R_{t_1 \\to t_2} = \\log\\left(\\frac{S_{t_2}}{S_{t_1}}\\right)\\] For very small time intervals, \\(S_{t_2} \\approx S_{t_1}\\), and these quantities converge. Log returns are preferred in mathematiacl contexts because they aggregate nicely over time and you don’t have to worry about compounding effects.10\nRegardless of the return convention used, we see division by the random quantity \\(S_{t_1}\\) and the hair on the back of our head should stand up. In more economic terms, \\(S_t\\) can go to zero (or near zero) whenever a company enters bankruptcy. And that’s something that happens! Not every day to every company, but it’s certainly not unheard of.\nThe impact of bankruptcy is clearest in log-returns: when a stock goes to zero, it has a \\(-\\infty\\%\\) return: there’s simply no coming back from that, no matter how long and how regularly the stock otherwise goes up. Because of that possibility, the law of large numbers does not apply to individual stock returns. Single-stock investing, no matter how long a time frame, remains risky: no LLN guarantees kick in.\nWhile this is not a quantitative investing class, it’s also important to note that a multi-asset portfolio fails to have this issue unless there’s a real chance that every company in the portfolio goes backrupt at the same time. With multi-asset investment, we work instead with classical returns: even if half the portfolio goes to zero, the losses to the overall portfolio are capped at 50% and so things aren’t too heavy failed. (Note how this argument breaks down as you add leverage - your losses are no longer capped!)\nPortfolio diversification is a very good thing!"
  },
  {
    "objectID": "notes/tails.html#degrees-of-heaviness",
    "href": "notes/tails.html#degrees-of-heaviness",
    "title": "On Tails of Distributions and Implications for Statistical Inference",
    "section": "Degrees of Heaviness",
    "text": "Degrees of Heaviness\nSo far, we have discussed three distributions:\n\nBernoulli (indicators)\nNormal\nCauchy\n\nThese exist on a spectrum of “heavy-tailedness”.\nBounded random variables, like the Bernoulli, have the thinnest and nicest possible tails. After the end of their support, the PDF goes to zero and the tails vanish into nothingness.\nOn the other end, distributions like the Cauchy are about as heavy tailed as possible. Recall that a PDF has to integrate to 1. The family of Cauchy-like PDFs\n\\[f_X(x) = \\frac{a}{1+|x|^c} \\]\nonly integrate to \\(1\\) for \\(c &gt; 1\\). (Things blow up precisely at \\(c = 1\\).) So, while we could go a bit more tail-tastic than the Cauchy, taking \\(c = 1.5\\) or even \\(c = 1.1\\), things really can’t get any heavier before we fail to have a PDF at all. Put another way, if a distribution has tails too much heavier than a Cauchy, it’s not only too wild to have a mean, it’s too wild to even define a real distribution!\nBut there is a wide range of distributions between these two families, broadly those with ‘exponential decay’ tails. We have already seen the normal distribution which has ‘squared exponential’ tails: \\(f_X(x) \\propto e^{-x^2}\\). We can thicken these tails by removing the square, giving us the Laplace distribution $f_X(x) \\(e^{-|x|}\\). We can also ‘thin’ the normal tails further by increasing the exponent, giving even faster decay: \\(f_X(x) \\propto e^{-x^4}\\) or \\(f_X(x) \\propto e^{-x^6}\\). These distributions, generally known as “generalized normal” or “Subbotin” distributions, are less common, but have been applied in a few settings successfully.\n“Heavy tails” are not a totally distinct field of models - they are just the hardest, nastiest limits of normal behaviors that require us to rethink many of our basic assumptions. In general, if we’re worried about large deviations having large effects, we need to change our estimator to minimize the impact of a large value. Classically, tools like the sample median are used, but we also have Windsorized means, robust regression methods, etc. In more modern work, particularly “CS-heritage” machine learning theory, 0/1-classification problems take center stage and we can sidestep any discussion of heavy tails by only looking at indicator functions (right/wrong prediction), which have bounded tails by construction.\nUnfortunately, these tools often lack the nice properties we associated with means and expectations: notably, they do not play quite as well with differentiation. But that’s a story for another course.\nAs we progress in this course, we won’t see too much more about heavy-tailed random variables. Our goal is to learn all the probability necessary for classical (mean-oriented) statistics and machine learning. But it’s always good to keep the Cauchy in the back of your mind: it’s easy to worth with, but it still breaks nearly everything. Whenever we claim a new result or discuss a phenomenon, test it against a Cauchy - does it need an LLN to work? Is there a transformation we can apply to our random variable to guarantee an LLN holds? This will help sharpen your intuition for when the “standard” guarantees of probability hold and when they fail."
  },
  {
    "objectID": "notes/tails.html#footnotes",
    "href": "notes/tails.html#footnotes",
    "title": "On Tails of Distributions and Implications for Statistical Inference",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRecall the “Random In, Random Out” principle.↩︎\nRecall that “probability-mode” thinking is ‘forward’–given a distributional model, what predictions can I make about future observations–while “statistics-mode” thinking is ‘backwards’–given some observational data, what can I infer about the distribution of the underlying population? Statistical theory blends both of these since we need to think “forward” to figure out a procedure that will reliably work “backwards”, but statistical practice is looking from finite data to distribution.↩︎\nUltra-pedantically, this is actually a series of estimators, \\(\\textsf{MEAN}_1(X_1)\\), \\(\\textsf{MEAN}_2(X_1, X_2)\\), \\(\\dots\\), but even I’m not sufficiently obnoxious to dwell on this point except in the vanishingly rare circumstances where it matters.↩︎\nThis use of “bias” is not (necessarily) related to concepts like prejudice. It’s the older meaning that still comes up in idioms like “cut on a bias” as opposed to “cut straight” in carving meat. See Wikipedia for more discussion.↩︎\nLater in this course, we will discuss the decomposition of error for biased estimators.↩︎\nThe mathematically minded reader might note that we have not specified the type of convergence here. More precisely, what exactly does it mean for a random quantity \\(\\overline{X}_n\\) to converge to a non-random quantity like \\(\\mu_X\\)? From our discussion of continuous random variables, we know that \\(\\P(\\overline{X}_n = \\mu_X)\\) is either zero or ill-defined, so something more subtle is at play here. In fact, there are actual several different “modes of convergence” we could use here; each gives rise to a different Laws of Large Numbers. We will not worry about such distinctions in this course.↩︎\nLike so many things in the history of science, Markov’s Inequality is not named after its original discoverer, Pafnuty Chebyshev, but rather his student, Andrey Markov. See Stigler’s Law of Eponomy for an exhaustive discussion of this cruel phenomenon.↩︎\nWe can also estimate \\(\\sigma_X\\) from the data, but it makes the math just a bit more cumbersome, so we’ll hold off on it for now.↩︎\nIn general, \\(\\E[X^p] \\text{ exists } \\implies \\E[X^q]\n\\text{ exists for } p &gt; q\\))↩︎\nStandard returns aggregate nicely “across assets”, so a portfolio that is 50% stock A and 50% stock B will have the average (standard) return of A and B. Log returns do not satisfy this property. Conversely, a stock that has a log return of 10% followed by another log return of -10% is unchanged; a stock that has a classical return of 10%, followed by a classical return of -10%, is still down 1%. Both conventions are useful - it just depends which direction you “aggregate” more frequently. Classically, mathematical finance is more concerned with modelling one or two assets over a lot of very short intervals, preferring log returns, but multi-asset portfolio modeling is increasingly important, particularly in risk management contexts, and is more suited for classical returns.↩︎"
  },
  {
    "objectID": "objectives.html",
    "href": "objectives.html",
    "title": "STA 9715 - Course Learning Objectives",
    "section": "",
    "text": "This course provides a comprehensive introduction to applied probability and probability distributions. Students will learn probability with an understanding of its applications in statistical inference. Topics include discrete and continuous random variables and distributions, such as the binomial, negative binomial, Poisson, geometric, uniform, normal, exponential, gamma (\\(\\Gamma\\)), beta (\\(B\\)), chi-square (\\(\\chi^2\\)), \\(t\\), and \\(F\\) distributions. This course thoroughly develops topics as transformation of variables, joint distributions, bivariate normal, expectations, conditional distributions and expectations, moment-generating functions, distribution of sums of random variables, means and variances of sums, ratios of independent variables, and central limit theorem. Students will acquire an excellent background to proceed to statistical inference."
  },
  {
    "objectID": "objectives.html#official-course-description",
    "href": "objectives.html#official-course-description",
    "title": "STA 9715 - Course Learning Objectives",
    "section": "",
    "text": "This course provides a comprehensive introduction to applied probability and probability distributions. Students will learn probability with an understanding of its applications in statistical inference. Topics include discrete and continuous random variables and distributions, such as the binomial, negative binomial, Poisson, geometric, uniform, normal, exponential, gamma (\\(\\Gamma\\)), beta (\\(B\\)), chi-square (\\(\\chi^2\\)), \\(t\\), and \\(F\\) distributions. This course thoroughly develops topics as transformation of variables, joint distributions, bivariate normal, expectations, conditional distributions and expectations, moment-generating functions, distribution of sums of random variables, means and variances of sums, ratios of independent variables, and central limit theorem. Students will acquire an excellent background to proceed to statistical inference."
  },
  {
    "objectID": "objectives.html#course-learning-objectives",
    "href": "objectives.html#course-learning-objectives",
    "title": "STA 9715 - Course Learning Objectives",
    "section": "Course Learning Objectives",
    "text": "Course Learning Objectives\nStudents successfully completing STA 9715 will:\n\nDefine and manipulate probability mass and density, expectation, and variance for discrete and continuous random variables.\nDefine and manipulate conditional probability, expectation, and variance.\nDefine and manipulate important named probability distributions including, but not limited to, the normal distribution, uniform distribution, and \\(t\\)-distribution.\nManipulate collections of random variables, characterizing them in terms of covariance and correlation, and establishing properties of their limits and sums.\nDefine and manipulate concentration of measure phenomena including the central limit theorem.\n\nAdditionally, STA 9715 will review important mathematical concepts used elsewhere in the statistics curriculum.\nThe following course elements contribute to these goals:\n\nContribution of Course Elements to Learning Goals\n\n\n\n\n\n\n\n\n\n\nPractice Problems\nLearning Goal 1\nLearning Goal 2\nLearning Goal 3\nLearning Goal 4\nLearning Goal 5\n\n\n\n\nWeek 1\n✓\n\n\n\n\n\n\nWeek 2\n✓\n✓\n\n\n\n\n\nWeek 3\n✓\n\n✓\n\n\n\n\nWeek 4\n✓\n\n✓\n\n\n\n\nWeek 5\n✓\n✓\n✓\n\n\n\n\nWeek 6\n✓\n✓\n✓\n✓\n\n\n\nWeek 7\n✓\n✓\n✓\n✓\n\n\n\nWeek 8\n✓\n✓\n✓\n✓\n\n\n\nWeek 10\n✓\n✓\n✓\n✓\n✓\n\n\nWeek 11\n✓\n✓\n✓\n✓\n✓\n\n\nWeek 12\n✓\n✓\n✓\n✓\n✓\n\n\nWeek 13\n✓\n✓\n✓\n✓\n✓"
  },
  {
    "objectID": "objectives.html#program-learning-goals",
    "href": "objectives.html#program-learning-goals",
    "title": "STA 9715 - Course Learning Objectives",
    "section": "Program Learning Goals",
    "text": "Program Learning Goals\nThis course contributes to the program learning goals of several MS programs offered by the Zicklin School of Business.\n\nMS in Business Analytics\nThis course contributes to the following Program Learning Goals for the MS in Business Analytics:\n\nMSBA Program Learning Goals\n\n\n\n\n\n\n\nSTA 9715 Learning Goal\nMSBA Learning Goal\nDescription\n\n\n\n\n\nData Management\nStudents will be able to apply methods, tools, and software for acquiring, managing/storing, and accessing structured and unstructured data. Students will also demonstrate knowledge of the strategic uses of data.\n\n\n✓\nFoundational Statistical / Quantitative Skills\nStudents will be able to prepare data for statistical analysis, perform basic exploratory and descriptive analysis as well as employ foundational statistical techniques needed to analyze data.\n\n\n✓\nAdvanced Statistical/Quantitative Skills\nStudents will be able to build and interpret advanced predictive models. Students will be able to combine business rules and mathematical models to optimize business decisions from data.\n\n\n✓\nEthical Awareness\nStudents will be able to articulate an understanding of ethical issues in all phases of business analytics with particular emphasis on the new possibilities afforded by the emergence of big data.\n\n\n✓\nProfessional Communication\nStudents will be able to explain complex analytical models and their results orally and in writing to technical and non technical/lay audiences.\n\n\n\nKnowledge Integration\nStudents will be able to apply the three key types of analytics (descriptive, predictive, and prescriptive) in a business domain to add value to business decision-making.\n\n\n\n\n\nMS in Quantitative Methods & Modeling\nThis course contributes to the following Program Learning Goals for the MS in Quantitative Methods & Modeling:\n\nMSQMM Program Learning Goals\n\n\n\n\n\n\n\nSTA 9715 Learning Goal\nMSQMM Learning Goal\nDescription\n\n\n\n\n✓\nOperations Research & Mathematical Modeling\nStudents will be able to effectively model, evaluate, and solve quantitative (business) problems using quantitative modeling methods (e.g. deterministic and probabilistic operations research techniques).\n\n\n✓\nStatistics\nStudents will be able to correctly apply appropriate statistical methods when defining, solving, and analyzing problems.\n\n\n\nTechnology Competency\nStudents will be able to use current technological tools, including spreadsheets and specialized software, when solving problems.\n\n\n✓\nProfessional Communication\nStudents will be able to effectively communicate their problem solving methods and solutions to technical and non-technical audiences.\n\n\n\n\n\nMS in Statistics\nThis course contributes to the following Program Learning Goals for the MS in Statistics:\n\nMS Statistics Program Learning Goals\n\n\n\n\n\n\n\nSTA 9715 Learning Goal\nMS Stat Learning Goal\nDescription\n\n\n\n\n✓\nGeneral Statistical Competence\nStudents will be able to apply appropriate probability models and statistical techniques when analyzing problems frm business and other fields.\n\n\n✓\nStatistical Practice\nStudents will become familiar with the standard tools of statistical practice for multiple regression, along with the tools of a subset of specialized statistical areas such as multivariate analysis, applied sampling, time series analysis, experimental design, data mining, categorical analysis, and/or stochastic processes.\n\n\n\nTechnology Competency\nStudents will learn to use one or more of the benchmark statistical software platforms, such as SAS or R."
  },
  {
    "objectID": "notes.html",
    "href": "notes.html",
    "title": "STA 9715 - Notes",
    "section": "",
    "text": "Supplemental course notes will be posted here.\n\nWeek 1: Foundations of Probability\n\nQuanta Magazine: “Perplexing the Web, One Probability Puzzle at a Time”\nWIRED Magazine: “Statistician Answers Stats Questions From Twitter | Tech Support”\n\nMore Jeff Rosenthal\n\nHarvard STAT 110 Playlist\n\nThis is the course on which our textbook (BH) is based\n\n\n\n\nWeek 2: Conditionality and Marginality\n\nThe YouTube channel 3blue1brown makes excellent ‘explainers’ about a variety of mathematical topics. Check out his videos on Bayes’ rule:\n\nThe Geometry of Changing Beliefs\n\nSee also A Quick Proof of Bayes Theorem\n\nThe Medical Test Paradox\n\nConditioning: The Soul of Statistics\nNotes on Expectations\n\n\n\nWeek 3: Discrete Probability\n\nNotes on Discrete Distributions\n\n\n\nWeek 4: From Discrete to Continuous Random Variables\n\nNotes on Continuous Random Variables\n\n\n\nWeek 5: Heavy Tails\n\nNotes on Tails of Distributions and Implications for Statistical Inference\n\n\n\nWeek 6: Random Vectors\n\nNotes on Vectors\nQuanta Article on Probability Puzzles\n\n\n\nWeek 7: Covariance and Correlation\n\nNotes on Covariance\n\n\n\nWeek 8: The Multivariate Normal Distribution and its Progeny\n\n3Brown1Blue - “Why \\(pi\\) is in the Normal Distribution”\n3Brown1Blue - “A Pretty Reason why Gaussian + Gaussian = Gaussian”\n\n\n\nWeek 9: Probability, Polling, and Prediction\n\nHow the Washington Post Estimates Outstanding Votes for the 2020 Presidential Election\n\n\n\nWeek 10: Perils and Paradoxes in Expectations\n\n\nWeek 11: Probability Inequalities and Limit Theorems\n\n\nWeek 12: Distributional Limits and the Central Limit Theorem\n\n\nWeek 13: Concentration of Measure: Generalized Limit Theory\n\n\nWeek 14: Computing with Randomness\n\n\nExam Materials\n\nTest 1:\n\nFormula Sheet\nExam Packet\nSolutions"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 9715 - Applied Probability",
    "section": "",
    "text": "Welcome to the course website for STA 9715 (Fall 2024)!\nSTA 9715 is an Applied Probability course targeted at students in the MS in Business Analytics, MS in Statistics, and MS in Quantitative Methods programs.\nThis site hosts the unofficial Course Syllabus, Course Policies, and Course Learning Objectives. Official copies of these documents can be found on CUNY Blackboard. Additional course handouts can also be found on this site.\nInstructor: Michael Weylandt"
  },
  {
    "objectID": "notes/Test1/solutions.html",
    "href": "notes/Test1/solutions.html",
    "title": "STA 9715: Test 1 (Fall 2024) – Solutions",
    "section": "",
    "text": "\\[\\newcommand{\\P}{\\mathbb{P}} \\newcommand{\\E}{\\mathbb{E}} \\newcommand{\\V}{\\mathbb{V}}\\] The original exam packet can be found here.\n\nQuestion 1\nIn an MLB Divisional Series, two teams play a sequence of games against each other, and the first team to win three games wins the series. Let \\(p\\) the probability that Team A wins an individual game, and assume that the games are independent. What is the probability that A wins the series?\n\n\n\n\n\n\nQuestion History\n\n\n\n\n\nThis is essentially Question BH 3.12.18(a), with “best 4-of-7” changed to “best 3-of-5”.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe number of games won by Team A follows a Binomial distribution; specificically, let \\(X \\sim \\text{Binomial}(5, p)\\) be the number of games won by Team A. The probability that Team A wins the series is then given by sum of the probabilities that A wins 3 games, A wins 4 games, or A wins 5 games. Mathematically, \\[\\begin{align*}\n\\P(\\text{A wins}) &= \\P(\\text{A wins 3}) + \\P(\\text{A wins 4}) + \\P(\\text{A wins 5}) \\\\\n&= \\binom{5}{3}p^3(1-p)^2 + \\binom{5}{4}p^4(1-p)^1 + \\binom{5}{5}p^5(1-p)^0\n\\end{align*}\\] where the individual probabilities can be computed using the Binomial PMF supplied on the Formula Sheet.\nWe can can simplify this further to: \\[ 10p^3(1-p)^2 + 5p^4(1-p) + p^5\\] after some simplification, this becomes:\n\\[ 6p^5 - 15p^4 + 10p^3\\]\nWe can plot this against \\(p\\) to see how the game-win probability impacts the series-win probability \\(p\\).\n\np &lt;- seq(0, 1, length.out=101)\np_calculated &lt;- 6 * p^5 - 15 * p^4 + 10 * p^3\n\n# pbinom gives probability P(X &lt;= x) or P(X &gt; x) so\n# to get P(X &gt;= 3), let's just take P(X &gt; 2.9)\np_builtin &lt;- pbinom(2.9, 5, p, lower.tail=FALSE)\n\nplot(p, p_calculated, \n     type=\"l\", col=\"red4\", \n     xlab=\"Team A: Game Win Probability\", \n     ylab=\"Team A: Series Win Probability\",\n     main=\"Impact of Best-of-5 Series Structure\")\nlines(p, p_builtin, col=\"green4\")\nlegend(\"topleft\", \n       legend=c(\"Calculated Probability\", \n                \"R pbinom Probability\"), \n       col=c(\"red4\", \"green4\"), \n       lwd=2)\nabline(a=0, b=1, col=\"black\", lty=2)\n\n\n\n\n\n\n\n\nAs we see here, the “best of” structure increases the chance that the “better” team wins the overall series.\nWe can also see this empirically in simulation. As always with simulation, we don’t expect exact alignment since simulation still has some randomness and we aren’t doing an infinite number of repetitions.\n\np &lt;- seq(0, 1, length.out=101)\np_calculated &lt;- 6 * p^5 - 15 * p^4 + 10 * p^3\np_empirical &lt;- vapply(p, \n                      function(p) mean(rbinom(1000, 5, p) &gt;= 3), \n                      0.0)\n\nplot(p, p_calculated, \n     type=\"l\", col=\"red4\", \n     xlab=\"Team A: Game Win Probability\", \n     ylab=\"Team A: Series Win Probability\",\n     main=\"Impact of Best-of-5 Series Structure\")\nlines(p, p_empirical, col=\"blue2\")\nlegend(\"topleft\", \n       legend=c(\"Calculated Probability\", \n                \"Simulated Probability\"), \n       col=c(\"red4\", \"blue2\"), \n       lwd=2)\nabline(a=0, b=1, col=\"black\", lty=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 2\nFor a group of 7 people, find the probability that all 4 seasons (winter, spring, summer, fall) occur at least once each among their birthdays, assuming that all seasons are equally likely.\n\n\n\n\n\n\nQuestion History\n\n\n\n\n\nThis is Question BH 1.9.51.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nTo compute this probability we use the “naive” (outcome-counting) definition of probability:\n\\[\\P = \\frac{\\text{\\# of outcomes with all four seasons represented}}{\\text{\\# of total possible outcomes}} \\]\nThe denominator is easy: each person is independent, so there are \\(4^7\\) possible outcomes.\nThe numerator is a bit trickier: we have to do some “inclusion-exclusion” math.\n\nNumber of “no winter” outcomes: \\(3^7\\)\nNumber of “no spring” outcomes: \\(3^7\\)\nNumber of “no summer” outcomes: \\(3^7\\)\nNumber of “no fall” outcomes: \\(3^7\\)\nNumber of “no winter and no spring” outcomes: \\(2^7\\)\nNumber of “no winter and no summer” outcomes: \\(2^7\\)\nNumber of “no winter and no fall” outcomes: \\(2^7\\)\nNumber of “no spring and no summer” outcomes: \\(2^7\\)\nNumber of “no spring and no fall” outcomes: \\(2^7\\)\nNumber of “no summer and no fall” outcomes: \\(2^7\\)\nNumber of “no winter and no spring and no summer” outcomes (all fall): \\(1^7\\)\nNumber of “no winter and no spring and no fall” outcomes (all summer): \\(1^7\\)\nNumber of “no winter and no summer and no fall” outcomes (all spring): \\(1^7\\)\nNumber of “no spring and no summer and no fall” outcomes (all winter): \\(1^7\\)\n\nThe pattern here is actually a bit easier to see if we wrap it up mathematically: if we want to allow \\(n\\) seasons (of 4), there are \\(\\binom{4}{n}\\) \\(n\\)-tuples of restrictions. For each of these, we have \\(n^7\\) possible outcomes, so the total number of outcomes is \\[\\sum_{n=1}^3 \\binom{4}{n}n^7(-1)^(n+1) = 4 * 1^7 - 6 * 2^7 + 4 * 3^7 = 7984\\] events that omit at least one season. This gives us a final probability of:\n\\[\\P = 1 - \\frac{7984}{4^7} = \\frac{8400}{4^7} = 51.2\\%\\]\nAdditionally, we can verify this solution in simulation:\n\nmean(replicate(10000, { # mean(replicate(, INDICATOR)) can be \n                        # used to estimate probabilities\n  seasons &lt;- sample(c(\"Winter\", \"Spring\", \"Summer\", \"Fall\"), 7, replace=TRUE)\n  length(unique(seasons)) == 4\n}))\n\n[1] 0.5175\n\n\nwhich is in substantial agreement with our exact result above.\nAlternatively, the sample space here is large enough that we can enumerate it in its entirety:\n\nlibrary(dplyr)\nlibrary(tidyr)\nOUTCOMES &lt;- expand_grid(B1 = c(\"Winter\", \"Spring\", \"Summer\", \"Fall\"),\n                        B2 = c(\"Winter\", \"Spring\", \"Summer\", \"Fall\"),\n                        B3 = c(\"Winter\", \"Spring\", \"Summer\", \"Fall\"),\n                        B4 = c(\"Winter\", \"Spring\", \"Summer\", \"Fall\"),\n                        B5 = c(\"Winter\", \"Spring\", \"Summer\", \"Fall\"),\n                        B6 = c(\"Winter\", \"Spring\", \"Summer\", \"Fall\"),\n                        B7 = c(\"Winter\", \"Spring\", \"Summer\", \"Fall\"))\n\nOUTCOMES |&gt; \n    rowwise() |&gt;\n    mutate(\n        has_winter = \"Winter\" %in% c_across(B1:B7), \n        has_spring = \"Spring\" %in% c_across(B1:B7), \n        has_summer = \"Summer\" %in% c_across(B1:B7), \n        has_fall   = \"Fall\" %in% c_across(B1:B7)\n    ) |&gt;\n    mutate(has_all_four = has_winter & has_spring & has_summer & has_fall) |&gt;\n    filter(has_all_four) |&gt;\n    NROW() \n\n[1] 8400\n\n\nwhich matches our calculation of the numerator above.\n\n\n\n\n\nQuestion 3\nSuppose that Ashley is playing a guessing game, where she has a 25% chance of answering a given question correctly (IID). If she answers a question correctly, she gets one point. Let \\(Q\\) be the total number of questions required for her to get five total points. What is the variance of \\(Q\\)?\n\n\n\n\n\n\nQuestion History\n\n\n\n\n\nA version of this question appeared as Question 2 from the Week 4 Quiz. Here, I ask about variance instead of expected value.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet \\(Q_1\\) be the number of attempts Ashley makes to get her first point; \\(Q_2\\) be the number of additional attempts Ashley makes to get her second point; etc.. Then \\(Q = Q_1 + Q_2 + Q_3 + Q_4 + Q_5\\).\nEach \\(Q_i\\) is IID Geometric with probability \\(p\\) and so its variance is given by \\(\\V[Q_i] = (1-p)/p^2\\), as can be seen on the Formula Sheet. Because the \\(Q_i\\) are IID, their variances add and we obtian \\[\\V[Q] = \\sum_{i=1}^5 \\V[Q_i] = \\sum_{i=1}^5 \\frac{1-p}{p^2} = \\frac{5(1-p)}{p^2}\\]\nAt \\(p=0.25\\), this works out to 60.\nIf we recognize this as a negative binomial distribution, we can also check it in R directly:\n\nvar(rnbinom(100000, 5, 0.25))\n\n[1] 59.84925\n\n\n\n\n\n\n\nQuestion 4\nA group of 50 people are comparing their birthdays; as usual, assume their birthdays are independent, are not February 29, etc. Find the expected number of pairs of people with the same birthday.\n\n\n\n\n\n\nQuestion History\n\n\n\n\n\nThis is the first half of Question BH 4.12.35.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nA given pair of people have a \\(1/365\\) chance of sharing a birthday. In a group of 50 people, there are \\(\\binom{50}{2} = 1225\\) total pairs. By the properties of indicators and expectations, the expected number of people to share a birthday is simply \\(\\binom{50}{2} * \\frac{1}{365} \\approx 3.36\\).\nWe can again verify this experimentally:\n\nmean(replicate(100000, { # mean(replicate(, N)) can be \n                         # used to estimate E[N]\n  birthdays &lt;- sample(365, 50, replace=TRUE)\n  N_shares &lt;- sum(outer(birthdays, birthdays, `==`))\n  (N_shares - 50)/2 # Remove \"self-shares\" and divide by 2 (i, j) == (j, i)\n}))\n\n[1] 3.35946\n\n\n\n\n\n\n\nQuestion 5\nA certain family has 6 children, consisting of 3 boys and 3 girls. Assuming that all birth orders are equally likely, what is the probability that the 3 eldest children are the 3 girls?\n\n\n\n\n\n\nQuestion History\n\n\n\n\n\nThis is Question BH 1.9.24.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThere are \\(\\binom{6}{3}\\) possible orderings (choosing in which of the 6 “slots” to put the 3 girls). Of these, only one has the three girls born first, so the probability is given by:\n\\[\\frac{1}{\\binom{6}{3}} = \\frac{1}{20} = 5\\%\\]\nWe can verify this computationally:\n\nmean(replicate(100000, {\n    birth_order &lt;- sample(c(\"G\", \"G\", \"G\", \"B\", \"B\", \"B\"), 6, replace=FALSE)\n    all(birth_order[1:3] == \"G\")\n}))\n\n[1] 0.04941\n\n\nClose enough!\n\n\n\n\n\nQuestion 6\nSuppose \\(X \\sim \\text{Poisson}(\\lambda)\\), that is \\(X\\) is a Poisson random variable with mean \\(\\lambda = \\E[X]\\). What is the second (non-central) moment of \\(X\\), i.e., \\(\\E[X^2]\\)?\n\n\n\n\n\n\nQuestion History\n\n\n\n\n\nThis is Question 3 from the Week 4 Quiz.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe recall that \\(\\V[X] = \\E[X^2] - \\E[X]^2\\). Rearranging, this gives us \\(\\E[X^2] = \\E[X]^2 + \\V[X]\\). For a Poisson random variable, we have \\(\\E[X] = \\V[X] = \\lambda\\), so we obtain:\n\\[\\E[X^2] = \\lambda^2 + \\lambda.\\]\n\n\n\n\n\nQuestion 7\nSuppose that course grades are distributed as follows:\n\n\n\nGrade\nA\nB\nC\nD\nF\n\n\n\n\nGPA Points\n4\n3\n2\n1\n0\n\n\nFraction of Class\n30%\n30%\n15%\n5%\n20%\n\n\n\nGiven that a student did not receive an F, what is the probability they receive an A or a B in the course?\n\n\n\n\n\n\nQuestion History\n\n\n\n\n\nThis is a variant of Question 1 from the Week 4 Quiz. Here, I ask for a conditional probability instead of a conditional expectation.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nTo compute the PMF conditional on not failing, we can use the definition of conditional probability\n\\[\\P(A | \\text{ not } F) = \\frac{\\P(A \\text{ and not } F)}{\\P(\\text{not }F)} = \\frac{\\P(A)}{1 - \\P(F)}  = \\frac{0.3}{1-0.2} = \\frac{3}{8}\\]\nSimilarly,\n\\[\\P(B | \\text{ not } F) = \\frac{\\P(B \\text{ and not } F)}{\\P(\\text{not }F)} = \\frac{\\P(B)}{1 - \\P(F)}  = \\frac{0.3}{1-0.2} = \\frac{3}{8}\\]\nCombining these, we have:\n\\[\\P(A \\text{ or } B | \\text{ not } F) = \\P(A | \\text{ not } F) + \\P(B | \\text{ not } F) = \\frac{3}{8} + \\frac{3}{8} = \\frac{3}{4}\\]\n\n\n\n\n\nQuestion 8\nSuppose that the number of Baruch students to win the lottery each year is Poisson distributed with mean \\(2\\). What is the probability that an above average (i.e., above mean) number of Baruch students win the lottery next year?\n\n\n\n\n\n\nQuestion History\n\n\n\n\n\nThis is a new question, designed to test your use of PMFs and CDFs.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe use the complement rule to convert the infinite event “above 2” to a finite set of outcomes “0, 1, or 2”. We then simply use the Poisson PMF: \\[\\begin{align*}\n\\P(X &gt; 2) &= 1 - \\P(X \\leq 2) \\\\\n          &= 1 - \\sum_{x=0}^2 \\P(X = x) \\\\\n          &= 1 - \\sum_{x=0}^2 \\frac{2^x e^{-2}}{x!} \\\\\n          &= 1 - \\left(\\frac{2^0 e^{-2}}{0!}+\\frac{2^1 e^{-2}}{1!}+\\frac{2^2 e^{-2}}{2!}\\right) \\\\\n          &= 1 - \\left(e^{-2} + 2e^{-2} + 2e^{-2}\\right) \\\\\n          &= 1 - 5e^{-2} \\\\\n          &\\approx 32.3\\%\n\\end{align*}\\]\nWe can also compute this more directly in R:\n\nppois(2, 2, lower.tail=FALSE)\n\n[1] 0.3233236\n\n\nHere, pDIST(..., lower.tail=FALSE) gives the complimentary CDF.\n\n\n\n\n\nQuestion 9\nAccording to the CDC, men who smoke are 23 times more likely to develop lung cancer than men who don’t smoke. Also according to the CDC, 21.6% of men in the US smoke. What is the probability that a man in the US is a smoker, given that he develops lung cancer?\n\n\n\n\n\n\nQuestion History\n\n\n\n\n\nThis is Question BH 2.11.3.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet \\(C\\) be the event that an individual develops lung cancer and let \\(S\\) be the event that he his a smoker. The CDC data then gives us:\n\\[\\begin{align*}\n\\P(S) = 0.216 \\\\\n\\P(C | S) &= 23 \\P(C | S^c)\n\\end{align*}\\]\nWe can combine these using a variant of Bayes’ rule:\n\\[\\begin{align*}\n\\P(S | C) &= \\frac{\\P(C | S) * \\P(S)}{\\P(C)} \\\\\n          &= \\frac{\\P(C | S) * \\P(S)}{\\P(C|S)\\P(S) + \\P(C | S^c)\\P(S^c)} \\\\\n          &= \\frac{23\\P(C | S^c) * \\P(S)}{23\\P(C|S^c)\\P(S) + \\P(C | S^c)\\P(S^c)} \\\\\n          &= \\frac{23\\P(S)}{23\\P(S) + \\P(S^c)} \\\\\n          &= \\frac{23\\P(S)}{23\\P(S) + 1 - \\P(S)} \\\\\n          &= \\frac{23 \\P(S)}{1 + 22\\P(S)} \\\\\n          &= \\frac{23 * 0.216}{1 + 22 * 0.216} \\\\\n          &\\approx 86.4\\%\n\\end{align*}\\]\n\n\n\n\n\nQuestion 10\nLet \\(T\\) be the time until a radioactive particle decays and suppose that \\(T \\sim \\text{Exponential}(\\lambda)\\). The half-life of the particle is the time at which there is a 50% chance that the particle has decayed (i.e., the median of \\(T\\)). Find the half-life of the particle in terms of \\(\\lambda\\).\nHint: Recall \\(\\int e^{ax}\\,\\text{d}x = \\frac{e^{ax}}{a}\\).\n\n\n\n\n\n\nQuestion History\n\n\n\n\n\nThis is Question BH 5.10.37(a).\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nTo find the median, i.e., the 50% probability point, we first need to compute the CDF. Since \\(T\\) is exponentially distributed, we can compute its CDF by integrating its PDF:\n\\[\\begin{align*}\nF_T(\\tau) &= \\P(T &lt; \\tau) \\\\\n          &= \\int_0^{\\tau} f_T(t)\\,\\text{d}t \\\\\n          &= \\int_0^{\\tau}\\lambda e^{-\\lambda t}\\,\\text{d}t \\\\\n          &= \\left.\\left[-e^{-\\lambda t}\\right]\\right|_0^{\\tau} \\\\\n          &= \\left(-e^{-\\lambda \\tau}\\right) - \\left(-e^{-\\lambda * 0}\\right) \\\\\n          &= 1 - e^{-\\lambda \\tau}\n\\end{align*}\\]\nNow, we set this equal to one half in order to find the half life:\n\\[\\begin{align*}\n\\frac{1}{2} &= 1 - e^{-\\lambda \\tau} \\\\\ne^{-\\lambda \\tau} &= \\frac{1}{2} \\\\\n-\\lambda \\tau &= \\log(1/2) \\\\\n\\lambda \\tau &= \\log(2) \\\\\n\\tau_{\\text{Half-Life}} &= \\frac{\\log(2)}{\\lambda}\n\\end{align*}\\]\n\n\n\n\n\nQuestion 11\nSuppose the random variables \\((X, Y)\\) have joint PDF \\(f_{(X, Y)}(x, y) = 4xy\\) with support on the unit square \\([0, 1]^2\\). (That is, both \\(X\\) and \\(Y\\) can take any value in \\([0, 1]\\)). What is the conditional expectation of \\(X\\) given \\(Y &gt; 0.5\\)\n\n\n\n\n\n\nQuestion History\n\n\n\n\n\nThis is a new question, designed to test your use of conditional PDFs. Due to its use of conditional probabilities and PDFs, this is probably the most advanced question on this test.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe need to compute the density of \\(X\\), conditional on \\(Y &gt; 0.5\\).\nIt will be useful to first compute the probability that \\(Y &gt; 0.5\\):\n\\[\\begin{align*}\n\\P(Y &gt; 0.5) &= \\int_{(x, y) \\in [0,1]\\times[0.5, 1]} f_{X, Y}(x, y)\\,\\text{d}x\\,\\text{d}y \\\\\n            &= \\int_{x=0}^1 \\int_{y=0.5}^1 4xy\\,\\text{d}y\\,\\text{d}x \\\\\n            &= \\int_0^1\\left(\\left.2xy^2\\right|_{0.5}^1\\right)\\,\\text{d}x \\\\\n            &= \\int_0^1\\left(2x - x/2\\right)\\,\\text{d}x \\\\\n            &= \\int_0^1 \\frac{3}{2}x\\,\\text{d}x \\\\\n            &= \\left.\\frac{3}{4}x^2\\right|_0^1 \\\\\n            &= \\frac{3}{4}\n\\end{align*}\\]\nAs usual, we apply our standard conditional formula, here to PDFs instead of PMFs:\n\\[\\begin{align*}\nf_{X | Y &gt; 0.5}(x) &= \\frac{\\int_{0.5}^1 f_{X, Y}(x, y)\\,\\text{d}y}{\\P(Y &gt; 0.5)} \\\\\n&= \\frac{\\int_{0.5}^1 4xy\\,\\text{d}y}{\\frac{3}{4}} \\\\\n&= \\frac{\\left.2xy^2\\right|_{y=0.5}^1}{\\frac{3}{4}} \\\\\n&= \\frac{1.5x}{\\frac{3}{4}} \\\\\n&= 2x\n\\end{align*}\\]\nNow that we have the conditional PDF, we can use it to compute the conditional expectation:\n\\[\\begin{align*}\n\\E[X | Y &gt; 0.5] &= \\int_0^1 x * f_{X|Y &gt; 0.5}(x)\\,\\text{d}x \\\\\n                &= \\int_0^1 x * 2x\\,\\text{d}x \\\\\n                &= \\int_0^1 2x^2\\,\\text{d}x \\\\\n                &= \\left.\\frac{2}{3}x^3\\right|_0^1 \\\\\n                &= \\frac{2}{3}\n\\end{align*}\\]\nAs we will see later in this course, you can also factorize this as\n\\[f_{(X, Y)}(x, y) = (2x) * (2y) = f_X(x) f_Y(y)\\]\nso \\(X, Y\\) are independent. Hence \\(\\E[X | Y &gt; 0.5] = \\E[X]\\). To get the expectation of \\(X\\), we simply use the standard integral representation:\n\\[\\begin{align*}\n\\E[X] &= \\int_0^1 x * f_X(x)\\,\\text{d}x \\\\\n        &= \\int_0^1 2x^2\\,\\text{d}x \\\\\n        &= \\left.\\frac{2x^3}{3}\\right|_0^1 \\\\\n        &= \\frac{2}{3}*1^3 - \\frac{2}{3}*0^3 \\\\\n        &= \\frac{2}{3}\n\\end{align*}\\]\n\n\n\n\n\nQuestion 12\nFive students board the Baruch express elevators at the same time from the second floor. Assuming that their destinations are uniformly random (i.e., that they exit at each floor with equal probability), what is the probability that no students exit on the 11th floor? (Recall that the Baruch express elevators stop at the 5th, 8th, and 11th floors.)\n\n\n\n\n\n\nQuestion History\n\n\n\n\n\nThis is Question 1 from the Week 2 Quiz.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nBy assumption, each student has a \\(2/3\\) chance of exiting other than the 11th floor. Because the students are independent, their exit floors are independent events and the associated probabilities may be multiplied: \\[\\left(\\frac{2}{3}\\right)^5 \\approx 0.13\\] Computationally,\n\nmean(replicate(100000, {\n    all(sample(c(5, 8, 11), 5, replace=TRUE) &lt; 11)\n}))\n\n[1] 0.13149\n\n\n\n\n\n\n\nQuestion 13\nLet \\[X \\sim \\mathcal{N}(3, \\sqrt{2}^2)\\] and \\[Y \\sim \\mathcal{N}(1, \\sqrt{2}^2)\\] be independent normal random variables. Calculate \\(\\mathbb{P}(X &lt; Y)\\). You may leave your answer in terms of the standard normal CDF \\(\\Phi(\\cdot)\\).\nHint: Use the fact that \\(Z_1 \\sim \\mathcal{N}(\\mu_1, \\sigma_1^2)\\) and \\(Z_2 \\sim \\mathcal{N}(\\mu_2, \\sigma_2^2)\\) implies \\[aZ_1 + bZ_2 + c \\sim \\mathcal{N}(a\\mu_1 + b\\mu_2 + c, a^2\\sigma_1^2 + b^2\\sigma_2^2)\\] for \\(Z_1, Z_2\\) independent.\n\n\n\n\n\n\nQuestion History\n\n\n\n\n\nThis is a simplified version of Question BH 5.10.25.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAs the hint suggests, let’s look at the distribution of \\(X - Y\\) since\n\\[\\P(X &lt; Y) = \\P(X - Y &lt; 0)\\]\nPer the hint, \\(X - Y\\) will have a normal distribution with mean \\[\\E[X - Y] = \\E[X] - \\E[Y] = 3 - 1 = 2\\] and variance \\[\\V[X - Y] = \\V[X] + \\V[Y] = \\sqrt{2}^2 + \\sqrt{2^2} = 2 + 2 = 4 = 2^2\\] so \\[X - Y\\sim \\mathcal{N}(2, 2^2)\\]. We then note that \\(X - Y = 2 + 2Z\\) for standard normal \\(Z\\), so \\[\\P(X - Y &lt; 0) = \\P(2 + 2Z &lt; 0) = \\P(2Z &lt; -2) = \\P(Z &lt; -1) = \\Phi(-1) \\approx 15.8\\%.\\]\nAs usual, let’s check this computationally:\n\nX &lt;- rnorm(50000, mean=3, sd=sqrt(2))\nY &lt;- rnorm(50000, mean=1, sd=sqrt(2))\nmean(X &lt; Y)\n\n[1] 0.15714\n\n\n\n\n\n\n\nQuestion 14\nSuppose a random variable \\(X\\) takes continuous values between 2 and 5. Suppose further that its PDF is \\(f_X(x) = c x^2\\) for some unknown \\(c\\). What is \\(c\\)?\n\n\n\n\n\n\nQuestion History\n\n\n\n\n\nThis is a new question, requiring you to use the fact that PDFs integrate to 1 over their support.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe know that the PDF must integrate to 1 over the interval \\([2, 5]\\). Hence: \\[\\begin{align*}\n1 &= \\int_2^5 cx^2\\,\\text{d}x \\\\\n  &= \\left.\\frac{cx^3}{3}\\right|_2^5 \\\\\n  &= c\\left(\\frac{5^3}{3} - \\frac{2^3}{3}\\right) \\\\\n  &= 39c \\\\\n\\implies c &= \\frac{1}{39}\n\\end{align*}\\]\nWe can, as usual, verify our work computationally:\n\nintegrate(function(x) x^2/39, lower=2, upper=5)\n\n1 with absolute error &lt; 1.1e-14\n\n\n\n\n\n\n\nQuestion 15\nIn the Gregorian calendar, each year has either 365 days (normal) or 366 (leap year). A year is randomly chosen with probability 3/4 of being a normal year and 1/4 of being a leap year. Find the mean and variance of the number of days in the chosen year.\n\n\n\n\n\n\nQuestion History\n\n\n\n\n\nThis is Question BH 4.12.2.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet \\(N\\) be the number of days in a year. Under the set-up of the problem, it is clear that \\(N \\sim 365 + \\text{Bernoulli}(1/4)\\). Hence,\n\\[\\begin{align*}\n\\E[N] &= \\E[365 + \\text{Bernoulli}(1/4)] \\\\\n      &= 365 + \\E[\\text{Bernoulli}(1/4)] \\\\\n      &= 365 + \\frac{1}{4} \\\\\n      &= 365.25 \\\\\n\\V[N] &= \\V[365 + \\text{Bernoulli}(1/4)] \\\\\n      &= \\V[\\text{Bernoulli}(1/4)] \\\\\n      &= \\frac{1}{4}\\left(1 - \\frac{1}{4}\\right) \\\\\n      &= \\frac{3}{16}\\\\\n\\end{align*}\\]\n\n\n\n\n\nQuestion 16\nThe random variable \\(X\\) has PDF \\(f(x) = 12x^2(1-x)\\) and support \\([0, 1]\\). Compute \\(\\mathbb{P}(0 \\leq X \\leq 1/2)\\).\n\n\n\n\n\n\nQuestion History\n\n\n\n\n\nThis is Question BH 5.10.8(b).\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nTo compute the probability of a random variable falling in an interval, we simply integrate its PDF over that interval:\n\\[\\begin{align*}\n\\int_0^{1/2} 12x^2(1-x)\\,\\text{d}x &= \\int_0^{1/2} 12x^2-12x^3\\,\\text{d}x \\\\\n&= \\left.\\left[\\frac{12}{3}x^3 - \\frac{12}{4}x^4\\right]\\right|_{x=0}^{x=1/2} \\\\\n&= \\left.\\left[4x^3 - 3x^4\\right]\\right|_{x=0}^{x=1/2} \\\\\n&= \\left(4(0.5)^3 - 3(0.5)^4\\right) - \\left(4(0)^3 - 3(0)^4\\right) \\\\\n&= \\left(\\frac{1}{2} - \\frac{3}{16}\\right) - \\left(0 - 0\\right) \\\\\n&= \\frac{5}{16}\\end{align*}\\]\nOur textbook points out that this is a particular Beta distribution, so we can also check our work in R:\n\npbeta(0.5, 3, 2)\n\n[1] 0.3125\n\n\n\n\n\n\n\nQuestion 17\n\\(X\\) is a mixture distribution defined as follows:\n\n\\(X_1 \\sim \\mathcal{N}(0, 5^2)\\),\n\\(X_2 \\sim \\text{Poisson}(5)\\), and\n\\(X_3 \\sim \\text{ContinuousUniform}([-3, 3])\\).\n\\(Z\\) is uniform on \\(\\{1, 2, 3\\}\\) and\n\\(X = X_Z\\).\n\nThat is, \\(X\\) is the value of each mixture arm with equal probability. \\(Z, X_1, X_2, X_3\\) are all independent.\nCompute the variance of \\(X\\).\n\n\n\n\n\n\nQuestion History\n\n\n\n\n\nThis is a new question, designed to test your use of the Law of Total Variance.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nRecall the Law of Total Variance. Apply it as\n\\[\\begin{align*}\n\\V_X[X] &= \\E_Z[\\V_X[X | Z]] + \\V_Z[\\E[X | Z]]\n\\end{align*}\\]\nWe start with the various cases for the conditional variance of \\(X\\):\n\n\\(\\V_X[X | Z = 1] = \\V[X_1] = \\V[\\mathcal{N}(0, 5^2)] = 5^2 = 25\\)\n\\(\\V_X[X | Z = 2] = \\V[X_2] = \\V[\\text{Poisson}(5)] = 5\\)\n\\(\\V_X[X | Z = 3] = \\V[X_3] = \\V[\\text{ContinuousUniform}([-3, 3])] = \\frac{(3-(-3))^2}{12} = 3\\)\n\\(\\implies \\E_Z[\\V_X[X | Z]] = \\frac{1}{3} * 25 + \\frac{1}{3} * 5 + \\frac{1}{3} * 3 = 11\\)\n\nSimilarly, we handle the conditional expectation of \\(X\\):\n\n\\(\\E_X[X | Z = 1] = \\E[X_1] = \\E[\\mathcal{N}(0, 5^2)] = 0\\)\n\\(\\E_X[X | Z = 2] = \\E[X_2] = \\E[\\text{Poisson}(5)] = 5\\)\n\\(\\E_X[X | Z = 3] = \\E[X_3] = \\E[\\text{ContinuousUniform}([-3, 3])] = 0\\)\n\\(\\implies \\V_Z[\\E_X[X | Z]] = \\V[5 * \\text{Bernoulli}(1/3)] = 25 \\V[\\text{Bernoulli}(1/3)] = \\frac{50}{9}\\)\n\nSo we have:\n\\[\\begin{align*}\n\\V_X[X] = \\E_Z[\\V_X[X | Z]] + \\V_Z[\\E[X | Z]] = 11 + \\frac{50}{9} \\approx 16.55\n\\end{align*}\\]\nThat’s enough tricky algebra that we might want to check our work in simulation:\n\nvar(replicate(100000, {\n    X1 &lt;- rnorm(1, mean=0, sd = 5)\n    X2 &lt;- rpois(1, 5)\n    X3 &lt;- runif(1, -3, 3)\n    sample(c(X1, X2, X3), 1)\n}))\n\n[1] 16.67737\n\n\nNot too shabby.\n\n\n\n\n\nQuestion 18\nFour players, named A, B, C, and D, are playing a card game. A standard well-shuffled deck of cards is dealt to the players so each player receives a 13 card hand. How many possibilities are there for the hand that play A will get? (Within a hand, the order in which cards were received doesn’t matter.)\n\n\n\n\n\n\nQuestion History\n\n\n\n\n\nThis is Question BH 1.9.12(a).\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSince the order doesn’t matter, we use the binomial coefficient:\n\\[\\binom{52}{13} = {}_{52}C_{13} = \\frac{52!}{13!(52-13)!} = 635013559600\\]\nFor full credit you do not need to compute this exactly.\n\n\n\n\n\nQuestion 19\nLet \\(X\\) be the number of Heads in 10 fair coin tosses (IID). Find the conditional variance of \\(X\\), given that the first two tosses both land Heads.\n\n\n\n\n\n\nQuestion History\n\n\n\n\n\nThis is a slight variation on Question BH 3.12.24(a), asking only for the conditional variance instead of the full conditional PMF.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet \\(Y = (X - 2) | \\{H, H\\}\\) be the number of Heads in the final 8 coin tosses. Because the tosses are IID Bernoulli(0.5), we can see that \\(Y \\sim \\text{Binomial}(8, 0.5)\\). From here, we use the Binomial variance supplied on the Formula Sheet to see that \\[\\V[Y] = 8 * 0.5 * (1-0.5) = 2.\\]\nNote that, here, we use the fact that, conditional on some of the Bernoulli trials, a Binomial becomes a smaller Binomial.\n\n\n\n\n\nQuestion 20\nSuppose that, before a major election, a polling company contacts a large number of likely voters and successfully asks 1000 voters who they intend to vote for. Candidate A’s supporters have a 100% chance of answering the poll if contacted, while Candidate B’s supporters have only a 50% chance of answering the poll. If 75% of respondents say they intend to vote for Candidate A, what is A’s expected fraction of total votes cast on election day?\n(You may assume that supporters of candidate A and B are equally likely to vote and that they only differ in their likelihood to respond to the poll. You may also assume only two candidates. You may also assume respondents don’t lie and are otherwise fully representative, except for differential response rates.)\n\n\n\n\n\n\nQuestion History\n\n\n\n\n\nThis is Question 1 from the Week 3 Quiz.\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nLet \\(A\\) be the event that a voter supports candidate A, \\(B\\) be the event that a voter supports candidate \\(B\\), and \\(R\\) be the event that a voter responds to a poll if contacted. We then have:\n\\[\\begin{align*}\n\\P(R | A) &= 1  \\\\\n\\P(R | B) &= 0.5 \\\\\n\\P(A | R) &= 0.75\n\\end{align*}\\]\nWhile we could formally use the rules of conditional probability, it is easier to think in “raw counts”. Specifically, if we had 1000 responses, with 75% support for A, that means we had 750 respondents supporting A and 250 supporting B. Since B supporters only have a 50% chance of responding, that implies 500 B supporters total. Hence, the true support rate for candidate A is \\(750 / (750 + 500) = 60\\%\\)."
  },
  {
    "objectID": "notes/expectations.html",
    "href": "notes/expectations.html",
    "title": "What to Expect when You’re Expecting: Notes on Expectations, Variances, and Probabiblities",
    "section": "",
    "text": "\\[\\newcommand{\\P}{\\mathbb{P}} \\newcommand{\\E}{\\mathbb{E}} \\newcommand{\\V}{\\mathbb{V}}\\]\nIn this note, I outline some of the basic properties of expectations and variances of random variables. I also show how many of these properties can be extended to probabilities via the use of indicator functions."
  },
  {
    "objectID": "notes/expectations.html#random-variables",
    "href": "notes/expectations.html#random-variables",
    "title": "What to Expect when You’re Expecting: Notes on Expectations, Variances, and Probabiblities",
    "section": "Random Variables",
    "text": "Random Variables\nSo far, we have mainly focused on probabilities of individual events (e.g., the probability of rolling a certain sum from a set of dice). This is useful enough, but somewhat limiting. If we have to start from scratch and build probabilities for every possible event from the raw sample space, we will never get anything done. A far more productive approach is to work with random variables. Formally, a random variable is a function from the sample space to the set of real numbers. That is, for every \\(\\omega \\in \\Omega\\), we can define a random variable \\(X\\) as \\(X(\\omega) = f(\\omega)\\). \\(X\\) inherits a probability measure from \\(\\Omega\\): \\[\\P(X = a) = \\P(X(\\omega) = a) = \\P(\\{\\omega: X(\\omega) = a\\}).\\] That is, we compute the probability of \\(X\\) taking a value \\(a\\) by looking at the probability of all inputs that could have lead to \\(a\\). (This induced measure is sometimes called the ‘push-forward’ because we get probabilities on \\(X\\) by pushing ‘raw’ probabilities on \\(\\Omega\\) into \\(X\\)-world.) Because \\(X\\) ever only takes one value at at time, the events \\(\\{X = a_1\\}, \\{X = a_2\\}, \\dots\\) are disjoint, which makes it much easier to calculate with \\(X\\) than it is with \\(\\omega\\). For example, \\[\\P(X = a \\text{ or } X = b) = \\P(X = a) + \\P(X = b) - \\P(X = a \\text{ and } X = b) = \\P(X = a) + \\P(X = b)\\]\nThis formal definition is great, but we can also just ‘start’ with \\(X\\) and avoid talking about the sample space \\(\\Omega\\) at all. Specifically, let’s define a random variable \\(X\\) by a set of probabilities and real values, subject to the constraint that the probabilities add to 1. For example, we may define the random variable \\(X\\) by:\n\nRandom Variable \\(X\\)\n\n\n\\(a\\)\n\\(\\P(X = a)\\)\n\n\n\n\n1\n\\(\\frac{1}{16}\\)\n\n\n2\n\\(\\frac{4}{16} = \\frac{1}{4}\\)\n\n\n3\n\\(\\frac{6}{16} = \\frac{3}{8}\\)\n\n\n4\n\\(\\frac{4}{16} = \\frac{1}{4}\\)\n\n\n5\n\\(\\frac{1}{16}\\)\n\n\n\nExamining this, we see that the sum \\(\\sum_{a=1}^5 \\P(X = a) = 1\\) so \\(X\\) here is a valid random variable.\n\n\n\n\n\n\nRandom Variables - Working Definition\n\n\n\nA random variable \\(X\\) is defined by a set of outcome-probability pairs \\(X \\equiv \\{(a_1, p_1), (a_2, p_2), \\dots\\}\\) such that:\n\nThe outcomes are all distinct \\(a_i \\neq a_j\\) for \\(i \\neq j\\);\nThe probabilities are non-negative: \\(p_i \\geq 0\\) for all \\(i\\); and\nThe probabilities sum to \\(1\\): \\(\\sum_i p_i = 1\\).\n\nThe probability expression \\(\\P(X = a)\\) is a ‘look-up’ expression:\n\\[\\P(X = a) = p \\text{ if and only if } (a, p) \\in X\\]\n\n\nComparing this to the “naive” definition of probability (all outcomes equal - events comprised of different numbers of outcomes), you might argue that we haven’t actually simplified anything: we’ve just moved the complexity around. Technically, you may be right, but I would argue that working from random variables as our starting point is hugely helpful. We have replaced the tedious and somewhat painful algebra of counting with the simple and easily automated algebra of summing. For instance, if we want to compute the probability that the random variable \\(X\\) we defined above is even, we only need to sum \\[\\P(X = 2) + \\P(X = 4) = \\frac{1}{4} + \\frac{1}{4} = \\frac{1}{2}.\\] No intersections, unions, permutations, or combinations to be seen.\n\n\n\n\n\n\nA Note on Notation\n\n\n\nIn this course, we will adopt a nearly universal notational convention: capital letters, e.g. \\(X\\), refer to random variables while \\(x\\) refers to fixed deterministic (non-random) quantities. In this convention, a statement like \\(\\P(X = x)\\) is asking what is the probability that a random quantity (\\(X\\)) takes a certain fixed value. When we have multiple random variables in play (\\(X, Y\\)), we can compute \\(\\P(X = Y)\\), the chance of a ‘tie’, but statements like \\(\\P(x = y)\\) are essentially meaningless since there’s no randomness.\n\n\nWhen the set of outcomes is ‘not too infinite’, we refer to \\(X\\) is as a discrete random variable and require the probabilities to sum to one. If \\(X\\) is ‘quite infinite’, we refer to \\(X\\) as a continuous random variable and require probabilities to integrate to one instead.1 Specifically, if \\(X\\) has:\n\na finite set of outcomes; or\nan infinite set of outcomes that can be listed (‘countably infinite’)\n\nwe’ll treat it as discrete. In this course, the only ‘countably infinite’ sets we deal with are the integers or subsets thereof (e.g. positive integers), so the heuristic of “discrete variables have integer outcomes or only finite numbers of outcomes” will serve you well."
  },
  {
    "objectID": "notes/expectations.html#transformations-of-random-variables",
    "href": "notes/expectations.html#transformations-of-random-variables",
    "title": "What to Expect when You’re Expecting: Notes on Expectations, Variances, and Probabiblities",
    "section": "Transformations of Random Variables",
    "text": "Transformations of Random Variables\nOften, we may have a random variable \\(X\\) and are interested in performing some calculations on an induced random variable \\(f(X)\\) for some known function \\(f\\). If \\(f\\) is one-to-one, this is easy:\n\\[\\P(f(X) = a) = \\P(X = f^{-1}(a))\\].\nFor example, using our definition of \\(X\\) above,\n\\[ \\P(X^2 = 25) = \\P(X = 5) = \\frac{1}{16}.\\]\nIn other contexts, \\(f\\) may not be one-to-one; that is, there may be multiple \\(x\\) such that \\(f(x) = a\\). In this case, we need to interpret \\(f^{-1}(a)\\) as the set of all inputs leading to \\(a\\). When we compute \\(\\P(X \\in f^{-1}(a))\\), we must compute all possibilities for this input: e.g., let’s take \\(f(x) = (x - 3)^2\\) and compute \\(\\P(f(X) = 1)\\).\n\\[\\P(f(X) = 1) = \\P(X \\in f^{-1}(1)) = \\P(X \\in \\{2, 4\\}) = \\P(X = 2) + \\P(X = 4) = \\frac{1}{2}\\]\nWe have to do a bit more work here to compute \\(f^{-1}(1)\\), but after that, we’re just getting the aggregate probability of disjoint events, so addition suffices. Again - no unions or intersections (inclusion-exclusion rules) in sight: random variables are always in one and only one of their outcomes."
  },
  {
    "objectID": "notes/expectations.html#expectations",
    "href": "notes/expectations.html#expectations",
    "title": "What to Expect when You’re Expecting: Notes on Expectations, Variances, and Probabiblities",
    "section": "Expectations",
    "text": "Expectations\nWhen faced with a random variable \\(X\\), we may ask (or be asked) “What’s going to Happen?” Clearly, because \\(X\\) is random, we can’t really be certain about what’s going to happen, but we can still make a ‘best guess’.\n\nLoss Functions and Best Predictions\nOf course, any notion of ‘best’ is context dependent: in simple problems, we may only care about ‘right / wrong’ predictions, but in many circumstances, the degree (and direction) of error in our prediction matters. If we are off by 1 degree in a weather prediction, that’s not bad, but if we are over by $1 on The Price is Right, we instantly lose.\nIn statistics, we often work with a loss function, a quantitative measure of the ‘pain’ we experience when our guess is wrong.2 Some examples of loss functions include:\n\nRight-or-Bust: \\[\\ell(\\text{guess}, \\text{truth}) = \\begin{cases} 0 & \\text{ if guess $=$ truth} \\\\ 1,000,000 & \\text{ if guess $\\neq$ truth}\\end{cases}\\]\nSquared Error: \\[\\ell(\\text{guess}, \\text{truth}) = (\\text{guess} - \\text{truth})^2\\]\nAbsolute Error: \\[\\ell(\\text{guess}, \\text{truth}) = |\\text{guess} - \\text{truth}|\\]\nClosest without Going Over: \\[\\ell(\\text{guess}, \\text{truth}) = \\begin{cases} \\text{truth} - \\text{guess} & \\text{ if guess $\\leq$ truth} \\\\ 1,000,000 & \\text{ if guess $&gt;$ truth} \\end{cases}\\]\n\n(Note that the number \\(1,000,000\\) here is a stand-in for any large number. It’s not special.)\nIn general, we allow any loss function satisfying \\(\\ell(x, y) \\geq 0\\) with equality if and only if \\(x = y\\); that is, we want our loss functions to be non-negative for any \\((x, y)\\) and zero only when we get exactly the right answer.\nOnce we commit to a loss function, the ‘best’ prediction is not too hard to figure out:\n\nRight-or-Bust gives us the mode, i.e., the single most probable value of \\(X\\)\nAbsolute Error gives us the median\nSquared Error gives us the mean\n\nGiven the ubiquity of means in statistics, you might expect squared error to be the ‘one true loss function’. In practice, very few loss functions are truly quadratic. But the general phenomenon of:\n\nsymmetric; and\nincreasing rate (the incremental pain of being off by 3 vs off by 2 is more than the incremental pain of off by 2 instead of off by 1)\n\nis quite common and squared error is the simplest mathematical model with those two properties. Accordingly, the mean is not the single best possible prediction for all scenarios, but it’s a very close to optimal prediction for a wide range of scenarios. Combine that with mathematical convenience and its no surprise that squared error loss and means dominate the field of statistics.\n\n\nExpected Values\nOk - that’s enough chit chat. Let’s just say I want my best possible prediction under a squared error loss. How do I actually compute it?\nLet us define the expectation of a random variable as follows:\n\n\n\n\n\n\nExpected Value of a Random Variable\n\n\n\nGiven a random variable \\(X\\), its expected value is defined as a probability-weighted average of all outcomes: that is,\n\\[ \\E[X] = \\sum_a \\P(X = a) * a \\]\nThe expression \\(\\E[X]\\) is pronounced “the expectation of \\(X\\)”.\n\n\nUsing our running example, we get\n\\[\\E[X] = 1 * \\frac{1}{16} + 2 * \\frac{4}{16} + 3 * \\frac{6}{16} + 4 * \\frac{4}{16} + 5 * \\frac{1}{16} = 3\\]\nNote here that the expectation is the center value of \\(X\\). That isn’t always the case, but it is when \\(X\\) is a symmetric random variable and here \\(X\\) is symmetric around \\(3\\).\nThere’s nothing special about \\(X\\) in expectations: it’s very possible to compute expectations of arbitrary random variables, including functions of \\(X\\) itself. For example, let’s try \\(\\E[(X - 3)^2 + 5]\\).\nBeing careful, let’s define a new random variable \\(Y = (X-3)^2 + 5\\). It’s not hard to check that \\(Y\\) is defined by\n\nDistribution of \\(Y\\)\n\n\ny\n\\(\\P(Y = y)\\)\n\n\n\n\n5\n\\(\\frac{1}{8}\\)\n\n\n6\n\\(\\frac{1}{2}\\)\n\n\n9\n\\(\\frac{3}{8}\\)\n\n\n\nThis gives us:\n\\[\\E[Y] = 5 * \\frac{1}{8} + 6 * \\frac{1}{2} + 9 * \\frac{3}{8} = 7\\]\nThat works, but it’s perhaps a little too much work. It turns out that we can just compute \\(\\E[(X - 3)^2 + 5]\\) directly without mentioning \\(Y\\).\n\n\n\n\n\n\nLaw of the Unconscious Statistician\n\n\n\nLaw of the Unconscious Statistician: expectations of functions of random variables can be computed by ‘naive’ substitution into the definition of expectation. That is,\n\\[\\E[f(X)] = \\sum f(x) \\P(X = x)\\]\n\n\nHere,\n\\[\\begin{align*}\n\\E[f(X)] &= f(1) * \\frac{1}{16} + f(2) * \\frac{4}{16} + f(3) * \\frac{6}{16} + f(4) * \\frac{4}{16} + f(5) * \\frac{1}{16} \\\\\n&= 9 * \\frac{1}{16} + 6 * \\frac{4}{16} + 5 * \\frac{6}{16} + 6 * \\frac{4}{16} + 9 * \\frac{1}{16} \\\\\n&= 7\n\\end{align*}\\]\n\n\nProperties of Expected Values\nExpected values satisfy many useful properties. From the “weighted sum” definition, it’s not hard to show:\n\nLinearity: \\[\\E[aX + b] = a\\E[X] + b\\]\nExpectation of a Constant: \\[\\E[c] = c\\]\nSums of Functions: \\[\\E[f(X) + g(X)] = \\E[f(X)] + \\E[g(X)]\\]\nRough Bounds: \\[\\min\\{X\\} \\leq \\E[X] \\leq \\max\\{X\\}\\]\nInterchange with Derivatives: \\[\\E\\left[\\frac{df}{dx}(X)\\right] = \\frac{d}{dx}\\E[f(X)]\\]\n\nWe’ll note more interesting properties of expectations in the following sections.\n\n\nIndicators and Expectations\nA particularly important function class we might consider are indicator functions. For any event \\(A\\), define \\(1_{A}(X)\\) as the function taking \\(1\\) if outcome \\(X\\) is in event \\(A\\) and \\(0\\) otherwise. For example, if \\(A\\) is the set of even numbers, \\(1_A(3) = 0\\) while \\(1_A(2) = 1\\). There is a deep connection between probabilities and expectations of indicator functions.\n\\[\\begin{align*}\n\\E[1_A(X)] &= 0 * \\P(X \\notin A) + 1 * \\P(X \\in A) \\\\\n&= \\P(X \\in A) \\\\\n&= \\P(A)\n\\end{align*}\\]\nBecause of this, any results we have about expectations can be used to derive similar results for probabilities. In particular, we know from statistical theory that sample means converge to expectations: this, in turn, implies that sample probabilities converge to true probabilities. We’ll discuss this below after we talk about variances.\n\n\nSums of Expectations\nSuppose we have two random variables \\((X, Y)\\). How can we compute the expectation of their sum? (By linearity above, if we can say something about the sum, we’ll be able to make similar claims about arbitrary linear combinations.)\nIn brief, the answer is that\n\\[\\E[X + Y] =\\E[X] + \\E[Y]\\]\nwithout assuming independence.\nNow let’s prove that: Let \\(Z = (X, Y)\\) be the compound random variable. Define \\(f_X(Z) = X\\) and \\(f_Y(Z) = Y\\) to be the ‘coordinate’ functions of \\(Z\\). Then define \\(f(Z) = f_X(Z) + f_Y(Z) = X + Y\\). Now apply LOTUS to \\(f(Z)\\).\n\\[\\E[(X + Y)] = \\E[f(Z)] = \\E[f_X(Z) + f_Y(Z)] = \\E[f_X(Z)] + \\E[f_Y(Z)] = \\E[X] + \\E[Y]\\]\nA somewhat remarkable phenomenon is that it is often easier to compute expectations of the number of times a complex event occurs than the actual probabilities of occurrences. We demonstrate this by the famous “hat problem”.\n\nSuppose \\(n\\) people at a restaurant check their coats. The coat checker is a bit absent-minded and returns the coats to the diners uniformly randomly. On average, how many people return home with their own coat?\n\nMore mathematically, if we shuffle the sequence \\((1, \\dots, n)\\) to generate \\((\\sigma_1, \\sigma_2, \\dots, \\sigma_n)\\), what can we say about the number of times \\(\\sigma_k = k\\)? Specifically, let \\(C\\) be the number of values \\(k\\) such that \\(\\sigma_k = k\\). Computing the distribution of \\(C\\) is somewhat difficult (and a good exercise), but computing \\(\\E[C]\\) is quite easy!\nLet \\(A_k\\) be the event \\(\\sigma_k = k\\): that is, diner \\(k\\) leaves with the proper coat. Clearly \\(C = \\sum_k 1_{A_k}\\), so \\[\\E[C] = \\E\\left[\\sum_{k=1}^n 1_{A_k}\\right] = \\sum_{k=1}^n \\E[1_{A_k}] = \\sum_{k=1}^n P(A_k) = n P(A_1)\\] Because the probabilities are uniform (by assumption), we can write the last step as \\(n P(A_1)\\). Finally, we note that \\(P(A_1)\\) is just the probability that the first person randomly gets the proper coat, which is \\(1/n\\), so we have\n\\[\\E[C] = 1\\]\nThat is, no matter how many coats are checked, on average exactly one person gets the right coat at the end of the evening.\nCompare this to the exact distribution of \\(C\\). Even the ‘simplest’ part - no one getting their own coat - has a difficult probability: \\[\\P(C = 0) = \\sum_{j=0}^n \\frac{(-1)^j}{j!} \\buildrel{n \\to \\infty}\\over\\to\\frac{1}{e} \\approx 36.8\\%\\] And that’s just one term of the sum!"
  },
  {
    "objectID": "notes/expectations.html#variances",
    "href": "notes/expectations.html#variances",
    "title": "What to Expect when You’re Expecting: Notes on Expectations, Variances, and Probabiblities",
    "section": "Variances",
    "text": "Variances\nNow that we have a notion of expectations as best predictions, we might ask how wrong our predictions will be ‘on average’. Naively, we might try to compute \\(\\E[(X - \\mu)]\\) for some guess \\(\\mu = \\E[X]\\). Unfortunately, this turns out to be a little useless:\n\\[\\E[(X - \\E[X])] = \\E[X] - \\E[\\E[X]] = \\E[X] - \\E[X] = 0\\]\nBut of course! On average, the average isn’t too high or too low. It’s unbiased in statistical speak. But we still don’t have an answer to our question. Clearly, if we want to know how far off we are, we need to just measure (unsigned) loss. For reasons we discussed earlier, let’s use the squared error loss:\n\\[\\E[\\text{Loss}] = \\E[(X - \\E[X])^2] = \\V[X]\\]\nThis quantity is called the variance of \\(X\\).\n\n\n\n\n\n\nVariance\n\n\n\nThe variance of a random variable \\(X\\) is given by\n\\[\\V[X] = \\E[(X - \\E[X])^2] = \\E[X^2] - \\E[X]^2\\]\n\n\nThe latter equality follows from standard algebra:\n\\[\\begin{align*}\n\\V[X] &= \\E[(X - \\E[X])^2] \\\\\n      &= \\E[X^2 - 2X \\E[X] + \\E[X]^2] \\\\\n      &= \\E[X^2] - 2\\E[X \\E[X]] + \\E[\\E[X]^2] \\\\\n      &= \\E[X^2] - 2\\E[X]\\E[X] + \\E[X]^2 \\\\\n      &= \\E[X^2] - 2\\E[X]^2 + \\E[X]^2 \\\\\n      &= \\E[X^2] - \\E[X]^2\n\\end{align*}\\]\nReading through this, you might find yourself a bit turned around by all of the \\(\\E[\\E[X]X]\\) trickery. While you can justify each step using our properties of expectation listed above, it’s often easier to just let \\(\\mu=\\E[X]\\) to emphasize that, for purposes of a variance calculation, the mean is essentially just any old number. Repeating the above:\n\\[\\begin{align*}\n\\V[X] &= \\E[(X - \\mu)^2] \\\\\n      &= \\E[X^2 - 2X \\mu + \\mu^2] \\\\\n      &= \\E[X^2] - 2\\E[X *\\mu] + \\E[\\mu^2] \\\\\n      &= \\E[X^2] - 2\\mu\\E[X] + \\mu^2 \\\\\n      &= \\E[X^2] - 2\\mu * \\mu + \\mu^2 \\\\\n      &= \\E[X^2] - 2\\mu^2 + \\mu^2\\\\\n      &= \\E[X^2] - \\mu^2\n\\end{align*}\\]\nReturning to the definition of \\(\\V\\), we recall that it is the expectation of a non-negative quantity (a square). Let \\(E_2 = (X - \\E[X])^2\\). Then \\(\\V[X] = \\E[E_2]\\). Since \\(\\min\\{E_2\\} = 0\\), we have \\(\\V[X] \\geq 0\\).\nThis is our first key property fo variances so we should restate it clearly:\n\nFor any random variable \\(X\\), \\(\\V[X] \\geq 0\\). Furthermore \\(\\V[X] = 0\\) only when \\(X\\) is a constant (degenerate) random variable.\n\nLooking more closely at \\(\\V[X] = \\E[E_2]\\), we get the basic intepretation of mean and variance:\n\n\\(\\E[X]\\) is our best squared error prediction of \\(X\\) (point prediction)\nGiven that, \\(\\V[X]\\) is the error we expect to get from our point prediction\n\nFor our next key property, we’ll use the other side of our basic bounds. Suppose \\(X\\) is a random variable that is never more than \\(M\\) in absolute value, \\(\\max\\{|X\\} \\leq M\\). Then \\(\\V[X] \\leq M^2\\). This is a bit crude, but actually surprisingly useful.\nFor instance, let \\(X\\) be an indicator function, taking only values \\(0, 1\\); then \\(\\V[X] \\leq 1\\). Because of this, for any theorem about expectations, we can convert it to a probability result setting variance to 1.3\nWe said earlier that \\(\\E[\\cdot]\\) behaves nicely under linear operators (multiplication and addition): how does \\(\\V[\\cdot]\\) do?\n\\[\\begin{align*}\n\\V[aX] &= \\E[( aX - \\E[aX])^2] \\\\\n       &= \\E[(aX)^2 - 2(aX)\\E[aX] + \\E[aX]^2] \\\\\n       &= a^2 \\left(\\E[X^2 - 2X \\E[X] + \\E[X]^2]\\right) \\\\\n       &= a^2 \\V[X]\n\\end{align*}\\]\nExercise: Using a similar calculation, show \\(\\V[X + b] = \\V[X]\\).\nPutting these together, we have:\n\\[\\V[aX + b] = a^2\\V[X].\\]\nSo addition does nothing, while scalar multiplication applies quadratically. We can justify these from first principles as well:\n\nIf we shift the whole distribution by \\(b\\), our best guess will shift by \\(b\\) as well. But the problem isn’t any harder, so the variance (expected loss) doesn’t change.\nIf we change the units by a factor of \\(a\\) (e.g., feet to inches), our error multiplies by \\(a\\) and so our squared error multiples by \\(a^2\\).\n\nNote that the above formula works even if \\(a &lt; 0\\) because \\(a^2 &gt; 0\\). If we didn’t square things, we could get a negative variance by accident.4\nHow do variances behave with sums of random variables? E.g., \\(\\V[X + Y]\\). Sadly, the answer is far less clear:\n\\[\\begin{align*}\n\\V[X + Y] &= \\E[( (X + Y) - \\E[X+Y] )^2] \\\\\n          &= \\E[((X - \\E[X]) + (Y - \\E[Y]))^2] \\\\\n          &= \\E[(X-\\E[X])^2] + 2\\E[(X - \\E[X])(Y - \\E[Y])] + \\E[(Y - \\E[Y])]^2\n          &= \\V[X] + \\V[Y] + 2\\E[(X - \\E[X])(Y - \\E[Y])]\n\\end{align*}\\]\nDealing that final term, \\(2\\E[(X - \\E[X])(Y - \\E[Y])]\\), will be the subject of our next discussion of covariance and correlation.\n\nInfinite Variances\nFor some distributions, it is possible that \\(\\V[Y]\\) is infinite. These distributions are sometimes called ‘heavy-tailed’. We will discuss these more in a future set of notes, but in brief, these are the distributions that ‘break’ standard statistics."
  },
  {
    "objectID": "notes/expectations.html#conditional-expectations-and-variances",
    "href": "notes/expectations.html#conditional-expectations-and-variances",
    "title": "What to Expect when You’re Expecting: Notes on Expectations, Variances, and Probabiblities",
    "section": "Conditional Expectations and Variances",
    "text": "Conditional Expectations and Variances\nSee textbook."
  },
  {
    "objectID": "notes/expectations.html#footnotes",
    "href": "notes/expectations.html#footnotes",
    "title": "What to Expect when You’re Expecting: Notes on Expectations, Variances, and Probabiblities",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI would encourage you not too focus too much on this distinction: the magic of calculus is that integrals are just infinite limits of very finely diced sums and the same principles apply here. The branch of mathematics that formalizes this connection is measure theory, but we will just assert that these are fungible constructions in this course.↩︎\nThis is, up to sign, essentially the same as the economists’ notion of utility. You may ponder why statisticians work in terms of ‘pain minimization’ instead of ‘happiness maximization’.↩︎\nAs we will see, this is actually quite loose and we can use \\(\\V[X] \\leq \\frac{1}{4}\\) for indicators, but sometimes \\(1\\) makes the math nicer.↩︎\nWe don’t really do complex numbers in this course, but strictly speaking, we should be multiplying by \\(a\\overline{a}\\), which is always positive, even for complex numbers.↩︎"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "STA 9715 - Course Syllabus",
    "section": "",
    "text": "Professor Michael Weylandt\nDepartment of Information Systems & Statistics\nZicklin School of Business\nBaruch College, CUNY"
  },
  {
    "objectID": "syllabus.html#instructor",
    "href": "syllabus.html#instructor",
    "title": "STA 9715 - Course Syllabus",
    "section": "",
    "text": "Professor Michael Weylandt\nDepartment of Information Systems & Statistics\nZicklin School of Business\nBaruch College, CUNY"
  },
  {
    "objectID": "syllabus.html#course-meetings",
    "href": "syllabus.html#course-meetings",
    "title": "STA 9715 - Course Syllabus",
    "section": "Course Meetings",
    "text": "Course Meetings\n\nLectures\n\nMondays 6:05pm-9:00pm (In-Person)\n\nBaruch Main Campus (1 Bernard Baruch Way)\nNewman Vertical Campus (NVC) 9-170\n\n\n\n\nOffice Hours\n\nIn-Person\n\nBaruch Main Campus (1 Bernard Baruch Way)\nNewman Vertical Campus (NVC) 11-246\nMondays 4:30-5:30pm\nSubject to periodic cancellation (communicated via Brightspace)\n\nVirtual:\n\nThursdays 4:30pm-5:30pm\nZoom link provided via Brightspace"
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "STA 9715 - Course Syllabus",
    "section": "Grading",
    "text": "Grading\n\n50% Mid-Semester Tests (Best two of three; 100 points each; 200 points total)\n\nOctober 7th, covering Weeks 1-4\nNovember 11th, covering Weeks 5-8\nDecember 9th, covering Weeks 10-13\n\n50% Comprehensive Final Exam (200 points total)\n\nScheduled by Baruch Registrar (tentatively December 16th at 6:00pm)\n\n\nSmall amounts of extra credit will be given for active and helpful participation in the course discussion board (Piazza) at the instructor’s discretion.\nFinal course grades will be curved in accordance with relevant program, departmental, school, and college policies.1\n\nWeekly Quizzes\nIn lieu of homework, I will provide a short list of practice problems following each lecture. At the start of the following lecture, a short (15 minute) quiz drawn closely from the practice problems will be administered. The quiz questions will not be verbatim from the practice problems, but if you can answer the practice problems quickly and fluently, the quiz should pose little difficulty.\nThese in-class weekly quizzes will generate extra credit applied to your final aggregate score. Each quiz will receive a score out of 3 added directly to your final score. Because the final aggregate score is out of 400, perfect scores on all 12 weekly quizzes can raise your final aggregate score (pre-curve) up to 9%.\nTo take part in the weekly quizzes, please come to class with both i) a black or blue pen; and ii) a red pen (for peer grading) each week.\nMake-up opportunities for the weekly quizzes will only be allowed in exceptional and unforeseeable circumstances.\n\n\nRegrading Policy\nIf you feel an assignment has been improperly graded, please contact the instructor by private message on the course discussion board within 48 hours of the graded assignment being returned. Note that the instructor will regrade the assignment de novo, so your grade may be adjusted upwards or downwards."
  },
  {
    "objectID": "syllabus.html#tentative-course-schedule",
    "href": "syllabus.html#tentative-course-schedule",
    "title": "STA 9715 - Course Syllabus",
    "section": "Tentative Course Schedule",
    "text": "Tentative Course Schedule\n\n\n\n\n\n\n\n\n\n\n\n\nWeek\nLecture Date\nTopics\nPre-Reading\nPost-Reading\nPractice Problems\nMid-Semester Tests\n\n\n\n\n1\nSeptember 9th, 2024\nFoundations of Probability:\n\nCourse Overview\nThe Logic of Theory\nProbability Axioms\nElements of Combinatorics\n\nDFO §6.1,\nGS §1.2, §3.1-3.3\nBH §1.1-1.4, §1.6-1.7, §A.1-A.2\nBH §1.9: 3, 4, 5, 12, 15, 23, 24, 26, 28, 29, 31, 41, 44, 45, 49\n\n\n\n2\nSeptember 16th, 2024\nConditionality and Marginality:\n\nConditional Probabilities\nExpectation\nVariance\nMoments\nConditional Expectation\n\nDFO §6.3\nGS §4.1, 6.1-6.2\nBH §2.1-2.9, §4.1-4.6, §A.8-A.10\nBH §2.11: 1, 3, 9, 11, 14, 19, 30, 48, 59\n§4.12: 2, 6, 12, 14, 34, 35\n\n\n\n3\nSeptember 23rd, 2024\nDiscrete Probability Calculations:\n\nProbability Mass Functions\nNamed Discrete Distributions\n\nGS §5.1\nBH §3.1-3.10\nBH: §3.12: 2, 3, 6, 9, 10, 15, 17, 18, 21, 23, 24, 25, 31, 34, 35, 38, 40\n\n\n\n4\nSeptember 30th, 2024\nFrom Discrete to Continuous Random Variables:\n\nCalculus Review\nProbability Density Functions\nCumulative Distribution Functions\n\nDFO §6.2, 6.5\nGS §5.2, 4.2, 6.3\nBH §5.1-5.8\nBH §5.10: 1, 3, 4, 6, 8, 9, 18, 19, 21, 24, 25, 27, 34, 37, 42, 44\n\n\n\n5\nOctober 7th, 2024\nHeavy Tails: What and Why?\nNone (test prep)\nBH §6.1-6.3\nHandout to be distributed\nBH §6.10: 3, 9, 11, 12\nTest I: Covering Weeks 1-4\n\n\n6\nTUESDAY October 15th, 2024 (Note date change)\nRandom Vectors:\n\nReview of Multivariable Calculus\nJoint Distributions\nMarginal Distributions\nConditional Distributions\n\nDFO §5.1-5.2\nBH §7.1-7.2,§ A.3, §A.6-A.7\nBH §7.8: 1, 4, 5, 6, 8, 9, 10, 11, 13, 14, 16, 17, 18,\n\n\n\n7\nOctober 21st, 2024\nCovariance and Correlation: Working with Linear Combinations of Random Variables\nGS §7.1-7.2\nBH §6.4-6.6, §7.3\nBH §7.8: 31, 33, 36, 37, 38, 41, 43, 48, 49, 51, 54, 59\n\n\n\n8\nOctober 28th, 2024\nThe Multivariate Normal Distribution and its Progeny:\n\nReview of Linear Algebra\nProperties of the Multivariate Normal Distribution\nDerived Distributions\n\nDFO §2.1-2.7, §3.1-3.4, $4.2-4.4\nBH §7.5-7.6, §10.4\nBH 7.8: §72, 73, 74, 77, 78,\nHandout to be provided\n\n\n\n9\nNovember 4th, 2024\nSpecial Topics: Probability, Polling, and Prediction\n\n\n\n\n\n\n10\nNovember 11th, 2024\nPerils and Paradoxes in Expectations:\n\nSelection and Sampling Biases\nImplications for (Over-)Fitting of Models\n\nNone (test prep)\nDFO §8.1-8.3, §8.6\nBH §9.1-9.3, §9.5-9.7\nBH §4.12: 17\n§9.9: 1, 13, 15, 16, 25, 29, 38, 39, 40, 43,\nTest II: Covering Weeks 5-8\n\n\n11\nNovember 18th, 2024\nProbability Inequalities and Limit Theorems\nGS §8.1-8.2\nBH §10.1-10.2\nBH §10.7:\n1, 2, 4, 6, 7, 13, 15, 16, 21,\n\n\n\n12\nNovember 25th, 2024\nDistributional Limits and the Central Limit Theorem\nGS §9.1-9.3\nBH §10.3\nBH §10.7: 22, 23, 24, 26, 28, 29, 30, 36, 37\n\n\n\n13\nDecember 2nd, 2024\nConcentration of Measure: Generalized Limit Theory\nHandout to be distributed.\nHandout to be distributed.\nHandout to be distributed.\n\n\n\n14\nDecember 9th, 2024\nComputing with Randomness: an Introduction to Monte Carlo Methods\nNone (test prep)\n\nNone (last day of class)\nTest III: Covering Weeks 10-13\n\n\n\nNote on Week 9: On November 4th (Election Eve), we will meet at our regular time (6:05pm). Instead of our usual format (quiz, peer evaluation, review, new material), we will discuss a set of election-related special topics, including i) construction and evaluation of probabilistic election forecasts; ii) martingale properties and their implications for forecasting; iii) conformal calibration as applied to real-time election results. New Material from Week 8 (Multivariate Normal Distribution) will be quizzed during Week 10 (November 11th).\nAll syllabus provisions subject to change with suitable advance notice.\nChanges will be announced in class and via Brightspace."
  },
  {
    "objectID": "syllabus.html#pre--and-post-reading-suggestions",
    "href": "syllabus.html#pre--and-post-reading-suggestions",
    "title": "STA 9715 - Course Syllabus",
    "section": "Pre- and Post-Reading Suggestions",
    "text": "Pre- and Post-Reading Suggestions\nStudents learn material most effectively when exposed to it on multiple occasions, ideally using alternative presentations strategies and formats.2 To this end, suggested pre-reading and post-reading is provided for each week of the course. Students are encouraged to pre-read the recommended text, which typically presents that week’s material in a less technical / more intuitive manner, before each week’s course session. Similarly, students are encouraged to review the post-reading for each week after lecture to see additional examples of topics covered.\nWhile lectures will focus primarily on ‘big picture’ and ‘major themes’, the recommended reading, especially the post-reading from BH, provides additional coverage of relevant technical detail.\nStudents with prior exposure to topics in probability may choose to omit pre-reading. In general, GS pre-reading introduces fundamentals of probability while DFO pre-reading reviews relevant mathematical tools. Students may also elect to consume post-reading as part of completing that week’s practice problems, rather than as a separate activity.\nStudents are responsible for all material appearing in the pre-reading, in lecture, and in the post-reading, but students will not be evaluated on reading per se."
  },
  {
    "objectID": "syllabus.html#footnotes",
    "href": "syllabus.html#footnotes",
    "title": "STA 9715 - Course Syllabus",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTheoretically, this may result in scores equivalent to an A in an un-curved course receiving a lower grade in this course. In practice, the instructor will design course assessments to induce a range of scores and does not anticipate “down-curving” happening.↩︎\nHaoyu Chen and Jiongjiong Yang. “Multiple Exposures Enhance Both Item Memory and Contextual Memory over Time”. Frontiers in Psychology 11. November 2020. DOI:10.3389/fpsyg.2020.565169↩︎"
  },
  {
    "objectID": "notes/random_vectors.html",
    "href": "notes/random_vectors.html",
    "title": "Properties of Random Vectors",
    "section": "",
    "text": "\\[\\newcommand{\\P}{\\mathbb{P}} \\newcommand{\\E}{\\mathbb{E}} \\newcommand{\\V}{\\mathbb{V}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\bx}{\\mathbf{x}} \\newcommand{\\by}{\\mathbf{y}} \\newcommand{\\bX}{\\mathbf{X}} \\newcommand{\\bY}{\\mathbf{Y}} \\newcommand{\\bZ}{\\mathbf{Z}}\\]\nIn this set of notes, we begin our study of random vectors. Before we discuss random vectors, let’s first review how vectors in general behave."
  },
  {
    "objectID": "notes/random_vectors.html#review-random-variables-mean-and-variance",
    "href": "notes/random_vectors.html#review-random-variables-mean-and-variance",
    "title": "Properties of Random Vectors",
    "section": "Review: Random Variables, Mean, and Variance",
    "text": "Review: Random Variables, Mean, and Variance\nRecall that a random variable, \\(X\\), is functionally specified by two components:\n\nThe support of \\(X\\) is the set of values \\(X\\) can take, encoded as real numbers. In the discrete random variable context, the support of \\(X\\) is typically integral: \\(\\textsf{supp}(X) \\subseteq \\mathbb{Z}\\)\nThe probability mass function (PMF) of \\(X\\) which is a mapping from \\(\\textsf{supp}(X)\\) to \\([0, 1]\\) satisfying: \\[ \\sum_{x \\in \\textsf{supp}(X)} \\P(X = x) = 1\\]\n\nAlongside these two defining quantities, we often report the mean (or expected value) and variance of a random variable:\n\\[\\begin{align*}\n\\E[X] &= \\sum_{x \\in \\textsf{supp}(X)} x\\, \\P(X = x) \\\\\n\\V[X] &= \\E[(X - \\E[X])^2] \\\\\n      &= \\sum_{x \\in \\textsf{supp}(X)} (x - \\E[X])^, \\P(X = x) \\\\\n      &= \\left(\\sum_{x \\in \\textsf{supp}(X)} x^2\\, \\P(X = x)\\right) - \\E[X]^2 \\\\\n      &= \\E[X^2] - \\E[X]^2\n\\end{align*}\\]\nRecall that the variance \\(\\V[X]\\) is always non-negative and is strictly positive if \\(|\\textsf{supp}(X)| \\geq 2\\) - that is, if \\(X\\) is “truly” random in the sense of possibly taking more than one value.1"
  },
  {
    "objectID": "notes/random_vectors.html#bernoulli",
    "href": "notes/random_vectors.html#bernoulli",
    "title": "Properties of Random Vectors",
    "section": "Bernoulli",
    "text": "Bernoulli\nOur simplest distribution is the Bernoulli distribution, named after the great Swiss mathematician Jacob Bernoulli. The Bernoulli distribution models a single “coin flip”-type event: that is, an event with two possible outcomes conventionally called “success” and “failure”. To make this a random variable, we associate “success” with the value \\(1\\) and “failure” with the value \\(0\\).\nNote that, even though we called these two outcomes “success” and “failure”, we can use a Bernoulli distribution for anything with two outcomes: left vs. right, up vs. down, right vs. wrong, or happened vs didn’t happen. These last two pairings are incredibly important. Whenever we make a binary prediction, it is either correct or incorrect - a Bernoulli outcome. Because of this, Bernoulli random variables are commonly used to study the predictive accuracy of classification systems, an incredibly important topic in Machine Learning. Bernoulli distributions are also “the most extreme” version of bounded random variables (putting all of the probability on two endpoints) so we can often bound the performance of any predictive model for bounded outcomes using Bernoulli variables.\nA Bernoulli distributed \\(X\\) is then defined by the PMF:\n\\[ P(X = 1) = p \\text{ and } P(X = 0) = 1 - P(X \\neq 0) = 1 - P(X = 1) = 1 - p = q \\]\n\n\n\n\n\n\nTip\n\n\n\nMake sure you can explicitly justify each step connecting \\(P(X = 0)\\) to \\(1 - p\\).\n\n\nIf we are clever - and recall that \\(p^0 = 1\\) for any \\(p \\neq 0\\)-we can write the Bernoulli PMF as\n\\[ \\P(X = x) = p^x(1-p)^{1-x} = p^xq^{1-x} \\text{ for } x \\in \\{0, 1\\}\\]\nNote that, even though we sometimes write the Bernoulli with two parameters, \\(p,q\\), it is really a one-parameter distribution since \\(q = 1 - p\\) by construction.\nThe mean and variance are quite easy to calculate:\n\\[\\begin{align*}\n\\E[X] &= \\sum_{x \\in \\textsf{supp}(X)} x * \\P(X = x) \\\\\n      &= 0 * \\P(X = 0) + 1 * \\P(X = 1) \\\\\n      &= 0 * (1 - p) + 1 * p \\\\\n      &= p\n\\end{align*}\\]\n\n\n\n\n\n\nTip\n\n\n\nWhy are we not surprised to see “expectation = probability” here? Think about the connection between Bernoulli random variables and indicator functions.\n\n\nWhile we can compute the variance directly, it’s a bit easier to work from \\(\\V[X] = \\E[X^2] - \\E[X]^2\\) if we note that \\(X^2 = X\\) for a Bernoulli random variable.\n\\[\\begin{align*}\n\\V[X] &= \\E[X^2] - \\E[X]^2 \\\\\n      &= \\E[X] - \\E[X^2] \\\\\n      &= p - p^2 \\\\\n      &= p(1 - p) \\\\\n      &= pq\n\\end{align*}\\]\nFrom this expression, it’s not hard to see that the variance of a Bernoulli random variable is never more than \\(0.25\\) and that the maximum is obtained when \\(p = q = 0.5\\): that is, the “50/50” coin-flip is the “most random” coin."
  },
  {
    "objectID": "notes/random_vectors.html#rademacher",
    "href": "notes/random_vectors.html#rademacher",
    "title": "Properties of Random Vectors",
    "section": "Rademacher",
    "text": "Rademacher\nA Rademacher variable is a close cousin of the Bernoulli often used to model incremental processes that, at each step, either become “a bit better” or “a bit worse”. Specifically, while a Bernoulli is a 0/1 random variable, Rademachers take values \\(\\pm 1\\).\n\\[P(X = x) = \\begin{cases} 1 & \\text{ with probability } p \\\\ 0 & \\text{ with probability } q = 1 - p \\end{cases}\\]\nWhile Bernoulli variables come with all sorts of weights, Rademachers are normally symmetric, taking \\(\\pm 1\\) with equal 50% probability.\nTo get the mean and variance of a Rademacher, let’s use the linearity of expectation. Let \\(R \\sim \\text{Rademacher}(p)\\); then \\(R = 2B - 1\\) where \\(B \\sim \\text{Bernoulli}(p)\\). Hence,\n\\[\\begin{align*}\n\\E[R] &= \\E[2B - 1] \\\\\n      &= 2\\E[B] - 1 \\\\\n      &= 2p - 1\n\\end{align*}\\]\nSimilarly,\n\\[\\begin{align*}\n\\V[R] &= \\V[2B - 1] \\\\\n      &= 2^2 \\V[B] \\\\\n      &= 4 * p * (1-p) \\\\\n      &= 4pq\n\\end{align*}\\]\nAs before, this is “most random” when \\(p = q = 0.5\\). In this case, however we get a variance of 1 for \\(R\\) instead of \\(0.25\\) for \\(B\\). Tricks like this make Rademachers very useful in theoretical analyses."
  },
  {
    "objectID": "notes/random_vectors.html#binomial",
    "href": "notes/random_vectors.html#binomial",
    "title": "Properties of Random Vectors",
    "section": "Binomial",
    "text": "Binomial\nThe Binomial distribution arises as the sum of a known, fixed number of \\(n\\) identically and independently distributed (IID) Bernoulli random variables. This concept of IID is incredibly important and we will see it many times throughout this course.\nBecause a binomial is a sum if IID elements, its mean and variance are relatively simple to compute. Let \\(X \\sim \\text{Binomial}(n, p)\\) - that is, let \\(X\\) be the sum of \\(n\\) \\(\\text{Bernoulli}(p)\\) random variables, \\(X_1, X_2, \\dots, X_n\\). Then\n\\[\\begin{align*}\n\\E[X] &= \\E\\left[\\sum_{i=1}^n X_i\\right] \\\\\n      &= \\sum_{i=1}^n \\E[X_i] \\text{ by linearity of expectation} \\\\\n      &= \\sum_{i=1}^n p \\\\\n      &= np\n\\end{align*}\\]\nSimilarly,\n\\[\\begin{align*}\n\\V[X] &= \\V\\left[\\sum_{i=1}^n X_i\\right] \\\\\n      &= \\sum_{i=1}^n \\V[X_i] \\text{ (Variances add for independent RVs)}\\\\\n      &= \\sum_{i=1}^n p(1-p) \\\\\n      &= n p(1-p)\n\\end{align*}\\]\nWhile the mean and variance are quite easy, it’s a bit trickier to derive the PMF from first principles. This is an important element of “probability thinking” - it is often easier to compute aspects of distributions indirectly instead of computing the distribution in toto and then deriving its properties. In particular, when you can break a problem into a set of IID elements - as we have done here - tools like linearity, expectation, and variance make life quite easy.\nSuppose we want to compute \\(\\P(X = x)\\). We know that we must have \\(x\\) successes and \\(n - x\\) failures for a sum of \\(x\\). The probability of the event\n\\[\\P\\left[(X_1, X_2, \\dots, X_n) = (\\underbrace{1, 1, \\dots, 1}_{\\text{$x$ times}}, \\underbrace{0, 0, \\dots, 0}_{\\text{$n-x$ times}})\\right]\\]\ncan be computed by independence of the individual Bernoullis:\n\\[\\begin{align*}\n\\P\\left[(X_1, X_2, \\dots, X_n) = (\\underbrace{1, 1, \\dots, 1}_{\\text{$x$ times}}, \\underbrace{0, 0, \\dots, 0}_{\\text{$n-x$ times}})\\right] &= \\prod_{i=1}^n P(X_i = x_i) \\\\\n&= \\prod_{i=1}^x \\P(X_i = 1) * \\prod_{i=x+1}^{n} \\P(X_i = 0) \\\\\n&=  \\prod_{i=1}^x p * \\prod_{i=x+1}^{n} (1-p) \\\\\n&= p^x (1-p)^{n-x}\n\\end{align*}\\]\nBut \\(\\P(X = x)\\) is not just this particular ordering of \\((X_1, \\dots, X_n)\\). For purposes of the Binomial random variable, we don’t really care what order these happened, so we have \\(\\binom{n}{x}\\) possible orderings (of \\(n\\) flips, choosing \\(x\\) of them to be 1). Because the set of possible orderings is a disjoint partition, we can get the aggregate probability \\(\\P(X = x)\\) by multipling \\(\\binom{n}{x}\\) by the probability of each outcome, which we already showed was \\(p^x(1-p)^{n-x}\\). Taken together, this gives us:\n\\[\\P(X = x) = \\binom{n}{x}p^x(1-p)^x \\text{ for } x \\in \\{0, \\dots, n\\}\\]\nWe pause here to note that the name binomial distribution comes from the similarity between this PMF and the standard binomial expansion:\n\\[(a + b)^n = \\sum_{x=0}^n \\binom{n}{x} a^xb^{n-x} \\]\nWe get the binomial distribution by setting \\(a = p, b = 1 - p\\). This lets us easily confirm that the sum of the binomial PMF is indeed 1, as we require: \\[\\begin{align*}\n\\sum_{x = 0}^n \\P(X = x) &= \\sum_{x=0}^n \\binom{n}{x}p^x(1-p)^x \\\\\n&= (p + (1-p))^n \\\\\n&= 1^n \\\\\n&= 1\n\\end{align*}\\]"
  },
  {
    "objectID": "notes/random_vectors.html#poisson",
    "href": "notes/random_vectors.html#poisson",
    "title": "Properties of Random Vectors",
    "section": "Poisson",
    "text": "Poisson\nThe Binomial distribution occurs with a fixed number of events \\(n\\) and known probability \\(p\\). An important ‘limiting’ case is where the number of events is very large and the probability is very small; in this case, the important number is the expected number of successes \\(\\mu = n * p\\). We model this case as a Poisson random variable. Specifically, a Poisson model is a model for count values that are, on average, reasonably small (around \\(\\mu\\)) but potentially unbounded.\nThe Poisson PMF with mean \\(\\mu\\) is given by \\[\\P(X = k) \\frac{\\mu^k e^{-\\mu}}{k!} \\text{ for } k \\in \\{0, 1, 2 \\dots, \\} \\]\nAs we have discussed before, factorials grow even more rapidly than exponentials, so this tends towards zero as \\(k\\) gets large: that is, very large counts become exceedingly unlikely. You can derive the Poisson PMF from the binomial PMF by setting \\(p = \\mu / n\\) and taking the \\(n \\to \\infty\\) limit, but the arithmetic is a bit cumbersome and so we do not pursue it here.\nWhile we have already called \\(\\mu\\), the Poisson mean, we can show this explicitly:\n\\[\\begin{align*}\n\\E[X] &= \\sum_{x=0}^{\\infty} x \\P(X = x) \\\\\n      &= \\sum_{x=0}^{\\infty} x * \\frac{\\mu^x e^{-\\mu}}{x!} \\\\\n      &= \\sum_{x=1}^{\\infty} x * \\frac{\\mu^x e^{-\\mu}}{x!} \\\\\n      &= e^{-\\mu} \\sum_{x=1}^{\\infty} x * \\frac{\\mu^x}{x!} \\\\\n      &= e^{-\\mu} \\mu \\sum_{x=1}^{\\infty} \\frac{\\mu^{x-1}}{(x-1)!} \\\\\n      &= e^{-\\mu} \\mu \\sum_{y=0}^{\\infty} \\frac{\\mu^{y}}{y!} \\\\\n      &= e^{-\\mu} \\mu e^{\\mu} \\\\\n      &= \\mu\n\\end{align*}\n\\]\nNext, we turn to the variance. As similar argument shows \\(\\E[X^2] = \\mu^2 + \\mu\\), so we get \\(\\V[X] = \\E[X^2] - \\E[X]^2 = \\mu^2 + \\mu - \\mu^2 = \\mu\\).\nThis is a remarkable property: for a Poisson random variable, a single parameter controls both the mean and the variance. Further more, as the expected number of counts becomes larger, so does the variance.\nIf we think back to the binomial connection, we can see how this arises: the binomial variance is given by \\(n p q = np(1-p) = np - np^2\\). We create a Poisson limit by setting \\(p = \\mu / n\\) and letting \\(n \\to \\infty\\). Here, this yields:\n\\[np - np^2 = n * \\left(\\frac{\\mu}{n}\\right) - n* \\left(\\frac{\\mu}{n}\\right)^2 = \\mu - \\mu^2 / n\\].\nAs \\(n \\to \\infty\\), we simply get the variance \\(\\mu\\) which matches direct calculation. At a high level, for the Poisson mean to get larger, we need \\(p\\) to get larger, which in turn raises the variance (since we are far below the ‘turning point’ of binomial variance at \\(p = 0.5\\))."
  },
  {
    "objectID": "notes/random_vectors.html#geometric",
    "href": "notes/random_vectors.html#geometric",
    "title": "Properties of Random Vectors",
    "section": "Geometric",
    "text": "Geometric\nSo far, we have considered distributions that count the number of times “success” happens out of a fixed number of trials. We now turn to distributions with a fixed number of successes, but a random number of total trials. In these models, the random variable of interest is the total number of trials.2\nOur basic model is the geometric distribution. The total number of coin flips until we get our first heads (inclusive. If we denote this variable as \\(X\\), we can easily see that the PMF is given by:\n\\[\\P(X = x) = p(1-p)^{x-1} \\text{ for } x \\in \\{1, 2, \\dots\\}\\]\nThis PMF arises because we don’t need to account for order: we know the last flip is a success with probability \\(p\\) and the previous \\(x-1\\) flips are each failures, occurring with probability \\(q = 1-p\\). By independence, these probabilities can be combined with simple multiplication, giving the resulting PMF.\nMean and variance can be computed in many ways. Here, we’ll show a general approach that uses differentiation and geometric series creatively to compute several useful quantities in the same manner.\nRecall that a geometric series satisfies:\n\\[\\sum_{i=0}^{\\infty} ar^i = \\frac{a}{1-r}\\]\nWe can differentiate both sides of this with respect to \\(r\\) to find:\n\\[\\begin{align*}\n\\sum_{i=0}^{\\infty} ar^i &= \\frac{a}{1-r} \\\\\n\\frac{\\text{d}}{\\text{d}r}\\sum_{i=0}^{\\infty} ar^i &= \\frac{\\text{d}}{\\text{d}r}\\frac{a}{1-r} \\\\\n\\sum_{i=0}^{\\infty} air^{i-1} &= \\frac{a}{(1-r)^2} * (-1) * (-1)\\\\\n\\sum_{i=0}^{\\infty} air^{i-1} &= \\frac{a}{(1-r)^2}\n\\end{align*}\\]\nwhere the right hand side picks up two \\(-1\\) terms: one from the exponent on the denominator and one from the minus sign inside the denominator (chain rule).\nWe can repeat this trick again:\n\\[\\begin{align*}\n\\sum_{i=0}^{\\infty} air^{i-1} &= \\frac{a}{(1-r)^2} \\\\\n\\frac{\\text{d}}{\\text{d}r}\\sum_{i=0}^{\\infty} air^{i-1} &= \\frac{\\text{d}}{\\text{d}r}\\frac{a}{(1-r)^2} \\\\\n\\sum_{i=0}^{\\infty} ai(i-1)r^{i-2} &= \\frac{2a}{(1-r)^3}\n\\end{align*}\\]\nWith these three formulae in hand, we are ready to show the basic properties of a geometric random variable:\n\\[\\begin{align*}\n\\sum_{x=1}^{\\infty} \\P(X = x) &= \\sum_{x=1}^{\\infty} p(1-p)^{x-1} \\\\\n                              &= \\sum_{y=0}^{\\infty} p(1-p)^y \\\\\n                              &= \\frac{p}{1-(1-p)} \\\\\n                              &= 1\n\\end{align*}\\]\nwhere we used only the “basic” geometric series formula here.\nNext, for expectation:\n\\[\\begin{align*}\n\\E[X] &= \\sum_{x=1}^{\\infty} x \\P(X = x) \\\\\n      &= \\sum_{x=1}^{\\infty} x p(1-p)^{x-1} \\\\\n      &= \\frac{p}{(1-(1-p))^2} \\\\\n      &= \\frac{p}{p^2} \\\\\n      &= \\frac{1}{p}\n\\end{align*}\\]\nwhere we used our first differentiated formula. This fits our intuition: if something happens \\(p\\) times, we need \\(1/p\\) tries for it to happen on average.\nSimilarly, the second differentiated formula can be used to compute \\(\\E[X(X-1)] = \\E[X^2] - \\E[X]\\) and from there, \\(\\V[X]\\) = $. Again, comparing against intuition, variance is highest for small \\(p\\) - if something is very rare, it’s very hard to say how long until it happens.\nThe geometric distribution has a remarkable property called memorylessness: \\(P(X &gt; m + n | X &gt; n) = P(X &gt; m)\\). This says that, if you have already tried \\(n\\) times, the probability of taking \\(m + n\\) tries is the same as \\(m\\) tries if starting afresh. The coin flip process is “memoryless” in that it doesn’t remember or depend upon what came before. Because of the memorylessness property, we can never say a success is “due up” in a geometric process. This is at stark odds with our intuition about gambling - if something hasn’t happened for a while, it’s bound to happen. If the events are truly IID, this simply isn’t the case.\nMemorylessness is a bit magic: the geometric distribution (and its close kin) is actually the only discrete distribution with this property. The other famous distribution with this property is the (continuous) exponential distribution, which has the same negative exponential structure. For this reason, the geometric distribution is sometimes called the discrete exponential distribution, though that name has mainly fallen out of paper.\nTo show memorylessness, we can use some of our basic principles of conditional PMFs. Before doing so, let’s define some useful alternative formulations of the PMF.\n\nThe CDF - cumulative distribution function - is \\[F(x) = \\P(X \\leq x) = \\sum_{i=1}^{x} \\P(X = x)\\]\nThe CCDF - complementary CDF - is \\[\\overline{F}(x) = \\P(X &gt; x) = \\sum_{x+1}^{\\infty} \\P(X = x)\\]\n\nClearly, \\(F(x) + \\overline{F}(x) = 1\\) for all \\(x\\). With these in hand, it’s easy to state the manipulation formulas for “self-conditioned” random variables.\n\n\\(\\P(X = x | X \\leq x) = \\P(X = x) / F(x)\\)\n\\(\\P(X = x | X &gt; x) = \\P(X = x) / \\overline{F}(x)\\)\n\nWe will use the latter form for showing memorylessness of the geometric.\nFirst, note that\n\\[\\begin{align*}\nF(x) &= \\sum_{i=1}^x p(1-p)^{i-1}  \\\\\n     &= p \\sum_{j=0}^{x-1} (1-p)^j \\\\\n     &= p * \\frac{1-(1-p)^{x}}{1-(1-p)} \\\\\n     &= p * \\frac{1 - (1-p)^x}{p}\\\\\n     &= 1 - (1-p)^x\n\\end{align*}\\]\nusing the formula for a finite geometric series. From this, we have \\(\\overline{F}(x) = (1-p)^x\\). At this point, you should be realizing that things are likely to work out very nicely when dividing \\(\\P(X = x)\\) and \\(\\overline{F}(x)\\).\nHence, \\[\\begin{align*}\n\\P(X = x + y | X &gt; y) &= \\frac{\\P(X = x + y) }{\\overline{F}(y)} \\\\\n                      &= \\frac{p(1-p)^{x+y-1}}{(1-p)^x} \\\\\n                      &= p(1-p)^{y-1} \\\\\n                      &= P(Y = y)\n\\end{align*}\\] where \\(Y\\) is a “new” (restarted) random variable."
  },
  {
    "objectID": "notes/random_vectors.html#negative-binomial",
    "href": "notes/random_vectors.html#negative-binomial",
    "title": "Properties of Random Vectors",
    "section": "Negative Binomial",
    "text": "Negative Binomial\nTODO"
  },
  {
    "objectID": "notes/random_vectors.html#hypergeometric",
    "href": "notes/random_vectors.html#hypergeometric",
    "title": "Properties of Random Vectors",
    "section": "Hypergeometric",
    "text": "Hypergeometric\nTODO"
  },
  {
    "objectID": "notes/random_vectors.html#footnotes",
    "href": "notes/random_vectors.html#footnotes",
    "title": "Properties of Random Vectors",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRecall that we sometimes consider constants, \\(a\\), as “degenerate” random variables satisfying \\(P(X = a) = 1\\) to make the statements of our theorems easier.↩︎\nUnfortunately, there are two conflicting conventions used for some of these distributions: some count the total number of trials (success + failure) while others count only the number of failures. This is not a hard change - it’s just a simple \\(+s\\) for \\(s\\) successes - but it makes comparing formulae from different references a bit inconvenient.↩︎"
  },
  {
    "objectID": "notes/random_vectors.html#properties-of-vectors",
    "href": "notes/random_vectors.html#properties-of-vectors",
    "title": "Properties of Random Vectors",
    "section": "Properties of Vectors",
    "text": "Properties of Vectors\nIn mathematics, a vector - random or otherwise - is a fixed-length ordered collection of numbers. When we want to be precise about the size of a vector, we often call it a “tuple”, e.g., a length-three vector is a “triple”, a length-four vector is a “4-tuple”, a length-five vector is a “5-tuple” etc..\nSo, these are all vectors:\n\n\\((3, 4)\\)\n\\((1, 1, 1)\\)\n\\((1, 5, 6, 10)\\)\n\nWhen we want to talk about the set of vectors of a given size, we use the Cartesian product of sets. For two sets, \\(A, B\\), the product set \\(A \\times B\\) is the set of all pairs, with the first element from \\(A\\) and the second from \\(B\\). In mathematical notation,\n\\[A \\times B = \\left\\{(a, b): a \\in A, b \\in B\\right\\} \\]\nThis set-builder notation is read as follows: “The Cartesian Product of \\(A\\) and \\(B\\) is the set of all pairs \\((a, b)\\) such that \\(a\\) is in \\(A\\) and \\(b\\) is in \\(B\\).”\nIf \\(A\\) and \\(B\\) are the same set, we define a Cartesian power as follows:\n\\[A^2 = A \\times A = \\left\\{(a_1, a_2): a_1 \\in A, a_2 \\in A\\right\\}\\]\nNote that even though the sets \\(A\\) and \\(A\\) in this product are the same, the elements in each pair may vary. For example, if \\(A = \\{1, 2, 3\\}\\), we have\n\\[A^2 = \\left\\{(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 1), (3,2), (3, 3)\\right\\}\\]\nNote that vectors are ordered pairs so \\((2, 1) \\neq (1, 2)\\). From here, it should be pretty easy to convince yourself that set sizes play nicely with Cartesian products:\n\n\\(|A \\times B| = |A| |B|\\)\n\\(|A^k| = |A|^k\\)\n\nThe most common set of vectors we use are those where each element is an arbitrary real number. The set of vectors of length \\(n\\) (\\(n\\)-tuples) is thus \\(\\R^n\\). We rarely mix vectors of different lengths, so we don’t really have a name or notation for the “combo pack” \\(\\R^2 \\cup \\R^3 \\cup \\R^4\\).\nConventionally, vectors are written in bold (if on a computer) or with a little arrow on top (hand written): so a vector called “x” would be denoted \\(\\mathbf{x}\\) or \\(\\vec{x}\\). The elements of \\(\\bx\\) are denoted by subscripts \\(\\bx = (x_1, x_2, \\dots, x_n)\\).\n\nVector Arithmetic\nWe have three arithmetic operations we can perform on general vectors. The simplest is scalar multiplication. A scalar is a non-vector number, i.e., a ‘regular’ number. Scalar multiplication consists of applying the scalar independently to each element of a vector.\n\\[\\alpha \\bx = \\alpha(x_1, x_2, \\dots, x_n) = (\\alpha x_1, \\alpha x_2, \\dots, \\alpha x_n)\\]\nFor example, if \\(\\bx = (3, 4)\\) and \\(\\alpha = 2\\), we have \\[\\alpha \\bx = (6, 8)\\]\nNote that the output of scalar multiplication is always a vector of the same length as the input.\nWe also have the ability to add vectors. This again is performed element-wise.\n\\[\\bx + \\by = (x_1, \\dots, x_n) + (y_1, \\dots, y_n) = (x_1 + y_1, \\dots, x_n + y_n) \\]\nNote that we can’t add vectors of different lengths (recall our “no mixing” rule) and the output length is always the same as the input lengths.\nFinally, we have the vector inner product, defined as:\n\\[\\langle \\bx, \\by \\rangle = x_1y_1 + x_2y_2 + \\dots + x_ny_n \\]\nYou might have seen this previously as the “dot” product. The inner product takes two length-\\(n\\) vectors and gives back a scalar. This structure might seem a bit funny, but as we’ll see below, it’s actually quite useful.\nYou might ask if there’s a “vector-out” product: there is one, with the fancy name “Hadamard product”, but it doesn’t play nicely with other tools, so we don’t use it very much.\nThese tools play nicely together:\n\n\\(\\alpha(\\bx + \\by) = \\alpha \\bx + \\alpha \\by\\) (Distributive)\n\\(\\langle \\alpha \\bx, \\by \\rangle = \\alpha \\langle \\bx, \\by \\rangle\\) (Associative)\n\\(\\langle \\bx, \\by \\rangle = \\langle \\by, \\bx \\rangle\\) (Commutative)\n\n\n\nVector Length and Angle\nWe sometimes want to think about the “size” of a vector, analogous to the absolute value of a scalar. In scalar-world, we say “drop the sign” but there’s not an obvious analogue to a sign for a vector. For instance, if \\(\\bx = (3, -4)\\) is \\(\\bx\\) “positive”, “negative” or somewhere in beetween?\nWe note a trick from scalar-land: \\(|x| = \\sqrt{x^2}\\). We can use the same idea for vectors:\n\\[ \\|\\bx\\| = \\sqrt{\\langle \\bx, \\bx\\rangle} = \\sqrt{\\sum_{i=1}^n x_i^2}\\]\nThis quantity, \\(\\|\\bx\\|\\), is called the norm or length of a vector. We use the double bars to distinguish it from the absolute value of a scalar, but it’s fundamentally the same idea.\nIn \\(\\R^2\\), we recognize this formula for length as the Pythagorean theorem:\n\\[ \\|(3, 4)\\| = \\sqrt{3^2 + 4^2} = \\sqrt{25} = 5 \\]\nWe also sometimes want to define the angle between two vectors. We can define this as:\n\\[ \\cos \\angle(\\bx, \\by) = \\frac{\\langle \\bx, \\by\\rangle}{\\|\\bx\\|\\|\\by\\|} \\Leftrightarrow \\angle(\\bx, \\by) = \\cos^{-1}\\left(\\frac{\\langle \\bx, \\by\\rangle}{\\|\\bx\\|\\|\\by\\|}\\right)\\]\nWe won’t use this formula too often, but it’s good to have it."
  },
  {
    "objectID": "notes/random_vectors.html#random-vectors",
    "href": "notes/random_vectors.html#random-vectors",
    "title": "Properties of Random Vectors",
    "section": "Random Vectors",
    "text": "Random Vectors\nJust like a vector is a ordered collection of “regular” numbers, a random vector is an ordered collection of random variables.\nWhere do random vectors come from? Everywhere!\nEssentially any data collection can be thought of “vectorly”. If we record multiple pieces of information for each sample, each sample gives us a vector of information."
  },
  {
    "objectID": "notes/random_vectors.html#distributions-on-random-vectors",
    "href": "notes/random_vectors.html#distributions-on-random-vectors",
    "title": "Properties of Random Vectors",
    "section": "Distributions on Random Vectors",
    "text": "Distributions on Random Vectors\nHow might we begin to specify probabilities on vectors? We have essentially two approaches. We can begin from a definition of how we want probabilities to behave, extending the rules we developed for random variables, or we can assemble a distribution on a vector from distributions on variables defined in just the right way. Both of these will be fruitful, but let’s begin with the axiomatic approach.\n\nProperties of Multivariate Distributions\nIn our discussion of random variables, we highlighted the role of the CDF as a tool that can unify both discrete and continuous variates. Our definition of random variables - real-valued random quantities - guaranteed that quantities like \\(\\P(X \\leq x)\\) were always defined.\nUnfortunately, as we move from \\(\\R\\)-valued to \\(\\R^n\\)-valued quantities, it’s not quite as simple to make sense of statements like \\(\\bX \\leq \\bx\\) (bold here for vectors). Most commonly, we define vector inequalities elementwise, so\n\\[\\bX \\leq \\bx \\implies X_1 \\leq x_1 \\text{ and } X_2 \\leq x_2 \\dots \\text{ and} X_n \\leq x_n\\]\nUnfortunately, this has several limitations. Most notably, we no longer have the “three-way” logic of standard inequalities, it is possible for neither \\(\\bX \\leq \\bx\\) or \\(\\bX &gt; \\bx\\) to be true: some components can be less than while others can be greater than. Even so, we could still try to build a multi-dimensional CDF for \\(\\bX\\), \\(F_{\\bX}(\\bx)  = \\P(\\bX \\leq \\bx)\\).\nWe know that as \\(\\bx \\to \\infty\\), we must have \\(F_{\\bX}((\\infty, \\infty, \\dots, \\infty)) = 1\\) and that \\(F_{\\bX}\\) must be monotonically increasing in each component. (Why?) Unfortunately, that’s not a particularly nice type of function, so it’s hard to naturally come up with examples like this.\nIt may be more fruitful to “piece-together” multivariate distributions from univariate components. To do so, we’ll actually put the PDF front and center in the multivariate case.\nThe properties we expect of a PDF translate naturally to the multivariate case:\n\n\\(\\int_{\\R^n} f_{\\bX}(\\bx)\\,\\text{d}\\bx = 1\\)\n\\(f_{\\bX}(\\cdot) \\geq 0\\) everywhere\n\nAs always, replace the integral with a sum if \\(\\bX\\) is discrete.\nThe only wrinkle here is working with the multivariate integral, \\(\\int_{\\R^n}\\), so let’s do some practice problems.\n\nExample 1: 2D Uniform\nLet’s first consider a 2D uniform distribution on the unit square \\([0, 1]^2\\), that is, the set of all \\((x, y)\\) such that \\(0 \\leq x \\leq 1\\) and \\(0 \\leq y \\leq 1\\) (with no restrictions on \\(x, y\\) together). Since we want to build a uniform distribution, all we can assume is \\[f_{(x, y)}(x, y) = c\\] for some constant \\(c \\geq 0\\). We know that this quantity must integrate to 1, so let’s work out the integral:\n\\[\\begin{align*}\n1 &= \\iint_{[0, 1]^2} c\\,\\text{d}x\\,\\text{d}y \\\\\n&= c \\iint_{[0, 1]^2} \\text{d}x\\,\\text{d}y \\\\\n&= c \\int_{0}^1 \\int_0^1 \\text{d}x\\,\\text{d}y \\\\\n&= c \\int_{0}^1 \\left.x\\right|_0^1\\,\\text{d}y \\\\\n&= c \\int_{0}^1 1\\text{d}y \\\\\n&= c \\left(\\left.y\\right|_0^1\\right) \\\\\n&= c \\\\\n\\implies c &= 1\n\\end{align*}\\]\nso the uniform distribution on the square has constant PDF 1. This is quite nice: by extending the above argument, we can actually see that for any set \\(A \\subseteq [0, 1]^2\\), \\(\\P(\\bX \\in A) = \\text{Area}(A)\\). This justifies our intuition for uniform distributions.\nWe can extend this idea to a fun special case: let \\(A\\) be a quarter circle embedded in the unit square:\n\nx &lt;- seq(0, 1, length.out=201)\ny &lt;- sqrt(1 - x^2)\nplot(x, y,type=\"h\", col=\"red2\", asp=1, xlim=c(0, 1))\nsegments(c(0, 0, 1, 0), \n         c(0, 0, 0, 1), \n         c(0, 1, 1, 1), \n         c(1, 0, 1, 1), \n         lwd=3)\n\n\n\n\n\n\n\n\nClearly the square has area 1 while the circle has area \\(\\pi/4\\).\nIf we were to pick a point uniformly from within the square, there is thus a \\(\\pi/4\\) chance that it falls inside the red area. This is a bit impractical to do by hand (though people did it back in the day!), but quite easy to do on a computer:\n\nn &lt;- 1e6 # Generate one million points IID uniform on the unit square\nX &lt;- runif(n, min=0, max=1)\nY &lt;- runif(n, min=0, max=1)\n\n# Check fraction that are in the red area\nin_red &lt;- (X^2 + Y^2) &lt; 1\n\nP_red &lt;- mean(in_red)\nprint(P_red)\n\n[1] 0.785004\n\n\nFrom this, we can actually ‘back out’ the value of \\(\\pi\\) as \\(4 * \\hat{\\P}(\\text{red})\\):\n\npi_approx &lt;- 4 * P_red\nprint(pi_approx)\n\n[1] 3.140016\n\n\nNot terrible!\nFor a bit of review, let’s compute the variance of our \\(\\pi\\)-estimator.\nDefine \\[\\hat{\\Pi}_n = 4 * \\text{Fraction of points in red area} = \\frac{4}{n}\\sum_{i=1}^n 1_{\\text{Red Area}}(X_i)\\]\nHere, we use the average indicator of the red area to compute the fraction of points in the red zone. Since each point is selected randomly, the indicators are independent and hence we can compute the variance quite simply:\n\\[\\begin{align*}\n\\V[\\hat{\\Pi}_n] &= \\V\\left[\\frac{4}{n}\\sum_{i=1}^n 1_{\\text{Red Area}}(X_i)\\right] \\\\\n&= \\frac{16}{n^2}\\V\\left[\\sum_{i=1}^n 1_{\\text{Red Area}}(X_i)\\right] \\\\\n&= \\frac{16}{n^2}\\sum_{i=1}^n \\V[1_{\\text{Red Area}}(X_i)] \\\\\n&= \\frac{16}{n^2}\\sum_{i=1}^n \\V[\\text{Bernoulli}(\\pi/4)] \\\\\n&= \\frac{16}{n^2}\\sum_{i=1}^n \\frac{\\pi}{4}\\left(1-\\frac{4}{\\pi}\\right) \\\\\n&= \\frac{16}{n^2} *  n * \\frac{\\pi}{4}\\left(1-\\frac{\\pi}{4}\\right) \\\\\n&= \\frac{4\\pi}{n}\\left(1-\\frac{\\pi}{4}\\right) \\\\\n&\\approx \\frac{2.7}{n}\n\\end{align*}\\]\nSo our example above with one million points has a variance of about 0.0003%, giving a standard deviation of 0.0016. That means that, very roughly, we get about 3 digits of accuracy from one million points, consistent with above.\nWe note that this analysis requires us to know the probability we are trying to estimate. That’s not a super-practical assumption, but if we recall that the Bernoulli variance is bounded above by \\(0.25\\), we can get an upper bound of\n\\[\\V[\\hat{\\Pi}_n] \\leq \\frac{4}{n}\\]\nwhich really isn’t too much worse than the “true” value.\nThis approach might seem a bit crazy - and it definitely is not a very efficient way to compute \\(\\pi\\) - but it’s actually incredibly useful. Variants of this approach, known as the “Monte Carlo” approach, are used throughout advanced science and engineering to compute probabilities of adverse events which depend on uncertain physical parameters. We will say more about MC methods later in this course.\n\n\n\nProduct Distributions: Independence\nOne easy way to create vector distributions is via product distributions. Given a random variable \\(X\\) and a second random variable \\(Y\\), mutually independent, and each with PDF \\(f_X(\\cdot)\\) and \\(f_Y(\\cdot)\\) respectively, we can create a new random variable \\(\\bZ = (X, Y)\\). The PDF of \\(\\bZ\\) is given by\n\\[f_{\\bZ}(\\bz) = f_{(X, Y)}((z_1, z_2)) = f_{X}(z_1)f_{Y}(z_2)\\]\nThis structure, where we can break things apart into two terms is called a product distribution and it’s the most general form of independence we consider in this course. In fact, you can basically take this as as a definition of independence. Two random variables \\(X, Y\\) are independent if their joint PDF is just the product of their separate PDFs.\nRecall that, in our initial discussion of independent events, we said \\(A, B\\) are independent if \\(\\P(A \\cap B) = \\P(A)\\P(B)\\). If you squint, this looks a lot like our definition of a product distribution. We can make this (semi-)formal:\n\\[\\begin{align*}\n\\P(X \\in A_X, Y \\in A_Y) &= \\int_{A_X}\\int_{A_Y} f_{(X, Y)}(x, y)\\,\\text{d}y\\,\\text{d}x \\\\\n&= \\int_{A_X}\\int_{A_Y} f_X(x)f_Y(y)\\,\\text{d}y\\,\\text{d}x \\tag{Assuming product structure}\\\\\n&= \\int_{A_X} f_X(x)\\int_{A_Y}f_Y(y)\\,\\text{d}y\\,\\text{d}x \\tag{Factor out $x$-terms}\\\\\n&= \\int_{A_X} f_X(x)\\P(Y \\in A_Y)\\,\\text{d}x \\tag{Integrate $y$-terms}\\\\\n&= \\P(Y \\in A_Y)\\int_{A_X} f_X(x)\\,\\text{d}x \\tag{Factor out constant}\\\\\n&= \\P(Y \\in A_Y)\\P(X \\in A_X) \\tag{Integrate $x$-terms}\n\\end{align*}\\]\nSince we made no assumptions on the shapes of \\(A_X, A_Y\\), we see that this argument holds for any events defined in terms of one vector component only.\nLet’s stay this again because it’s important:\n\nIf the random vector \\((X, Y)\\) has a PDF that has a product structure, \\(X\\) and \\(Y\\) are independent and so are any pair of events based on them separately.\n\nThis may be a bit counterintuitive:\n\n\\(f_{(X, Y)}\\propto xy\\) has \\(X, Y\\) independent\n\\(f_{(X, Y)}\\propto x + y\\) does not have \\(X, Y\\) independent\n\nCan you see why? What about \\(4 + 2\\cos(x) + 2\\sin(y) + \\cos(x)\\sin(y) = (2+\\cos(x))(2+\\sin(y))\\)?\nAt the beginning of this course, we emphasized that the conditions under which an “and” statement could be evaluated by multiplying probabilities were a bit subtle: we have now fully expressed these conditions using the notions of independence and factorizability.\n\n\nMarginal Distributions\nIn other circumstances, we may have a joint PDF and want to only look at one component. The “induced” distribution that we get by ignoring \\(Y\\) and only looking at \\(X\\) is called the marginal distribution.\nTo build up the mathematics of marginal distributions, let’s introduce the special value \\(\\textsf{ANY}\\), which does exactly what it sounds like it should. Use of \\(\\textsf{ANY}\\) lets us express the marginal distribution PDF from the joint PDF:\n\\[f_{X}(x) = f_{(X, Y)}(x, \\textsf{ANY})\\].\nHere, since we don’t care about the value of \\(Y\\) (\\(\\textsf{ANY}\\)), we integrate over its whole range to find:\n\\[f_{X}(x) = \\int f_{(X, Y)}(x, y)\\,\\text{d}y\\]\nThe “x” is not integrated since we’re keeping it “free” in the marginal PDF. Of course, if we have a product structure, this is particularly nice:\n\\[f_{X}(x) = \\int f_{(X, Y)}(x, y)\\,\\text{d}y = f_X(x) \\int f_Y(y)\\,\\text{d}y = f_X(x)\\]\nSo the marginal distribution of two independent random variables is “just” the factor we care about. (Independence makes life so easy!)\nWhat about a case without independence? Suppose we have \\(f_{(X, Y)}(x, y) c(x+y)\\). We first want to find the constant \\(c\\) \nTODO\n\n\nConditional Distributions\nTODO\n\n\nNamed Distributions\nTODO"
  },
  {
    "objectID": "notes/covariance.html",
    "href": "notes/covariance.html",
    "title": "Correlation and Covariance",
    "section": "",
    "text": "\\[\\newcommand{\\P}{\\mathbb{P}} \\newcommand{\\E}{\\mathbb{E}} \\newcommand{\\V}{\\mathbb{V}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\bx}{\\mathbf{x}} \\newcommand{\\by}{\\mathbf{y}} \\newcommand{\\bX}{\\mathbf{X}} \\newcommand{\\bY}{\\mathbf{Y}} \\newcommand{\\bZ}{\\mathbf{Z}} \\newcommand{\\C}{\\mathbb{C}} \\newcommand{\\indep}{\\,\\perp\\!\\!\\!\\!\\perp\\,} \\]\nHaving introduced random vectors last week, we are now ready to introduce the fundamental concepts of covariance and correlation. To date, we have mainly focused on manipulating independent random variables, establishing useful results like \\(n^{-1/2}\\) convergence of averages, the law of large numbers, and tail bounds derived from Markov and Chebyshev’s inequalities. While we introduced these in the context of independence for mathematical convenience, they thankfully hold in more generality.\nThat generality is a very good thing - real data is rarely uncorrelated and independent in the ways we’ve supposed so far. In our “big data” era, we work with data derived from thousands of sensors writing thousands upon thousands of records to massive hard drives. But we don’t deploy these sensors so easily. When we measure all these quantities, correlation is unavoidable. For example, when fleets of sensors are deployed to get high resolution temperature measurements all over NYC, these aren’t independent! An “above average” hot day in the East Village is almost certainly a day that is hot in the West Village as well! It may be slightly less hot out in Queens, but it would be shocking if Queens had a blizzard on the same day. This is perhaps the Monkey’s Paw of Big Data - we have so much more data, but it’s not clear whether we have truly gained information. Concepts of correlation and covariance will let us start untangling this thicket."
  },
  {
    "objectID": "notes/covariance.html#covariance-of-random-variables",
    "href": "notes/covariance.html#covariance-of-random-variables",
    "title": "Correlation and Covariance",
    "section": "Covariance of Random Variables",
    "text": "Covariance of Random Variables\n\nProduct Expectation of Independent Variates\nBefore we take on the general case of vectors, let’s first develop the theory of covariance for a pair of random variables.\nTo date, we have seen that expectations play well with sums:\n\\[ \\E[X + Y] = \\E[X] + \\E[Y] \\]\nwith no further assumptions on \\(X, Y\\) or the relationship between them. What can we say about the relationship between expectations and products? Depending on your point-of-view, we will be able to say very much or nothing at all.\nLet’s review the case of \\(X, Y\\) independent. We know that for independent random variables, their PDFs factorize as\n\\[f_{(X, Y)} = f_Xf_Y\\]\nUsing this, we can compute the product expectation \\(\\E[XY]\\) easily:\n\\[\\begin{align*}\n\\E[XY] &= \\iint_{\\R^2} (xy) * f_{(X, Y)}(x, y) \\,\\text{d}x\\,\\text{d}y \\\\\n&= \\int_{\\R} \\int_{\\R} (xy) * f_X(x)f_Y(y) \\,\\text{d}x\\,\\text{d}y \\\\\n&= \\int_{\\R} y * f_Y(y)\\int_{\\R} x * f_X(x) \\,\\text{d}x\\,\\text{d}y \\\\\n&= \\int_{\\R} y * f_Y(y)\\E[X]\\,\\text{d}y \\\\\n&= \\E[X]\\int_{\\R} y * f_Y(y)\\,\\text{d}y \\\\\n&= \\E[X]\\E[Y]\n\\end{align*}\\]\nso, for independent \\((X, Y)\\), expectation plays nicely with products!\nWhat can we say for general (non-independent) \\(X, Y\\)? Not so much just yet.\n\n\nVariance of Sums of Independent Random Variables\nNext, let’s recall how variance of sums behave for independent random variables:\n\\[ \\V[X + Y] = \\V(X) + \\V(Y) \\text{ if } X, Y \\text{ are independent} \\]\nWe can write this in terms of the standard deviation of \\(X, Y\\) and \\(Z = X + Y\\):\n\\(\\sigma_Z^2 = \\sigma_X^2 + \\sigma_Y^2 \\text{ if } X \\indep Y\\)\nRecall that \\(X \\indep Y\\) means \\(X, Y\\) are independent.\nWritten this way, we see an obvious parallel with the Pythagorean theorem (\\(c^2 + a^2 + b^2\\)) in the result, but there’s also a parallel in the assumptions. In the Pythagorean theorem, we get this nice “sum of squares” behavior from right angleness; in probability, we seem to get it from independence.\nThis isn’t a coincidence.\n\nVariance of Sums of Non-Independent Random Variables\nLet’s now look at what we can say about \\(\\V[X + Y]\\) when \\(X, Y\\) are not assumed independent.\n\\[\\begin{align*}\n\\V[X + Y] &= \\E[(X + Y)^2] - \\E[X + Y]^2 \\\\\n&= \\E[(X^2 + 2 X Y + Y^2)] - (\\E[X] + \\E[Y])^2 \\\\\n&= \\E[X^2] + 2\\E[XY] + \\E[Y^2] - \\left(\\E[X]^2 + 2\\E[X]\\E[Y] + \\E[Y]^2\\right) \\\\\n&= \\left(\\E[X^2] - \\E[X]^2\\right) + 2\\left(\\E[XY] - \\E[X]\\E[Y]\\right) + \\left(\\E[Y^2] - \\E[Y]^2\\right) \\\\\n&= \\V[X] + 2\\left(\\E[XY] - \\E[X]\\E[Y]\\right) + \\V[Y]\n\\end{align*}\\]\nThis middle term is new! From our discussion above, we know it is zero if \\(X, Y\\) are independent, but what can we say about it generally?\nNot much! But we can name it. We define the covariance of two random variables \\(X, Y\\) to be\n\\[\\C[X, Y] = \\E[XY] - \\E[X]\\E[Y]\\]\nWhat can we say about covariance? First, we note that, like variance, it has an equivalent form:\n\\[\\C[X, Y] = \\E\\left[(X - \\E[X])(Y - \\E[Y])\\right]\\]\n(You should be able to prove this is algebraically equivalent.)\nFrom here, we actually see that variance as we have understood it to date is a special case of covariance. Specifically,\n\\[\\V[X] = \\C[X, X]\\]\nThat is, the variance of a random variable is just a measure of how much it covaries with itself. Put another way, all the covariance is variance when a variable is compared to itself.\nCovariance has many of the algebraic properties of variance:\n\n\\(\\C[X + a, Y + b] = \\C[X, Y]\\)\n\\(\\C[aX, bY] = ab \\C[X, Y]\\)\n\nUnlike variance, covariance can be negative. Notably,\n\\[\\C[X, -X] = -\\C[X, X] = -\\V[X]\\]\n\n\n\nCorrelation\nOn its own, covariance, like variance, is a bit tricky to understand because it’s “product-ish” (recall variance is “squared-ish”). To understand variance, we took a square root and called it standard deviation. Unfortunately, that’s not quite as safe for covariance since it can be negative.\nWe can do something similarly useful - note that:\n\\[\\begin{align*}\n\\C[X, Y] &= \\E[(X - \\E[X])(Y - \\E[Y])] \\\\\n& \\leq \\E[|X - \\E[X]| * |Y - \\E[Y]|] \\\\\n&\\leq \\E[|X - \\E[X]|] \\E[|Y - \\E[Y]|] \\\\\n&\\leq \\sqrt{\\E[(X - \\E[X])^2]} \\sqrt{\\E[(Y - \\E[Y])^2]} \\\\\n&= \\sqrt{\\V[X]}\\sqrt{\\V[Y]} \\\\\n&= \\sigma_X \\sigma_Y\n\\end{align*}\\]\nso\n\\[ -\\sigma_X\\sigma_Y \\leq \\C[X, Y] \\leq \\sigma_X\\sigma_Y \\]\n(Note that the set of calculations above isn’t a rigorous proof. We need to invoke the Cauchy-Schwarz inequality to make this formal.)\nThis motivates us to look at the quantity\n\\[\\rho_{X,Y} = \\frac{\\C[X, Y]}{\\sqrt{\\V[X]}\\sqrt{V[Y]}} = \\frac{\\C[X, Y]}{\\sqrt{\\C[X, X]}\\sqrt{\\C[Y, Y]}} = \\frac{\\C[X, Y]}{\\sigma_X\\sigma_Y}\\]\nThis unitless quantity is called the correlation of \\(X\\) and \\(Y\\). From our analysis above, we have:\n\\[-1 \\leq \\rho_{X, Y} \\leq 1\\]\nso correlation is bounded between -1 and 1.\nLet’s turn back to \\(\\V[Z] = \\V[X + Y]\\). From above, we have\n\\[\\V[Z] = \\V[X] + \\V[Y] + 2\\C[X, Y]\\]\nIf we substitute in the definition of correlation, we have:\n\\[\\sigma_Z^2 = \\sigma_X^2 + \\sigma_Y^2 + 2\\sigma_X\\sigma_Y \\rho_{X, Y}\\]\nIf the independent-\\(X, Y\\) formula reminded us of the Pythagorean theorem, this should look a lot like the Law of Cosines, with the correlation playing the role of the “cosine angle” between \\(X, Y\\).\nThis isn’t just an overly convoluted metaphor: it is “mathematically real”. Given two (non-random) vectors, we define the angle between them by:\n\\[\\cos \\angle(\\bx, \\by) = \\frac{\\langle \\bx, \\by\\rangle}{\\|\\bx\\| \\|\\by\\|} = \\frac{\\langle \\bx, \\by\\rangle}{\\sqrt{\\langle \\bx, \\bx\\rangle \\langle, \\by,\\by\\rangle}\\]\nIf we interpret \\(\\langle \\cdot, \\cdot \\rangle\\) as vector equivalent of covariance, and vector norm as the equivalent of standard deviation, the pieces all fit together perfectly.\nWe know from trigonometry that \\(|\\cos\\theta| \\leq 1\\) for all angles \\(\\theta\\), with \\(\\cos \\theta = 1\\), \\(\\cos \\theta = 0\\), and \\(\\cos \\theta = -1\\) being special values. But we’ve seen these already!\n\n\\(\\cos \\theta = 0 \\leftarrow \\rho_{X, Y} = 0\\). This is what we see for independent random variables!\n\\(\\cos \\theta = 1 \\leftarrow \\rho_{X, Y} = 1\\). This is what we saw for \\(\\C[X, X] = \\V[X]\\). If the cosine of the angle is 1, that means the angle is zero, so the two variables are “exactly” on top of each other. That’s true for \\(X\\) and \\(X\\).\n\\(\\cos \\theta = -1 \\leftarrow \\rho_{X, Y} = -1\\). We saw this above for \\(X\\) and \\(-X\\) which go in “exactly opposite directions”.\n\nThis connection between “right angles” and “zero correlation” is quite well-known and slips into the day-to-day conversation of data scientists. In particular, two vectors at right angles are called orthogonal (from “ortho-” meaning “right”) so it’s very common to hear mathematical folks refer two two unrelated issues as “orthogonal”."
  },
  {
    "objectID": "notes/covariance.html#random-vectors",
    "href": "notes/covariance.html#random-vectors",
    "title": "Correlation and Covariance",
    "section": "Random Vectors",
    "text": "Random Vectors\nJust like a vector is a ordered collection of “regular” numbers, a random vector is an ordered collection of random variables.\nWhere do random vectors come from? Everywhere!\nEssentially any data collection can be thought of “vectorly”. If we record multiple pieces of information for each sample, each sample gives us a vector of information."
  },
  {
    "objectID": "notes/covariance.html#distributions-on-random-vectors",
    "href": "notes/covariance.html#distributions-on-random-vectors",
    "title": "Correlation and Covariance",
    "section": "Distributions on Random Vectors",
    "text": "Distributions on Random Vectors\nHow might we begin to specify probabilities on vectors? We have essentially two approaches. We can begin from a definition of how we want probabilities to behave, extending the rules we developed for random variables, or we can assemble a distribution on a vector from distributions on variables defined in just the right way. Both of these will be fruitful, but let’s begin with the axiomatic approach.\n\nProperties of Multivariate Distributions\nIn our discussion of random variables, we highlighted the role of the CDF as a tool that can unify both discrete and continuous variates. Our definition of random variables - real-valued random quantities - guaranteed that quantities like \\(\\P(X \\leq x)\\) were always defined.\nUnfortunately, as we move from \\(\\R\\)-valued to \\(\\R^n\\)-valued quantities, it’s not quite as simple to make sense of statements like \\(\\bX \\leq \\bx\\) (bold here for vectors). Most commonly, we define vector inequalities elementwise, so\n\\[\\bX \\leq \\bx \\implies X_1 \\leq x_1 \\text{ and } X_2 \\leq x_2 \\dots \\text{ and} X_n \\leq x_n\\]\nUnfortunately, this has several limitations. Most notably, we no longer have the “three-way” logic of standard inequalities, it is possible for neither \\(\\bX \\leq \\bx\\) or \\(\\bX &gt; \\bx\\) to be true: some components can be less than while others can be greater than. Even so, we could still try to build a multi-dimensional CDF for \\(\\bX\\), \\(F_{\\bX}(\\bx)  = \\P(\\bX \\leq \\bx)\\).\nWe know that as \\(\\bx \\to \\infty\\), we must have \\(F_{\\bX}((\\infty, \\infty, \\dots, \\infty)) = 1\\) and that \\(F_{\\bX}\\) must be monotonically increasing in each component. (Why?) Unfortunately, that’s not a particularly nice type of function, so it’s hard to naturally come up with examples like this.\nIt may be more fruitful to “piece-together” multivariate distributions from univariate components. To do so, we’ll actually put the PDF front and center in the multivariate case.\nThe properties we expect of a PDF translate naturally to the multivariate case:\n\n\\(\\int_{\\R^n} f_{\\bX}(\\bx)\\,\\text{d}\\bx = 1\\)\n\\(f_{\\bX}(\\cdot) \\geq 0\\) everywhere\n\nAs always, replace the integral with a sum if \\(\\bX\\) is discrete.\nThe only wrinkle here is working with the multivariate integral, \\(\\int_{\\R^n}\\), so let’s do some practice problems.\n\nExample 1: 2D Uniform\nLet’s first consider a 2D uniform distribution on the unit square \\([0, 1]^2\\), that is, the set of all \\((x, y)\\) such that \\(0 \\leq x \\leq 1\\) and \\(0 \\leq y \\leq 1\\) (with no restrictions on \\(x, y\\) together). Since we want to build a uniform distribution, all we can assume is \\[f_{(x, y)}(x, y) = c\\] for some constant \\(c \\geq 0\\). We know that this quantity must integrate to 1, so let’s work out the integral:\n\\[\\begin{align*}\n1 &= \\iint_{[0, 1]^2} c\\,\\text{d}x\\,\\text{d}y \\\\\n&= c \\iint_{[0, 1]^2} \\text{d}x\\,\\text{d}y \\\\\n&= c \\int_{0}^1 \\int_0^1 \\text{d}x\\,\\text{d}y \\\\\n&= c \\int_{0}^1 \\left.x\\right|_0^1\\,\\text{d}y \\\\\n&= c \\int_{0}^1 1\\text{d}y \\\\\n&= c \\left(\\left.y\\right|_0^1\\right) \\\\\n&= c \\\\\n\\implies c &= 1\n\\end{align*}\\]\nso the uniform distribution on the square has constant PDF 1. This is quite nice: by extending the above argument, we can actually see that for any set \\(A \\subseteq [0, 1]^2\\), \\(\\P(\\bX \\in A) = \\text{Area}(A)\\). This justifies our intuition for uniform distributions.\nWe can extend this idea to a fun special case: let \\(A\\) be a quarter circle embedded in the unit square:\n\nx &lt;- seq(0, 1, length.out=201)\ny &lt;- sqrt(1 - x^2)\nplot(x, y,type=\"h\", col=\"red2\", asp=1, xlim=c(0, 1))\nsegments(c(0, 0, 1, 0), \n         c(0, 0, 0, 1), \n         c(0, 1, 1, 1), \n         c(1, 0, 1, 1), \n         lwd=3)\n\n\n\n\n\n\n\n\nClearly the square has area 1 while the circle has area \\(\\pi/4\\).\nIf we were to pick a point uniformly from within the square, there is thus a \\(\\pi/4\\) chance that it falls inside the red area. This is a bit impractical to do by hand (though people did it back in the day!), but quite easy to do on a computer:\n\nn &lt;- 1e6 # Generate one million points IID uniform on the unit square\nX &lt;- runif(n, min=0, max=1)\nY &lt;- runif(n, min=0, max=1)\n\n# Check fraction that are in the red area\nin_red &lt;- (X^2 + Y^2) &lt; 1\n\nP_red &lt;- mean(in_red)\nprint(P_red)\n\n[1] 0.785258\n\n\nFrom this, we can actually ‘back out’ the value of \\(\\pi\\) as \\(4 * \\hat{\\P}(\\text{red})\\):\n\npi_approx &lt;- 4 * P_red\nprint(pi_approx)\n\n[1] 3.141032\n\n\nNot terrible!\nFor a bit of review, let’s compute the variance of our \\(\\pi\\)-estimator.\nDefine \\[\\hat{\\Pi}_n = 4 * \\text{Fraction of points in red area} = \\frac{4}{n}\\sum_{i=1}^n 1_{\\text{Red Area}}(X_i)\\]\nHere, we use the average indicator of the red area to compute the fraction of points in the red zone. Since each point is selected randomly, the indicators are independent and hence we can compute the variance quite simply:\n\\[\\begin{align*}\n\\V[\\hat{\\Pi}_n] &= \\V\\left[\\frac{4}{n}\\sum_{i=1}^n 1_{\\text{Red Area}}(X_i)\\right] \\\\\n&= \\frac{16}{n^2}\\V\\left[\\sum_{i=1}^n 1_{\\text{Red Area}}(X_i)\\right] \\\\\n&= \\frac{16}{n^2}\\sum_{i=1}^n \\V[1_{\\text{Red Area}}(X_i)] \\\\\n&= \\frac{16}{n^2}\\sum_{i=1}^n \\V[\\text{Bernoulli}(\\pi/4)] \\\\\n&= \\frac{16}{n^2}\\sum_{i=1}^n \\frac{\\pi}{4}\\left(1-\\frac{4}{\\pi}\\right) \\\\\n&= \\frac{16}{n^2} *  n * \\frac{\\pi}{4}\\left(1-\\frac{\\pi}{4}\\right) \\\\\n&= \\frac{4\\pi}{n}\\left(1-\\frac{\\pi}{4}\\right) \\\\\n&\\approx \\frac{2.7}{n}\n\\end{align*}\\]\nSo our example above with one million points has a variance of about 0.0003%, giving a standard deviation of 0.0016. That means that, very roughly, we get about 3 digits of accuracy from one million points, consistent with above.\nWe note that this analysis requires us to know the probability we are trying to estimate. That’s not a super-practical assumption, but if we recall that the Bernoulli variance is bounded above by \\(0.25\\), we can get an upper bound of\n\\[\\V[\\hat{\\Pi}_n] \\leq \\frac{4}{n}\\]\nwhich really isn’t too much worse than the “true” value.\nThis approach might seem a bit crazy - and it definitely is not a very efficient way to compute \\(\\pi\\) - but it’s actually incredibly useful. Variants of this approach, known as the “Monte Carlo” approach, are used throughout advanced science and engineering to compute probabilities of adverse events which depend on uncertain physical parameters. We will say more about MC methods later in this course.\n\n\n\nProduct Distributions: Independence\nOne easy way to create vector distributions is via product distributions. Given a random variable \\(X\\) and a second random variable \\(Y\\), mutually independent, and each with PDF \\(f_X(\\cdot)\\) and \\(f_Y(\\cdot)\\) respectively, we can create a new random variable \\(\\bZ = (X, Y)\\). The PDF of \\(\\bZ\\) is given by\n\\[f_{\\bZ}(\\bz) = f_{(X, Y)}((z_1, z_2)) = f_{X}(z_1)f_{Y}(z_2)\\]\nThis structure, where we can break things apart into two terms is called a product distribution and it’s the most general form of independence we consider in this course. In fact, you can basically take this as as a definition of independence. Two random variables \\(X, Y\\) are independent if their joint PDF is just the product of their separate PDFs.\nRecall that, in our initial discussion of independent events, we said \\(A, B\\) are independent if \\(\\P(A \\cap B) = \\P(A)\\P(B)\\). If you squint, this looks a lot like our definition of a product distribution. We can make this (semi-)formal:\n\\[\\begin{align*}\n\\P(X \\in A_X, Y \\in A_Y) &= \\int_{A_X}\\int_{A_Y} f_{(X, Y)}(x, y)\\,\\text{d}y\\,\\text{d}x \\\\\n&= \\int_{A_X}\\int_{A_Y} f_X(x)f_Y(y)\\,\\text{d}y\\,\\text{d}x \\tag{Assuming product structure}\\\\\n&= \\int_{A_X} f_X(x)\\int_{A_Y}f_Y(y)\\,\\text{d}y\\,\\text{d}x \\tag{Factor out $x$-terms}\\\\\n&= \\int_{A_X} f_X(x)\\P(Y \\in A_Y)\\,\\text{d}x \\tag{Integrate $y$-terms}\\\\\n&= \\P(Y \\in A_Y)\\int_{A_X} f_X(x)\\,\\text{d}x \\tag{Factor out constant}\\\\\n&= \\P(Y \\in A_Y)\\P(X \\in A_X) \\tag{Integrate $x$-terms}\n\\end{align*}\\]\nSince we made no assumptions on the shapes of \\(A_X, A_Y\\), we see that this argument holds for any events defined in terms of one vector component only.\nLet’s stay this again because it’s important:\n\nIf the random vector \\((X, Y)\\) has a PDF that has a product structure, \\(X\\) and \\(Y\\) are independent and so are any pair of events based on them separately.\n\nThis may be a bit counterintuitive:\n\n\\(f_{(X, Y)}\\propto xy\\) has \\(X, Y\\) independent\n\\(f_{(X, Y)}\\propto x + y\\) does not have \\(X, Y\\) independent\n\nCan you see why? What about \\(4 + 2\\cos(x) + 2\\sin(y) + \\cos(x)\\sin(y) = (2+\\cos(x))(2+\\sin(y))\\)?\nAt the beginning of this course, we emphasized that the conditions under which an “and” statement could be evaluated by multiplying probabilities were a bit subtle: we have now fully expressed these conditions using the notions of independence and factorizability.\n\n\nMarginal Distributions\nIn other circumstances, we may have a joint PDF and want to only look at one component. The “induced” distribution that we get by ignoring \\(Y\\) and only looking at \\(X\\) is called the marginal distribution.\nTo build up the mathematics of marginal distributions, let’s introduce the special value \\(\\textsf{ANY}\\), which does exactly what it sounds like it should. Use of \\(\\textsf{ANY}\\) lets us express the marginal distribution PDF from the joint PDF:\n\\[f_{X}(x) = f_{(X, Y)}(x, \\textsf{ANY})\\].\nHere, since we don’t care about the value of \\(Y\\) (\\(\\textsf{ANY}\\)), we integrate over its whole range to find:\n\\[f_{X}(x) = \\int f_{(X, Y)}(x, y)\\,\\text{d}y\\]\nThe “x” is not integrated since we’re keeping it “free” in the marginal PDF. Of course, if we have a product structure, this is particularly nice:\n\\[f_{X}(x) = \\int f_{(X, Y)}(x, y)\\,\\text{d}y = f_X(x) \\int f_Y(y)\\,\\text{d}y = f_X(x)\\]\nSo the marginal distribution of two independent random variables is “just” the factor we care about. (Independence makes life so easy!)\nWhat about a case without independence? Suppose we have \\(f_{(X, Y)}(x, y) c(x+y)\\). We first want to find the constant \\(c\\) \nTODO\n\n\nConditional Distributions\nTODO\n\n\nNamed Distributions\nTODO"
  },
  {
    "objectID": "notes/covariance.html#zero-covariance-vs-independence",
    "href": "notes/covariance.html#zero-covariance-vs-independence",
    "title": "Correlation and Covariance",
    "section": "Zero Covariance vs Independence",
    "text": "Zero Covariance vs Independence\nSo far, we have seen that independence implies zero covariance. But is the opposite true? NO\nA simple example: let \\(X \\sim \\text{Uniform}([-1, 1])\\) and let \\(Y = X^2\\). We can see that \\(X\\) and \\(Y\\) have zero correlation, even though they are clearly not independent.\n\\[\\begin{align*}\n\\E[XY] &= \\E[X^3]  \\\\\n       &= \\int_{-1}^1 x^3 * f_X(x)\\,\\text{d}x \\\\\n       &= \\int_{-1}^1 x^3 * \\frac{1}{2}\\,\\text{d}x \\\\\n       &= \\left.\\frac{x^4}{2}\\right|_{-1}^1 \\\\\n       &= \\frac{(1)^4 - (-1)^4}{2} \\\\\n       &= 0\n\\end{align*}\\]\nSimilarly, \\(\\E[X] = 0\\), so \\(\\C[X, Y] = \\E[XY] - \\E[X]\\E[Y] = 0 - 0 * \\E[Y] = 0\\).\n\nIndependence as “not correlatable”"
  },
  {
    "objectID": "notes/covariance.html#covariance-of-random-vectors",
    "href": "notes/covariance.html#covariance-of-random-vectors",
    "title": "Correlation and Covariance",
    "section": "Covariance of Random Vectors",
    "text": "Covariance of Random Vectors\nTODO - if time requires, we might start our discussion of the multivariate normal distribution with this."
  },
  {
    "objectID": "notes/normal.html",
    "href": "notes/normal.html",
    "title": "The Multivariate Normal Distribution",
    "section": "",
    "text": "\\[\\newcommand{\\P}{\\mathbb{P}} \\newcommand{\\E}{\\mathbb{E}} \\newcommand{\\V}{\\mathbb{V}} \\newcommand{\\R}{\\mathbb{R}} \\newcommand{\\bx}{\\mathbf{x}} \\newcommand{\\by}{\\mathbf{y}} \\newcommand{\\bX}{\\mathbf{X}} \\newcommand{\\bY}{\\mathbf{Y}} \\newcommand{\\bZ}{\\mathbf{Z}}\\]\nIn this set of notes, we begin our study of the most important distribution for random vectors, the multivariate normal distribution. Before we dig into the multivariate normal, however, it’s worth briefly discussing the univariate normal and how the concepts of variance and covariance apply to vectors."
  },
  {
    "objectID": "notes/normal.html#univariate-normal-distribution",
    "href": "notes/normal.html#univariate-normal-distribution",
    "title": "The Multivariate Normal Distribution",
    "section": "Univariate Normal Distribution",
    "text": "Univariate Normal Distribution\nThe univariate normal distribution is a continuous random variable with support on \\(\\R\\), that is, it takes all real-values. The standard normal distribution, almost universally called \\(Z\\), has PDF:\n\\[f_Z(z) = \\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2}\\]\nThe “core” of this distribution is reasonably straight-forward, \\(e^{-z^2/2}\\). This passes the “sniff” test for a distribution - it goes to zero quite quickly as \\(|z|\\) gets large, so it’s very believable that we have a finite integral. The “normalization constant” of \\(1/\\sqrt{2\\pi}\\) is a bit freaky, but there are deep reasons for it.\nBy definition, we can compute the mean and variance of \\(Z\\):\n\\[\\begin{align*}\n\\E[Z] &= \\int z f_Z(z)\\,\\text{d}z \\\\\n      &= \\frac{1}{\\sqrt{2\\pi}} \\int z e^{-z^2/2}\\,\\text{d}z \\\\\n      &= \\frac{1}{\\sqrt{2\\pi}} \\int z e^{-z^2/2}\\,\\text{d}z \\\\\n      &= \\frac{1}{\\sqrt{2\\pi}}\\left(e^{-z^2/2}\\right)_{z=-\\infty}^{\\infty} \\\\\n      &= \\frac{1}{\\sqrt{2\\pi}}\\left(e^{-\\infty^2/2} - e^{-(-\\infty)^2/2}\\right) \\\\\n      &= \\frac{1}{\\sqrt{2\\pi}}(0 - 0) \\\\\n      &= 0\n\\end{align*}\\]\nAs we would expect for a distributoin with a PDF that is symmetric around 0.\nThe variance is a bit trickier:\n\\[\\begin{align*}\n\\V[Z] &= \\E[Z^2] - \\E[Z]^2 \\\\\n&= \\E[Z^2] - 0 \\\\\n&= \\E[Z^2] \\\\\n&= \\int z^2 f_Z(z)\\,\\text{d}z \\\\\n&= \\dots\n&= 1\n\\end{align*}\\]\nwhere the dots capture some cumbersome, but standard algebra.\nThe normal distribution has a somewhat special property: it is a stable distribution, so if \\(X\\) has a normal distribution, so does \\(aX + b\\) for any scalars \\(a, b \\in \\R\\). We can use this fact to derive the distribution of any normal random variable.\nIf \\(X\\) has a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\), it can be shown that \\(X \\buildrel d\\over= \\mu + \\sigma Z\\) for standard normal \\(Z\\). (The \\(\\buildrel d\\over=\\) symbol means these two quantities have the same distribution. For these notes, it’s fine to interpret it as a standard equality.) Specifically, if \\(X \\buildrel d\\over= a + bZ\\) we can find that these must be the values of \\(a, b\\):\n\\[\\begin{align*}\n\\mu &= \\E[X] \\\\\n    &= \\E[a+bZ] \\\\\n    &= a + b\\E[Z] \\\\\n    &= a + b * 0 \\\\\n    &= a \\\\\n\\implies a &= \\mu\n\\end{align*}\\]\nand\n\\[\\begin{align*}\n\\sigma^2 &= \\V[X] \\\\\n         &= \\V[a + bZ] \\\\\n         &= b^2 \\V[Z] \\\\\n         &= b^2 * 1 \\\\\n\\implies b &= \\sigma\n\\end{align*}\\]\nWe can use this relationship to find the PDF and CDF of \\(X \\sim \\mathcal{N}(\\mu,\n\\sigma^2)\\). For the CDF, note that:\n\\[\\begin{align*}\nF_X(x) &= \\P(X \\leq x) \\\\\n&= \\P(\\mu + \\sigma Z \\leq x) \\\\\n&= \\P\\left(Z \\leq \\frac{x - \\mu}{\\sigma}\\right) \\\\\n&= \\Phi\\left(\\frac{x - \\mu}{\\sigma}\\right)\n\\end{align*}\\]\nwhere \\(\\Phi(\\cdot)\\) is the CDF of the standard normal \\(Z\\). \\(\\Phi(\\cdot)\\) is one of those functions that doesn’t have a “clean” formula in the usual sense, but it is so useful that basically all calculators and computers have it, or an equivalent function, built-in: C++, Python, R and javascript. In that way, it is quite like the trig functions \\(\\sin(\\cdot)\\), \\(\\cos(\\cdot)\\), and \\(\\tan(\\cdot)\\).\nNote that, by construction,\n\\[\\Phi(z) = \\P(Z \\leq z) = \\int_{-\\infty}^z f_Z(z')\\,\\text{d}z' = \\int_{-\\infty}^z \\frac{e^{-(z')^2/2}}{\\sqrt{2\\pi}}\\,\\text{d}z'\\]\nWith this in hand, we can get the PDF for \\(X\\) as well:\n\\[\\begin{align*}\nf_X(x) &= \\frac{\\text{d}}{\\text{d}x}F_X(x) \\\\\n       &= \\frac{\\text{d}}{\\text{d}x}\\Phi\\left(\\frac{x - \\mu}{\\sigma}\\right) \\\\\n       &= \\Phi'\\left(\\frac{x - \\mu}{\\sigma}\\right) * \\frac{\\text{d}}{\\text{d}x}\\left(\\frac{x - \\mu}{\\sigma}\\right) \\\\\n       &= \\phi\\left(\\frac{x - \\mu}{\\sigma}\\right) * \\frac{1}{\\sigma} \\\\\n       &= \\left(\\frac{\\exp\\left\\{-\\frac{\\left(\\frac{x-\\mu}{\\sigma}\\right)^2}{2}\\right\\}}{\\sqrt{2\\pi}}\\right)\\frac{1}{\\sigma} \\\\\n       &= \\frac{\\exp\\left\\{-(x-\\mu)^2/2\\sigma^2\\right\\}}{\\sqrt{2\\pi\\sigma^2}}\n\\end{align*}\\]\nNot so bad - and we don’t even have to compute the mean or variance since we started with those.\nWe will have a lot more to say about the normal distribution as we proceed in this course.\n\nRelated Distributions\nThe normal distribution is so ubiquitous in statistics that many functions of standard normal random variables are well-understood distributions in their own right. Perhaps the most important is \\(Z^2\\), so let’s explore it now. As usual, it’s easy enough to think about the distribution from the CDF:\n\\[\\begin{align*}\nF_{Z^2}(x) &= \\P(Z^2 \\leq x) \\\\\n&= \\P(-\\sqrt{x} \\leq Z \\leq \\sqrt{x}) \\\\\n&= \\P(Z \\leq \\sqrt{x}) - \\P(Z \\leq -\\sqrt{x}\\right) \\\\\n&= \\Phi(\\sqrt{x}) - \\Phi(-\\sqrt{x})\n\\end{align*}\\]\nFrom this, we can even get the PDF easily by differentiation:\n\\[\\begin{align*}\nf_{Z^2}(x) &= \\frac{\\text{d}}{\\text{d}x}F_{Z^2}(x)\\\\\n&= \\Phi'(\\sqrt{x}) * \\frac{1}{2\\sqrt{x}} - \\Phi'(-\\sqrt{x}) * \\frac{-1}{2\\sqrt{x}} \\\\\n&= \\Phi'(\\sqrt{x}) * \\frac{1}{2\\sqrt{x}} + \\Phi'(-\\sqrt{x}) * \\frac{+1}{2\\sqrt{x}} \\\\\n&= \\frac{1}{2\\sqrt{x}} * (\\phi(\\sqrt{x}) + \\phi(-\\sqrt{x})) \\\\\n&= \\frac{1}{2\\sqrt{x}}\\left(\\frac{e^{-\\sqrt{x}^2/2}}{\\sqrt{2\\pi}} + \\frac{e^{-(-\\sqrt{x})^2/2}}{\\sqrt{2\\pi}}\\right) \\\\\n&= \\frac{1}{2\\sqrt{x}}\\left(2\\frac{e^{-x/2}}{\\sqrt{2\\pi}}\\right) \\\\\n&= x^{-1/2}e^{-x/2} (2\\pi)^{-1/2}\n\\end{align*}\\] This is a special case of the \\(\\chi^2\\)-squared. Specifically, it is a \\(\\chi^2\\) PDF with one degree of freedom. To connect this to the standard form given on Wikipedia, inter alia, you need to know that \\(\\Gamma(1/2) = (-0.5)! = \\sqrt{\\pi}\\).1\nThe \\(\\chi^2\\) distribution is very important in statistical theory: the central limit theorem tells us that normal distributions (or something similar) appears almost anywhere, and \\(\\chi^2\\) variables appear whenever we start squaring normals. When we are interested in mean squared error, ordinary least squares, or normal log-likelihood, all of which contain “normal squared” terms, the \\(\\chi^2\\) is sure to follow.\nIn generality, we are rae"
  },
  {
    "objectID": "notes/normal.html#variance-and-covariance-of-vectors",
    "href": "notes/normal.html#variance-and-covariance-of-vectors",
    "title": "The Multivariate Normal Distribution",
    "section": "Variance and Covariance of Vectors",
    "text": "Variance and Covariance of Vectors"
  },
  {
    "objectID": "notes/normal.html#multivariate-normal-distribution",
    "href": "notes/normal.html#multivariate-normal-distribution",
    "title": "The Multivariate Normal Distribution",
    "section": "Multivariate Normal Distribution",
    "text": "Multivariate Normal Distribution\nBefore we discuss random vectors, let’s first review how vectors in general behave."
  },
  {
    "objectID": "notes/normal.html#properties-of-vectors",
    "href": "notes/normal.html#properties-of-vectors",
    "title": "The Multivariate Normal Distribution",
    "section": "Properties of Vectors",
    "text": "Properties of Vectors\nIn mathematics, a vector - random or otherwise - is a fixed-length ordered collection of numbers. When we want to be precise about the size of a vector, we often call it a “tuple”, e.g., a length-three vector is a “triple”, a length-four vector is a “4-tuple”, a length-five vector is a “5-tuple” etc..\nSo, these are all vectors:\n\n\\((3, 4)\\)\n\\((1, 1, 1)\\)\n\\((1, 5, 6, 10)\\)\n\nWhen we want to talk about the set of vectors of a given size, we use the Cartesian product of sets. For two sets, \\(A, B\\), the product set \\(A \\times B\\) is the set of all pairs, with the first element from \\(A\\) and the second from \\(B\\). In mathematical notation,\n\\[A \\times B = \\left\\{(a, b): a \\in A, b \\in B\\right\\} \\]\nThis set-builder notation is read as follows: “The Cartesian Product of \\(A\\) and \\(B\\) is the set of all pairs \\((a, b)\\) such that \\(a\\) is in \\(A\\) and \\(b\\) is in \\(B\\).”\nIf \\(A\\) and \\(B\\) are the same set, we define a Cartesian power as follows:\n\\[A^2 = A \\times A = \\left\\{(a_1, a_2): a_1 \\in A, a_2 \\in A\\right\\}\\]\nNote that even though the sets \\(A\\) and \\(A\\) in this product are the same, the elements in each pair may vary. For example, if \\(A = \\{1, 2, 3\\}\\), we have\n\\[A^2 = \\left\\{(1, 1), (1, 2), (1, 3), (2, 1), (2, 2), (2, 3), (3, 1), (3,2), (3, 3)\\right\\}\\]\nNote that vectors are ordered pairs so \\((2, 1) \\neq (1, 2)\\). From here, it should be pretty easy to convince yourself that set sizes play nicely with Cartesian products:\n\n\\(|A \\times B| = |A| |B|\\)\n\\(|A^k| = |A|^k\\)\n\nThe most common set of vectors we use are those where each element is an arbitrary real number. The set of vectors of length \\(n\\) (\\(n\\)-tuples) is thus \\(\\R^n\\). We rarely mix vectors of different lengths, so we don’t really have a name or notation for the “combo pack” \\(\\R^2 \\cup \\R^3 \\cup \\R^4\\).\nConventionally, vectors are written in bold (if on a computer) or with a little arrow on top (hand written): so a vector called “x” would be denoted \\(\\mathbf{x}\\) or \\(\\vec{x}\\). The elements of \\(\\bx\\) are denoted by subscripts \\(\\bx = (x_1, x_2, \\dots, x_n)\\).\n\nVector Arithmetic\nWe have three arithmetic operations we can perform on general vectors. The simplest is scalar multiplication. A scalar is a non-vector number, i.e., a ‘regular’ number. Scalar multiplication consists of applying the scalar independently to each element of a vector.\n\\[\\alpha \\bx = \\alpha(x_1, x_2, \\dots, x_n) = (\\alpha x_1, \\alpha x_2, \\dots, \\alpha x_n)\\]\nFor example, if \\(\\bx = (3, 4)\\) and \\(\\alpha = 2\\), we have \\[\\alpha \\bx = (6, 8)\\]\nNote that the output of scalar multiplication is always a vector of the same length as the input.\nWe also have the ability to add vectors. This again is performed element-wise.\n\\[\\bx + \\by = (x_1, \\dots, x_n) + (y_1, \\dots, y_n) = (x_1 + y_1, \\dots, x_n + y_n) \\]\nNote that we can’t add vectors of different lengths (recall our “no mixing” rule) and the output length is always the same as the input lengths.\nFinally, we have the vector inner product, defined as:\n\\[\\langle \\bx, \\by \\rangle = x_1y_1 + x_2y_2 + \\dots + x_ny_n \\]\nYou might have seen this previously as the “dot” product. The inner product takes two length-\\(n\\) vectors and gives back a scalar. This structure might seem a bit funny, but as we’ll see below, it’s actually quite useful.\nYou might ask if there’s a “vector-out” product: there is one, with the fancy name “Hadamard product”, but it doesn’t play nicely with other tools, so we don’t use it very much.\nThese tools play nicely together:\n\n\\(\\alpha(\\bx + \\by) = \\alpha \\bx + \\alpha \\by\\) (Distributive)\n\\(\\langle \\alpha \\bx, \\by \\rangle = \\alpha \\langle \\bx, \\by \\rangle\\) (Associative)\n\\(\\langle \\bx, \\by \\rangle = \\langle \\by, \\bx \\rangle\\) (Commutative)\n\n\n\nVector Length and Angle\nWe sometimes want to think about the “size” of a vector, analogous to the absolute value of a scalar. In scalar-world, we say “drop the sign” but there’s not an obvious analogue to a sign for a vector. For instance, if \\(\\bx = (3, -4)\\) is \\(\\bx\\) “positive”, “negative” or somewhere in beetween?\nWe note a trick from scalar-land: \\(|x| = \\sqrt{x^2}\\). We can use the same idea for vectors:\n\\[ \\|\\bx\\| = \\sqrt{\\langle \\bx, \\bx\\rangle} = \\sqrt{\\sum_{i=1}^n x_i^2}\\]\nThis quantity, \\(\\|\\bx\\|\\), is called the norm or length of a vector. We use the double bars to distinguish it from the absolute value of a scalar, but it’s fundamentally the same idea.\nIn \\(\\R^2\\), we recognize this formula for length as the Pythagorean theorem:\n\\[ \\|(3, 4)\\| = \\sqrt{3^2 + 4^2} = \\sqrt{25} = 5 \\]\nWe also sometimes want to define the angle between two vectors. We can define this as:\n\\[ \\cos \\angle(\\bx, \\by) = \\frac{\\langle \\bx, \\by\\rangle}{\\|\\bx\\|\\|\\by\\|} \\Leftrightarrow \\angle(\\bx, \\by) = \\cos^{-1}\\left(\\frac{\\langle \\bx, \\by\\rangle}{\\|\\bx\\|\\|\\by\\|}\\right)\\]\nWe won’t use this formula too often, but it’s good to have it."
  },
  {
    "objectID": "notes/normal.html#random-vectors",
    "href": "notes/normal.html#random-vectors",
    "title": "The Multivariate Normal Distribution",
    "section": "Random Vectors",
    "text": "Random Vectors\nJust like a vector is a ordered collection of “regular” numbers, a random vector is an ordered collection of random variables.\nWhere do random vectors come from? Everywhere!\nEssentially any data collection can be thought of “vectorly”. If we record multiple pieces of information for each sample, each sample gives us a vector of information."
  },
  {
    "objectID": "notes/normal.html#distributions-on-random-vectors",
    "href": "notes/normal.html#distributions-on-random-vectors",
    "title": "The Multivariate Normal Distribution",
    "section": "Distributions on Random Vectors",
    "text": "Distributions on Random Vectors\nHow might we begin to specify probabilities on vectors? We have essentially two approaches. We can begin from a definition of how we want probabilities to behave, extending the rules we developed for random variables, or we can assemble a distribution on a vector from distributions on variables defined in just the right way. Both of these will be fruitful, but let’s begin with the axiomatic approach.\n\nProperties of Multivariate Distributions\nIn our discussion of random variables, we highlighted the role of the CDF as a tool that can unify both discrete and continuous variates. Our definition of random variables - real-valued random quantities - guaranteed that quantities like \\(\\P(X \\leq x)\\) were always defined.\nUnfortunately, as we move from \\(\\R\\)-valued to \\(\\R^n\\)-valued quantities, it’s not quite as simple to make sense of statements like \\(\\bX \\leq \\bx\\) (bold here for vectors). Most commonly, we define vector inequalities elementwise, so\n\\[\\bX \\leq \\bx \\implies X_1 \\leq x_1 \\text{ and } X_2 \\leq x_2 \\dots \\text{ and} X_n \\leq x_n\\]\nUnfortunately, this has several limitations. Most notably, we no longer have the “three-way” logic of standard inequalities, it is possible for neither \\(\\bX \\leq \\bx\\) or \\(\\bX &gt; \\bx\\) to be true: some components can be less than while others can be greater than. Even so, we could still try to build a multi-dimensional CDF for \\(\\bX\\), \\(F_{\\bX}(\\bx)  = \\P(\\bX \\leq \\bx)\\).\nWe know that as \\(\\bx \\to \\infty\\), we must have \\(F_{\\bX}((\\infty, \\infty, \\dots, \\infty)) = 1\\) and that \\(F_{\\bX}\\) must be monotonically increasing in each component. (Why?) Unfortunately, that’s not a particularly nice type of function, so it’s hard to naturally come up with examples like this.\nIt may be more fruitful to “piece-together” multivariate distributions from univariate components. To do so, we’ll actually put the PDF front and center in the multivariate case.\nThe properties we expect of a PDF translate naturally to the multivariate case:\n\n\\(\\int_{\\R^n} f_{\\bX}(\\bx)\\,\\text{d}\\bx = 1\\)\n\\(f_{\\bX}(\\cdot) \\geq 0\\) everywhere\n\nAs always, replace the integral with a sum if \\(\\bX\\) is discrete.\nThe only wrinkle here is working with the multivariate integral, \\(\\int_{\\R^n}\\), so let’s do some practice problems.\n\nExample 1: 2D Uniform\nLet’s first consider a 2D uniform distribution on the unit square \\([0, 1]^2\\), that is, the set of all \\((x, y)\\) such that \\(0 \\leq x \\leq 1\\) and \\(0 \\leq y \\leq 1\\) (with no restrictions on \\(x, y\\) together). Since we want to build a uniform distribution, all we can assume is \\[f_{(x, y)}(x, y) = c\\] for some constant \\(c \\geq 0\\). We know that this quantity must integrate to 1, so let’s work out the integral:\n\\[\\begin{align*}\n1 &= \\iint_{[0, 1]^2} c\\,\\text{d}x\\,\\text{d}y \\\\\n&= c \\iint_{[0, 1]^2} \\text{d}x\\,\\text{d}y \\\\\n&= c \\int_{0}^1 \\int_0^1 \\text{d}x\\,\\text{d}y \\\\\n&= c \\int_{0}^1 \\left.x\\right|_0^1\\,\\text{d}y \\\\\n&= c \\int_{0}^1 1\\text{d}y \\\\\n&= c \\left(\\left.y\\right|_0^1\\right) \\\\\n&= c \\\\\n\\implies c &= 1\n\\end{align*}\\]\nso the uniform distribution on the square has constant PDF 1. This is quite nice: by extending the above argument, we can actually see that for any set \\(A \\subseteq [0, 1]^2\\), \\(\\P(\\bX \\in A) = \\text{Area}(A)\\). This justifies our intuition for uniform distributions.\nWe can extend this idea to a fun special case: let \\(A\\) be a quarter circle embedded in the unit square:\n\nx &lt;- seq(0, 1, length.out=201)\ny &lt;- sqrt(1 - x^2)\nplot(x, y,type=\"h\", col=\"red2\", asp=1, xlim=c(0, 1))\nsegments(c(0, 0, 1, 0), \n         c(0, 0, 0, 1), \n         c(0, 1, 1, 1), \n         c(1, 0, 1, 1), \n         lwd=3)\n\n\n\n\n\n\n\n\nClearly the square has area 1 while the circle has area \\(\\pi/4\\).\nIf we were to pick a point uniformly from within the square, there is thus a \\(\\pi/4\\) chance that it falls inside the red area. This is a bit impractical to do by hand (though people did it back in the day!), but quite easy to do on a computer:\n\nn &lt;- 1e6 # Generate one million points IID uniform on the unit square\nX &lt;- runif(n, min=0, max=1)\nY &lt;- runif(n, min=0, max=1)\n\n# Check fraction that are in the red area\nin_red &lt;- (X^2 + Y^2) &lt; 1\n\nP_red &lt;- mean(in_red)\nprint(P_red)\n\n[1] 0.784674\n\n\nFrom this, we can actually ‘back out’ the value of \\(\\pi\\) as \\(4 * \\hat{\\P}(\\text{red})\\):\n\npi_approx &lt;- 4 * P_red\nprint(pi_approx)\n\n[1] 3.138696\n\n\nNot terrible!\nFor a bit of review, let’s compute the variance of our \\(\\pi\\)-estimator.\nDefine \\[\\hat{\\Pi}_n = 4 * \\text{Fraction of points in red area} = \\frac{4}{n}\\sum_{i=1}^n 1_{\\text{Red Area}}(X_i)\\]\nHere, we use the average indicator of the red area to compute the fraction of points in the red zone. Since each point is selected randomly, the indicators are independent and hence we can compute the variance quite simply:\n\\[\\begin{align*}\n\\V[\\hat{\\Pi}_n] &= \\V\\left[\\frac{4}{n}\\sum_{i=1}^n 1_{\\text{Red Area}}(X_i)\\right] \\\\\n&= \\frac{16}{n^2}\\V\\left[\\sum_{i=1}^n 1_{\\text{Red Area}}(X_i)\\right] \\\\\n&= \\frac{16}{n^2}\\sum_{i=1}^n \\V[1_{\\text{Red Area}}(X_i)] \\\\\n&= \\frac{16}{n^2}\\sum_{i=1}^n \\V[\\text{Bernoulli}(\\pi/4)] \\\\\n&= \\frac{16}{n^2}\\sum_{i=1}^n \\frac{\\pi}{4}\\left(1-\\frac{4}{\\pi}\\right) \\\\\n&= \\frac{16}{n^2} *  n * \\frac{\\pi}{4}\\left(1-\\frac{\\pi}{4}\\right) \\\\\n&= \\frac{4\\pi}{n}\\left(1-\\frac{\\pi}{4}\\right) \\\\\n&\\approx \\frac{2.7}{n}\n\\end{align*}\\]\nSo our example above with one million points has a variance of about 0.0003%, giving a standard deviation of 0.0016. That means that, very roughly, we get about 3 digits of accuracy from one million points, consistent with above.\nWe note that this analysis requires us to know the probability we are trying to estimate. That’s not a super-practical assumption, but if we recall that the Bernoulli variance is bounded above by \\(0.25\\), we can get an upper bound of\n\\[\\V[\\hat{\\Pi}_n] \\leq \\frac{4}{n}\\]\nwhich really isn’t too much worse than the “true” value.\nThis approach might seem a bit crazy - and it definitely is not a very efficient way to compute \\(\\pi\\) - but it’s actually incredibly useful. Variants of this approach, known as the “Monte Carlo” approach, are used throughout advanced science and engineering to compute probabilities of adverse events which depend on uncertain physical parameters. We will say more about MC methods later in this course.\n\n\n\nProduct Distributions: Independence\nOne easy way to create vector distributions is via product distributions. Given a random variable \\(X\\) and a second random variable \\(Y\\), mutually independent, and each with PDF \\(f_X(\\cdot)\\) and \\(f_Y(\\cdot)\\) respectively, we can create a new random variable \\(\\bZ = (X, Y)\\). The PDF of \\(\\bZ\\) is given by\n\\[f_{\\bZ}(\\bz) = f_{(X, Y)}((z_1, z_2)) = f_{X}(z_1)f_{Y}(z_2)\\]\nThis structure, where we can break things apart into two terms is called a product distribution and it’s the most general form of independence we consider in this course. In fact, you can basically take this as as a definition of independence. Two random variables \\(X, Y\\) are independent if their joint PDF is just the product of their separate PDFs.\nRecall that, in our initial discussion of independent events, we said \\(A, B\\) are independent if \\(\\P(A \\cap B) = \\P(A)\\P(B)\\). If you squint, this looks a lot like our definition of a product distribution. We can make this (semi-)formal:\n\\[\\begin{align*}\n\\P(X \\in A_X, Y \\in A_Y) &= \\int_{A_X}\\int_{A_Y} f_{(X, Y)}(x, y)\\,\\text{d}y\\,\\text{d}x \\\\\n&= \\int_{A_X}\\int_{A_Y} f_X(x)f_Y(y)\\,\\text{d}y\\,\\text{d}x \\tag{Assuming product structure}\\\\\n&= \\int_{A_X} f_X(x)\\int_{A_Y}f_Y(y)\\,\\text{d}y\\,\\text{d}x \\tag{Factor out $x$-terms}\\\\\n&= \\int_{A_X} f_X(x)\\P(Y \\in A_Y)\\,\\text{d}x \\tag{Integrate $y$-terms}\\\\\n&= \\P(Y \\in A_Y)\\int_{A_X} f_X(x)\\,\\text{d}x \\tag{Factor out constant}\\\\\n&= \\P(Y \\in A_Y)\\P(X \\in A_X) \\tag{Integrate $x$-terms}\n\\end{align*}\\]\nSince we made no assumptions on the shapes of \\(A_X, A_Y\\), we see that this argument holds for any events defined in terms of one vector component only.\nLet’s stay this again because it’s important:\n\nIf the random vector \\((X, Y)\\) has a PDF that has a product structure, \\(X\\) and \\(Y\\) are independent and so are any pair of events based on them separately.\n\nThis may be a bit counterintuitive:\n\n\\(f_{(X, Y)}\\propto xy\\) has \\(X, Y\\) independent\n\\(f_{(X, Y)}\\propto x + y\\) does not have \\(X, Y\\) independent\n\nCan you see why? What about \\(4 + 2\\cos(x) + 2\\sin(y) + \\cos(x)\\sin(y) = (2+\\cos(x))(2+\\sin(y))\\)?\nAt the beginning of this course, we emphasized that the conditions under which an “and” statement could be evaluated by multiplying probabilities were a bit subtle: we have now fully expressed these conditions using the notions of independence and factorizability.\n\n\nMarginal Distributions\nIn other circumstances, we may have a joint PDF and want to only look at one component. The “induced” distribution that we get by ignoring \\(Y\\) and only looking at \\(X\\) is called the marginal distribution.\nTo build up the mathematics of marginal distributions, let’s introduce the special value \\(\\textsf{ANY}\\), which does exactly what it sounds like it should. Use of \\(\\textsf{ANY}\\) lets us express the marginal distribution PDF from the joint PDF:\n\\[f_{X}(x) = f_{(X, Y)}(x, \\textsf{ANY})\\].\nHere, since we don’t care about the value of \\(Y\\) (\\(\\textsf{ANY}\\)), we integrate over its whole range to find:\n\\[f_{X}(x) = \\int f_{(X, Y)}(x, y)\\,\\text{d}y\\]\nThe “x” is not integrated since we’re keeping it “free” in the marginal PDF. Of course, if we have a product structure, this is particularly nice:\n\\[f_{X}(x) = \\int f_{(X, Y)}(x, y)\\,\\text{d}y = f_X(x) \\int f_Y(y)\\,\\text{d}y = f_X(x)\\]\nSo the marginal distribution of two independent random variables is “just” the factor we care about. (Independence makes life so easy!)\nWhat about a case without independence? Suppose we have \\(f_{(X, Y)}(x, y) c(x+y)\\). We first want to find the constant \\(c\\) \nTODO\n\n\nConditional Distributions\nTODO\n\n\nNamed Distributions\nTODO"
  },
  {
    "objectID": "test_file.html",
    "href": "test_file.html",
    "title": "Untitled",
    "section": "",
    "text": "library(sf)\nlibrary(tidyverse)\n\nif(!file.exists(\"nyc_borough_boundaries.zip\")){\n    download.file(\"https://data.cityofnewyork.us/api/geospatial/tqmj-j8zm?method=export&format=Shapefile\", \n              destfile=\"nyc_borough_boundaries.zip\")\n}\n\n##-\ntd &lt;- tempdir(); \nzip_contents &lt;- unzip(\"nyc_borough_boundaries.zip\", \n                      exdir = td)\n    \nfname_shp &lt;- zip_contents[grepl(\"shp$\", zip_contents)]\nnyc_sf &lt;- read_sf(fname_shp, quiet=TRUE)\n\nBut later!\n\nnyc_sf\n\nSimple feature collection with 5 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -74.25559 ymin: 40.49613 xmax: -73.70001 ymax: 40.91553\nGeodetic CRS:  WGS84(DD)\n# A tibble: 5 × 5\n  boro_code boro_name      shape_area shape_leng                        geometry\n      &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;              &lt;MULTIPOLYGON [°]&gt;\n1         3 Brooklyn      1934142776.    728147. (((-73.86327 40.58388, -73.863…\n2         5 Staten Island 1623618684.    325910. (((-74.05051 40.56642, -74.050…\n3         1 Manhattan      636646082.    360038. (((-74.01093 40.68449, -74.011…\n4         2 Bronx         1187174772.    463181. (((-73.89681 40.79581, -73.896…\n5         4 Queens        3041418004.    888197. (((-73.82645 40.59053, -73.826…"
  },
  {
    "objectID": "notes/normal.html#footnotes",
    "href": "notes/normal.html#footnotes",
    "title": "The Multivariate Normal Distribution",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is profoundly not obvious, so don’t worry about it.↩︎"
  }
]